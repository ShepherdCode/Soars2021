{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ojm_6E9f9Kcf"
   },
   "source": [
    "# MLP GenCode \n",
    "Wen et al 2019 used DNN to distinguish GenCode mRNA/lncRNA.\n",
    "Based on K-mer frequencies, K={1,2,3}, they reported 99% accuracy.\n",
    "Their CNN used 2 Conv2D layers of 32 filters of width 3x3, max pool 2x2, 25% drop, dense 128.\n",
    "Can we reproduce that with MLP layers instead of CNN?\n",
    "Extract features as list of K-mer frequencies for K={1,2,3}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-08 17:23:17 EDT\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "def show_time():\n",
    "    t = time.time()\n",
    "    print(time.strftime('%Y-%m-%d %H:%M:%S %Z', time.localtime(t)))\n",
    "show_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PC_SEQUENCES=32000\n",
    "NC_SEQUENCES=32000\n",
    "RNA_LEN=32\n",
    "CDS_LEN=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "VQY7aTj29Kch"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoLab not working. On my PC, use relative paths.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "IN_COLAB = False\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    pass\n",
    "if IN_COLAB:\n",
    "    print(\"On Google CoLab, mount cloud-local file, get our code from GitHub.\")\n",
    "    PATH='/content/drive/'\n",
    "    #drive.mount(PATH,force_remount=True)  # hardly ever need this\n",
    "    #drive.mount(PATH)    # Google will require login credentials\n",
    "    DATAPATH=PATH+'My Drive/data/'  # must end in \"/\"\n",
    "    import requests\n",
    "    r = requests.get('https://raw.githubusercontent.com/ShepherdCode/Soars2021/master/SimTools/GenCodeTools.py')\n",
    "    with open('GenCodeTools.py', 'w') as f:\n",
    "        f.write(r.text)  \n",
    "    from GenCodeTools import GenCodeLoader\n",
    "    r = requests.get('https://raw.githubusercontent.com/ShepherdCode/Soars2021/master/SimTools/KmerTools.py')\n",
    "    with open('KmerTools.py', 'w') as f:\n",
    "        f.write(r.text)  \n",
    "    from KmerTools import KmerTools\n",
    "else:\n",
    "        print(\"CoLab not working. On my PC, use relative paths.\")\n",
    "        DATAPATH='data/'  # must end in \"/\"\n",
    "        sys.path.append(\"..\") # append parent dir in order to use sibling dirs\n",
    "        from SimTools.GenCodeTools import GenCodeLoader\n",
    "        from SimTools.KmerTools import KmerTools\n",
    "MODELPATH=\"BestModel\"  # saved on cloud instance and lost after logout\n",
    "#MODELPATH=DATAPATH+MODELPATH  # saved on Google Drive but requires login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load\n",
    "Restrict mRNA to those transcripts with a recognized ORF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PC_FILENAME='gencode.v38.pc_transcripts.fa.gz'\n",
    "NC_FILENAME='gencode.v38.lncRNA_transcripts.fa.gz'\n",
    "PC_FULLPATH=DATAPATH+PC_FILENAME\n",
    "NC_FULLPATH=DATAPATH+NC_FILENAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-08 17:23:19 EDT\n",
      "PC seqs loaded: 70825\n",
      "2021-07-08 17:23:24 EDT\n",
      "NC seqs loaded: 48752\n",
      "2021-07-08 17:23:26 EDT\n"
     ]
    }
   ],
   "source": [
    "# Full GenCode ver 38 human is 106143 pc + 48752 nc and loads in 7 sec.\n",
    "# Expect fewer transcripts if special filtering is used.\n",
    "loader=GenCodeLoader()\n",
    "loader.set_label(1)\n",
    "loader.set_check_utr(True)\n",
    "pcdf=loader.load_file(PC_FULLPATH)\n",
    "print(\"PC seqs loaded:\",len(pcdf))\n",
    "loader.set_label(0)\n",
    "loader.set_check_utr(False)\n",
    "ncdf=loader.load_file(NC_FULLPATH)\n",
    "print(\"NC seqs loaded:\",len(ncdf))\n",
    "show_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-08 17:23:26 EDT\n",
      "PC seqs pass filter: 55381 max len: 4000\n",
      "NC seqs pass filter: 46919 max len: 4000\n"
     ]
    }
   ],
   "source": [
    "# Length filter\n",
    "def apply_length_filter(df,low,high):\n",
    "    # The pandas query language is strange, \n",
    "    # but this is MUCH faster than loop & drop.\n",
    "    return df[ (df['seqlen']>=low) & (df['seqlen']<=high) ]\n",
    "\n",
    "PC_LENGTHS=(200,4000)\n",
    "NC_LENGTHS=(200,4000)  # oddly, the paper used 250 to 3500 for NC only\n",
    "pc_filtered=apply_length_filter(pcdf,PC_LENGTHS[0],PC_LENGTHS[1])\n",
    "nc_filtered=apply_length_filter(ncdf,NC_LENGTHS[0],NC_LENGTHS[1])\n",
    "show_time()\n",
    "print(\"PC seqs pass filter:\",len(pc_filtered),\"max len:\",pc_filtered['seqlen'].max())\n",
    "print(\"NC seqs pass filter:\",len(nc_filtered),\"max len:\",nc_filtered['seqlen'].max())\n",
    "# Garbage collection to reduce RAM footprint\n",
    "pcdf=None\n",
    "ncdf=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pc_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-4015823911ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKmerTools\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpc_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dict_upto_K\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_K\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpc_all\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_count_one_K\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpc_counts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMAX_K\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pc_all' is not defined"
     ]
    }
   ],
   "source": [
    "MAX_K = 3\n",
    "tool = KmerTools()\n",
    "pc_counts = tool.make_dict_upto_K(MAX_K)\n",
    "for sample in pc_all:\n",
    "    print(sample)\n",
    "    tool.update_count_one_K(pc_counts,MAX_K,sample,True)\n",
    "tool.harvest_counts_from_K(pc_counts,MAX_K)\n",
    "print(\"PC counts:\\n\",pc_counts)\n",
    "pc_freqs = tool.count_to_frequency(pc_counts,MAX_K)\n",
    "print (\"Frequency:\\n\",pc_freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_counts = tool.make_dict_upto_K(MAX_K)\n",
    "for sample in nc_all:\n",
    "    tool.update_count_one_K(nc_counts,MAX_K,sample,True)\n",
    "tool.harvest_counts_from_K(nc_counts,MAX_K)\n",
    "print(\"NC counts:\\n\",nc_counts)\n",
    "nc_freqs = tool.count_to_frequency(nc_counts,MAX_K)\n",
    "print (\"Frequency:\\n\",nc_freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = prepare_inputs_len_x_alphabet(pc_train,nc_train,ALPHABET) # shuffles\n",
    "print(\"Data ready.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MLP_205.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
