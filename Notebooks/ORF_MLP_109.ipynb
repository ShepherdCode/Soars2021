{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ORF_MLP_109.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0asdcdunj2Tx"
      },
      "source": [
        "# ORF recognition by MLP\n",
        "\n",
        "So far, no MLP has exceeded 50% accurcy on any ORF problem.\n",
        "Here, try a variety of things.\n",
        "\n",
        "RNA length 16, CDS length 8.\n",
        "No luck with 32 neurons or 64 neurons\n",
        "Instead of sigmoid, tried tanh and relu.\n",
        "Instead of 4 layers, tried 1.\n",
        "RNA length 12, CDS length 6.\n",
        "2 layers of 32 neurons, sigmoid.\n",
        "Even 512 neurons, rectangular or triangular, didn't work.\n",
        "Move INPUT_SHAPE from compile() to first layer parameter. \n",
        "\n",
        "This works: All PC='AC'*, all NC='GT'*. \n",
        "100% accurate on one epoch with 2 layers of 12 neurons.\n",
        "\n",
        "Nothing works! Now suspect the data preparation is incorrect. Try trivializing the problem by always adding ATG or TAG."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "QP1VTRNQj2UO",
        "outputId": "654e3893-461c-40f3-a38e-a28501149786"
      },
      "source": [
        "import time \n",
        "t = time.time()\n",
        "time.strftime('%Y-%m-%d %H:%M:%S %Z', time.localtime(t))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2021-06-23 17:57:18 UTC'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nhz4GKonj2T_"
      },
      "source": [
        "PC_SEQUENCES=32000   # how many protein-coding sequences\n",
        "NC_SEQUENCES=32000   # how many non-coding sequences\n",
        "PC_TESTS=1000\n",
        "NC_TESTS=1000\n",
        "RNA_LEN=32            # how long is each sequence\n",
        "CDS_LEN=16           # min CDS len to be coding\n",
        "ALPHABET=4          # how many different letters are possible\n",
        "INPUT_SHAPE_2D = (RNA_LEN,ALPHABET,1) # Conv2D needs 3D inputs\n",
        "INPUT_SHAPE = (None,RNA_LEN,ALPHABET) # MLP requires batch size None\n",
        "FILTERS = 16   # how many different patterns the model looks for\n",
        "CELLS = 16\n",
        "NEURONS = 32\n",
        "DROP_RATE = 0.4\n",
        "WIDTH = 3   # how wide each pattern is, in bases\n",
        "STRIDE_2D = (1,1)  # For Conv2D how far in each direction\n",
        "STRIDE = 1 # For Conv1D, how far between pattern matches, in bases\n",
        "EPOCHS=50  # how many times to train on all the data\n",
        "SPLITS=3  # SPLITS=3 means train on 2/3 and validate on 1/3 \n",
        "FOLDS=3  # train the model this many times (range 1 to SPLITS)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lr7q90rxj2UE",
        "outputId": "fc959abb-daa0-415a-996c-5be4f285ece8"
      },
      "source": [
        "import sys\n",
        "IN_COLAB = False\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    pass\n",
        "if IN_COLAB:\n",
        "    print(\"On Google CoLab, mount cloud-local file, get our code from GitHub.\")\n",
        "    PATH='/content/drive/'\n",
        "    #drive.mount(PATH,force_remount=True)  # hardly ever need this\n",
        "    #drive.mount(PATH)    # Google will require login credentials\n",
        "    DATAPATH=PATH+'My Drive/data/'  # must end in \"/\"\n",
        "    import requests\n",
        "    r = requests.get('https://raw.githubusercontent.com/ShepherdCode/Soars2021/master/SimTools/RNA_describe.py')\n",
        "    with open('RNA_describe.py', 'w') as f:\n",
        "        f.write(r.text)  \n",
        "    from RNA_describe import ORF_counter\n",
        "    from RNA_describe import Random_Base_Oracle\n",
        "    r = requests.get('https://raw.githubusercontent.com/ShepherdCode/Soars2021/master/SimTools/RNA_prep.py')\n",
        "    with open('RNA_prep.py', 'w') as f:\n",
        "        f.write(r.text)  \n",
        "    from RNA_prep import prepare_inputs_len_x_alphabet\n",
        "else:\n",
        "        print(\"CoLab not working. On my PC, use relative paths.\")\n",
        "        DATAPATH='data/'  # must end in \"/\"\n",
        "        sys.path.append(\"..\") # append parent dir in order to use sibling dirs\n",
        "        from SimTools.RNA_describe import ORF_counter,Random_Base_Oracle\n",
        "        from SimTools.RNA_prep import prepare_inputs_len_x_alphabet\n",
        "\n",
        "MODELPATH=\"BestModel\"  # saved on cloud instance and lost after logout\n",
        "#MODELPATH=DATAPATH+MODELPATH  # saved on Google Drive but requires login\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "On Google CoLab, mount cloud-local file, get our code from GitHub.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGDXH8Uwj2UM"
      },
      "source": [
        "from os import listdir\n",
        "import csv\n",
        "from zipfile import ZipFile\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats  # mode\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Embedding,Dropout\n",
        "from keras.layers import Conv1D,Conv2D\n",
        "from keras.layers import GRU,LSTM\n",
        "from keras.layers import Flatten,TimeDistributed\n",
        "from keras.layers import MaxPooling1D,MaxPooling2D\n",
        "from keras.losses import BinaryCrossentropy\n",
        "# tf.keras.losses.BinaryCrossentropy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import colors\n",
        "mycmap = colors.ListedColormap(['red','blue'])  # list color for label 0 then 1\n",
        "np.set_printoptions(precision=2)\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUOG_jEvGtOm",
        "outputId": "bc35d0dd-3a7a-4f06-f211-033a9f59d60e"
      },
      "source": [
        "rbo=Random_Base_Oracle(RNA_LEN,True)\n",
        "pc_all,nc_all = rbo.get_partitioned_sequences(CDS_LEN,10) # just testing\n",
        "pc_all,nc_all = rbo.get_partitioned_sequences(CDS_LEN,PC_SEQUENCES+PC_TESTS)\n",
        "print(\"Use\",len(pc_all),\"PC seqs\")\n",
        "print(\"Use\",len(nc_all),\"NC seqs\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "It took 29 trials to reach 10 per class.\n",
            "It took 142965 trials to reach 33000 per class.\n",
            "Use 33000 PC seqs\n",
            "Use 33000 NC seqs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIMcOB-9yEV6"
      },
      "source": [
        "# Make the problem super easy!\n",
        "def trivialize_sequences(list_of_seq,option):\n",
        "    num_seq = len(list_of_seq)\n",
        "    for i in range(0,num_seq):\n",
        "        seq = list_of_seq[i]\n",
        "        if option==0:\n",
        "            list_of_seq[i] = 'TTTTTT'+seq[6:]\n",
        "        else:\n",
        "            list_of_seq[i] = 'AAAAAA'+seq[6:]\n",
        "\n",
        "if False:\n",
        "    print(\"Trivialize...\")\n",
        "    trivialize_sequences(pc_all,1)\n",
        "    print(\"Trivial PC:\",pc_all[:5])\n",
        "    print(\"Trivial PC:\",pc_all[-5:])\n",
        "    trivialize_sequences(nc_all,0)\n",
        "    print(\"Trivial NC:\",nc_all[:5])\n",
        "    print(\"Trivial NC:\",nc_all[-5:])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-BmSXi2jUyl",
        "outputId": "2d088e19-6162-4755-8b33-83e2c51774b3"
      },
      "source": [
        "# Describe the sequences\n",
        "def describe_sequences(list_of_seq):\n",
        "    oc = ORF_counter()\n",
        "    num_seq = len(list_of_seq)\n",
        "    rna_lens = np.zeros(num_seq)\n",
        "    orf_lens = np.zeros(num_seq)\n",
        "    for i in range(0,num_seq):\n",
        "        rna_len = len(list_of_seq[i])\n",
        "        rna_lens[i] = rna_len\n",
        "        oc.set_sequence(list_of_seq[i])\n",
        "        orf_len = oc.get_max_orf_len()\n",
        "        orf_lens[i] = orf_len\n",
        "    print (\"Average RNA length:\",rna_lens.mean())\n",
        "    print (\"Average ORF length:\",orf_lens.mean())\n",
        "    \n",
        "print(\"Simulated sequences prior to adjustment:\")\n",
        "print(\"PC seqs\")\n",
        "describe_sequences(pc_all)\n",
        "print(\"NC seqs\")\n",
        "describe_sequences(nc_all)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Simulated sequences prior to adjustment:\n",
            "PC seqs\n",
            "Average RNA length: 32.0\n",
            "Average ORF length: 19.712818181818182\n",
            "NC seqs\n",
            "Average RNA length: 32.0\n",
            "Average ORF length: 2.858363636363636\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iP1y7-J3jUys"
      },
      "source": [
        "pc_train=pc_all[:PC_SEQUENCES]\n",
        "nc_train=nc_all[:NC_SEQUENCES]\n",
        "pc_test=pc_all[PC_SEQUENCES:]\n",
        "nc_test=nc_all[NC_SEQUENCES:]"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIpTrnH6j2US",
        "outputId": "1d8016d4-5c19-4fdc-e475-204b47fd70f3"
      },
      "source": [
        "# Use code from our SimTools library.\n",
        "X,y = prepare_inputs_len_x_alphabet(pc_train,nc_train,ALPHABET) # shuffles\n",
        "print(\"Data ready.\")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data ready.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVhr6K95qil7",
        "outputId": "6ef78fc6-3a1b-452f-8554-01212ebb78d2"
      },
      "source": [
        "print(len(X),\"sequences total\")\n",
        "print(len(X[0]),\"bases/sequence\")\n",
        "print(len(X[0][0]),\"dimensions/base\")\n",
        "#print(X[0])\n",
        "print(type(X[0]))\n",
        "print(X[0].shape)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "64000 sequences total\n",
            "32 bases/sequence\n",
            "4 dimensions/base\n",
            "<class 'numpy.ndarray'>\n",
            "(32, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NvrVU8ij2UU",
        "outputId": "ca13d2b0-b98e-4239-ed4d-c97886a0a8ba"
      },
      "source": [
        "def make_DNN():\n",
        "    print(\"make_DNN\")\n",
        "    print(\"input shape:\",INPUT_SHAPE)\n",
        "    dnn = Sequential()\n",
        "    dnn.add(Flatten())\n",
        "    dnn.add(Dense(NEURONS,activation=\"sigmoid\",dtype=np.float32,\n",
        "                 input_shape=INPUT_SHAPE ))   \n",
        "    dnn.add(Dense(NEURONS,activation=\"sigmoid\",dtype=np.float32))   \n",
        "    dnn.add(Dense(NEURONS,activation=\"sigmoid\",dtype=np.float32))   \n",
        "    dnn.add(Dense(NEURONS,activation=\"sigmoid\",dtype=np.float32))   \n",
        "    #dnn.add(Dropout(DROP_RATE))\n",
        "    dnn.add(Dense(1,activation=\"sigmoid\",dtype=np.float32))   \n",
        "    dnn.compile(optimizer='adam',\n",
        "                loss=BinaryCrossentropy(from_logits=False),\n",
        "                metrics=['accuracy'])   # add to default metrics=loss\n",
        "    dnn.build(input_shape=INPUT_SHAPE) \n",
        "    #dnn.build() \n",
        "    #ln_rate = tf.keras.optimizers.Adam(learning_rate = LN_RATE)\n",
        "    #bc=tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "    #model.compile(loss=bc, optimizer=ln_rate, metrics=[\"accuracy\"])\n",
        "    return dnn\n",
        "\n",
        "model = make_DNN()\n",
        "print(model.summary())"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "make_DNN\n",
            "input shape: (None, 32, 4)\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_6 (Flatten)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 32)                4128      \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 7,329\n",
            "Trainable params: 7,329\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlVF0hR3j2UW"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "def do_cross_validation(X,y):\n",
        "    cv_scores = []\n",
        "    fold=0\n",
        "    mycallbacks = [ModelCheckpoint(\n",
        "        filepath=MODELPATH, save_best_only=True, \n",
        "        monitor='val_accuracy', mode='max')]   \n",
        "    splitter = KFold(n_splits=SPLITS)  # this does not shuffle\n",
        "    for train_index,valid_index in splitter.split(X):\n",
        "        if fold < FOLDS:\n",
        "            fold += 1\n",
        "            X_train=X[train_index] # inputs for training\n",
        "            y_train=y[train_index] # labels for training\n",
        "            X_valid=X[valid_index] # inputs for validation\n",
        "            y_valid=y[valid_index] # labels for validation\n",
        "            print(\"MODEL\")\n",
        "            # Call constructor on each CV. Else, continually improves the same model.\n",
        "            model = model = make_DNN()\n",
        "            print(\"FIT\")  # model.fit() implements learning\n",
        "            start_time=time.time()\n",
        "            history=model.fit(X_train, y_train, \n",
        "                    epochs=EPOCHS, \n",
        "                    verbose=1,  # ascii art while learning\n",
        "                    callbacks=mycallbacks,   # called at end of each epoch\n",
        "                    validation_data=(X_valid,y_valid))\n",
        "            end_time=time.time()\n",
        "            elapsed_time=(end_time-start_time)                        \n",
        "            print(\"Fold %d, %d epochs, %d sec\"%(fold,EPOCHS,elapsed_time))\n",
        "            # print(history.history.keys())  # all these keys will be shown in figure\n",
        "            pd.DataFrame(history.history).plot(figsize=(8,5))\n",
        "            plt.grid(True)\n",
        "            plt.gca().set_ylim(0,1) # any losses > 1 will be off the scale\n",
        "            plt.show()\n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ggt4EsSj2UY",
        "outputId": "278175e6-a693-45be-d659-5707c0239f68"
      },
      "source": [
        "do_cross_validation(X,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MODEL\n",
            "make_DNN\n",
            "input shape: (None, 32, 4)\n",
            "FIT\n",
            "Epoch 1/50\n",
            "1334/1334 [==============================] - 5s 4ms/step - loss: 0.6617 - accuracy: 0.5938 - val_loss: 0.5733 - val_accuracy: 0.7116\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 2/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.5692 - accuracy: 0.7119 - val_loss: 0.5672 - val_accuracy: 0.7132\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 3/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.5620 - accuracy: 0.7165 - val_loss: 0.5500 - val_accuracy: 0.7250\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 4/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.5407 - accuracy: 0.7285 - val_loss: 0.4966 - val_accuracy: 0.7594\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 5/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.4753 - accuracy: 0.7733 - val_loss: 0.4389 - val_accuracy: 0.7993\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 6/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.4185 - accuracy: 0.8099 - val_loss: 0.4022 - val_accuracy: 0.8182\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 7/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.3814 - accuracy: 0.8284 - val_loss: 0.3868 - val_accuracy: 0.8254\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 8/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.3717 - accuracy: 0.8314 - val_loss: 0.3798 - val_accuracy: 0.8290\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 9/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.3540 - accuracy: 0.8453 - val_loss: 0.3692 - val_accuracy: 0.8374\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 10/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.3427 - accuracy: 0.8478 - val_loss: 0.3616 - val_accuracy: 0.8415\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 11/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.3340 - accuracy: 0.8557 - val_loss: 0.3598 - val_accuracy: 0.8431\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 12/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.3292 - accuracy: 0.8592 - val_loss: 0.3645 - val_accuracy: 0.8423\n",
            "Epoch 13/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.3179 - accuracy: 0.8636 - val_loss: 0.3697 - val_accuracy: 0.8379\n",
            "Epoch 14/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.3135 - accuracy: 0.8639 - val_loss: 0.3431 - val_accuracy: 0.8526\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 15/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.3086 - accuracy: 0.8673 - val_loss: 0.3398 - val_accuracy: 0.8545\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 16/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.3006 - accuracy: 0.8695 - val_loss: 0.3385 - val_accuracy: 0.8536\n",
            "Epoch 17/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.2904 - accuracy: 0.8752 - val_loss: 0.3350 - val_accuracy: 0.8569\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 18/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.2895 - accuracy: 0.8781 - val_loss: 0.3351 - val_accuracy: 0.8537\n",
            "Epoch 19/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.2854 - accuracy: 0.8803 - val_loss: 0.3307 - val_accuracy: 0.8598\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 20/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.2825 - accuracy: 0.8814 - val_loss: 0.3334 - val_accuracy: 0.8552\n",
            "Epoch 21/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.2755 - accuracy: 0.8868 - val_loss: 0.3267 - val_accuracy: 0.8601\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 22/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.2743 - accuracy: 0.8852 - val_loss: 0.3502 - val_accuracy: 0.8505\n",
            "Epoch 23/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.2639 - accuracy: 0.8895 - val_loss: 0.3242 - val_accuracy: 0.8639\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 24/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.2653 - accuracy: 0.8884 - val_loss: 0.3350 - val_accuracy: 0.8591\n",
            "Epoch 25/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.2591 - accuracy: 0.8945 - val_loss: 0.3272 - val_accuracy: 0.8621\n",
            "Epoch 26/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.2514 - accuracy: 0.8930 - val_loss: 0.3197 - val_accuracy: 0.8648\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 27/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.2603 - accuracy: 0.8916 - val_loss: 0.3295 - val_accuracy: 0.8654\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 28/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.2577 - accuracy: 0.8937 - val_loss: 0.3218 - val_accuracy: 0.8674\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 29/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.2529 - accuracy: 0.8968 - val_loss: 0.3172 - val_accuracy: 0.8662\n",
            "Epoch 30/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.2433 - accuracy: 0.9007 - val_loss: 0.3168 - val_accuracy: 0.8688\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 31/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.2503 - accuracy: 0.8957 - val_loss: 0.3152 - val_accuracy: 0.8697\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 32/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.2488 - accuracy: 0.8971 - val_loss: 0.3190 - val_accuracy: 0.8663\n",
            "Epoch 33/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.2434 - accuracy: 0.8979 - val_loss: 0.3176 - val_accuracy: 0.8688\n",
            "Epoch 34/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.2433 - accuracy: 0.9003 - val_loss: 0.3155 - val_accuracy: 0.8699\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 35/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.2411 - accuracy: 0.8994 - val_loss: 0.3162 - val_accuracy: 0.8703\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 36/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.2337 - accuracy: 0.9052 - val_loss: 0.3145 - val_accuracy: 0.8690\n",
            "Epoch 37/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.2333 - accuracy: 0.9053 - val_loss: 0.3121 - val_accuracy: 0.8714\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 38/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.2384 - accuracy: 0.9027 - val_loss: 0.3215 - val_accuracy: 0.8660\n",
            "Epoch 39/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.2303 - accuracy: 0.9062 - val_loss: 0.3242 - val_accuracy: 0.8643\n",
            "Epoch 40/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.2360 - accuracy: 0.9020 - val_loss: 0.3173 - val_accuracy: 0.8705\n",
            "Epoch 41/50\n",
            "1225/1334 [==========================>...] - ETA: 0s - loss: 0.2280 - accuracy: 0.9072"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-jG1h5fj2Ua"
      },
      "source": [
        "from keras.models import load_model\n",
        "X,y = prepare_inputs_len_x_alphabet(pc_test,nc_test,ALPHABET)\n",
        "best_model=load_model(MODELPATH)\n",
        "scores = best_model.evaluate(X, y, verbose=0)\n",
        "print(\"The best model parameters were saved during cross-validation.\")\n",
        "print(\"Best was defined as maximum validation accuracy at end of any epoch.\")\n",
        "print(\"Now re-load the best model and test it on previously unseen data.\")\n",
        "print(\"Test on\",len(pc_test),\"PC seqs\")\n",
        "print(\"Test on\",len(nc_test),\"NC seqs\")\n",
        "print(\"%s: %.2f%%\" % (best_model.metrics_names[1], scores[1]*100))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VycUnmvUj2Ue"
      },
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "ns_probs = [0 for _ in range(len(y))]\n",
        "bm_probs = best_model.predict(X)\n",
        "ns_auc = roc_auc_score(y, ns_probs)\n",
        "bm_auc = roc_auc_score(y, bm_probs)\n",
        "ns_fpr, ns_tpr, _ = roc_curve(y, ns_probs)\n",
        "bm_fpr, bm_tpr, _ = roc_curve(y, bm_probs)\n",
        "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='Guess, auc=%.4f'%ns_auc)\n",
        "plt.plot(bm_fpr, bm_tpr, marker='.', label='Model, auc=%.4f'%bm_auc)\n",
        "plt.title('ROC')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "print(\"%s: %.2f%%\" %('AUC',bm_auc*100.0))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFMb6rGNj2Ug"
      },
      "source": [
        "t = time.time()\n",
        "time.strftime('%Y-%m-%d %H:%M:%S %Z', time.localtime(t))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-mEgDrQjUzF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}