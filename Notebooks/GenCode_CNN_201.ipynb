{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0asdcdunj2Tx"
   },
   "source": [
    "# PC/NC classification by CNN\n",
    "\n",
    "The convolutional neural network (CNN) was invented for image processing.\n",
    "We can use Conv1D layers for processing string sequences. \n",
    "How well does CNN work on human RNA as a binary classifier of protein-coding/non-coding?\n",
    "\n",
    "Assume user downloaded files from GenCode 38 [FTP](http://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_38/)\n",
    "to a subdirectory called data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "QP1VTRNQj2UO",
    "outputId": "9c0b236a-35ff-4112-d270-bc3f7220ff26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-01 10:48:47 EDT\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "def show_time():\n",
    "    t = time.time()\n",
    "    s = time.strftime('%Y-%m-%d %H:%M:%S %Z', time.localtime(t))\n",
    "    print(s)\n",
    "show_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PC_FILENAME='gencode.v38.pc_transcripts.fa.gz'\n",
    "NC_FILENAME='gencode.v38.lncRNA_transcripts.fa.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Nhz4GKonj2T_"
   },
   "outputs": [],
   "source": [
    "PC_SEQUENCES=20000   # how many protein-coding sequences\n",
    "NC_SEQUENCES=20000   # how many non-coding sequences\n",
    "PC_TESTS=1000\n",
    "NC_TESTS=1000\n",
    "BASES=1000            # how long is each sequence\n",
    "ALPHABET=4          # how many different letters are possible\n",
    "INPUT_SHAPE_2D = (BASES,ALPHABET,1) # Conv2D needs 3D inputs\n",
    "INPUT_SHAPE = (BASES,ALPHABET) # Conv1D needs 2D inputs\n",
    "FILTERS = 32   # how many different patterns the model looks for\n",
    "NEURONS = 16\n",
    "DROP_RATE = 0.2\n",
    "WIDTH = 3   # how wide each pattern is, in bases\n",
    "STRIDE_2D = (1,1)  # For Conv2D how far in each direction\n",
    "STRIDE = 1 # For Conv1D, how far between pattern matches, in bases\n",
    "EPOCHS=10  # how many times to train on all the data\n",
    "SPLITS=5  # SPLITS=3 means train on 2/3 and validate on 1/3 \n",
    "FOLDS=5  # train the model this many times (range 1 to SPLITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lr7q90rxj2UE",
    "outputId": "19cd66e8-b5c2-4a9d-a9a2-63f674b034f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoLab not working. On my PC, use relative paths.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import csv\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    IN_COLAB = True\n",
    "    print(\"On Google CoLab, mount cloud-local file, get our code from GitHub.\")\n",
    "    PATH='/content/drive/'\n",
    "    #drive.mount(PATH,force_remount=True)  # hardly ever need this\n",
    "    drive.mount(PATH)    # Google will require login credentials\n",
    "    DATAPATH=PATH+'My Drive/data/'  # must end in \"/\"\n",
    "    import requests\n",
    "    r = requests.get('https://raw.githubusercontent.com/ShepherdCode/Soars2021/master/SimTools/RNA_gen.py')\n",
    "    with open('RNA_gen.py', 'w') as f:\n",
    "        f.write(r.text)  \n",
    "    from RNA_gen import *\n",
    "    r = requests.get('https://raw.githubusercontent.com/ShepherdCode/Soars2021/master/SimTools/RNA_describe.py')\n",
    "    with open('RNA_describe.py', 'w') as f:\n",
    "        f.write(r.text)  \n",
    "    from RNA_describe import *\n",
    "    r = requests.get('https://raw.githubusercontent.com/ShepherdCode/Soars2021/master/SimTools/RNA_prep.py')\n",
    "    with open('RNA_prep.py', 'w') as f:\n",
    "        f.write(r.text)  \n",
    "    from RNA_prep import *\n",
    "except:\n",
    "    print(\"CoLab not working. On my PC, use relative paths.\")\n",
    "    IN_COLAB = False\n",
    "    DATAPATH='../data/'  # must end in \"/\"\n",
    "    sys.path.append(\"..\") # append parent dir in order to use sibling dirs\n",
    "    from SimTools.RNA_gen import *\n",
    "    from SimTools.RNA_describe import *\n",
    "    from SimTools.RNA_prep import *\n",
    "\n",
    "MODELPATH=\"BestModel\"  # saved on cloud instance and lost after logout\n",
    "#MODELPATH=DATAPATH+MODELPATH  # saved on Google Drive but requires login\n",
    "\n",
    "if not assert_imported_RNA_gen():\n",
    "    print(\"ERROR: Cannot use RNA_gen.\")\n",
    "if not assert_imported_RNA_prep():\n",
    "    print(\"ERROR: Cannot use RNA_prep.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "EGDXH8Uwj2UM"
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "#from zipfile import ZipFile\n",
    "import gzip\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats  # mode\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Embedding,Dropout\n",
    "from keras.layers import Conv1D,Conv2D\n",
    "from keras.layers import Flatten,MaxPooling1D,MaxPooling2D\n",
    "from keras.losses import BinaryCrossentropy\n",
    "# tf.keras.losses.BinaryCrossentropy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "mycmap = colors.ListedColormap(['red','blue'])  # list color for label 0 then 1\n",
    "np.set_printoptions(precision=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q0FetlLPj2UQ",
    "outputId": "c8305122-1080-480f-f66e-1ca69fedf3d3"
   },
   "outputs": [],
   "source": [
    "def load_gencode(filename,label):\n",
    "    DEFLINE='>'\n",
    "    DELIM='|'\n",
    "    EMPTY=''\n",
    "    labels=[]  # usually 1 for protein-coding or 0 for non-coding\n",
    "    seqs=[]    # usually string of ACGT\n",
    "    lens=[]    # sequence length\n",
    "    ids=[]     # GenCode transcript ID, always starts ENST\n",
    "    one_seq = EMPTY\n",
    "    one_id = None\n",
    "    # Use gzip 'r' mode to open file in read-only mode.\n",
    "    # Use gzip 't' mode to read each line of text as type string.\n",
    "    with gzip.open (filename,'rt') as infile:\n",
    "        for line in infile:\n",
    "            if line[0]==DEFLINE:\n",
    "                # Save the previous sequence if one exists.\n",
    "                if not one_seq == EMPTY:\n",
    "                    labels.append(label)\n",
    "                    seqs.append(one_seq)\n",
    "                    lens.append(len(one_seq))\n",
    "                    ids.append(one_id)\n",
    "                # Get ready to read the next sequence. \n",
    "                # Parse a GenCode defline that is formatted like this:\n",
    "                # >transcript_ID|gene_ID|other_fields other_info|other_info\n",
    "                one_id = line[1:].split(DELIM)[0]\n",
    "                one_seq = EMPTY\n",
    "            else:\n",
    "                # Continue loading sequence lines till next defline.\n",
    "                additional = line.rstrip()\n",
    "                one_seq = one_seq + additional\n",
    "        # Don't forget to save the last sequence after end-of-file.\n",
    "        if not one_seq == EMPTY:\n",
    "            labels.append(label)\n",
    "            seqs.append(one_seq)\n",
    "            lens.append(len(one_seq))\n",
    "            ids.append(one_id)\n",
    "\n",
    "    df1=pd.DataFrame(ids,columns=['tid'])\n",
    "    df2=pd.DataFrame(labels,columns=['class'])\n",
    "    df3=pd.DataFrame(seqs,columns=['sequence'])\n",
    "    df4=pd.DataFrame(lens,columns=['seqlen'])\n",
    "    df=pd.concat((df1,df2,df3,df4),axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-01 10:52:31 EDT\n",
      "PC seqs loaded: 106143\n",
      "2021-06-01 10:52:37 EDT\n",
      "NC seqs loaded: 48752\n",
      "2021-06-01 10:52:38 EDT\n"
     ]
    }
   ],
   "source": [
    "PC_FULLPATH=DATAPATH+PC_FILENAME\n",
    "NC_FULLPATH=DATAPATH+NC_FILENAME\n",
    "show_time()\n",
    "pcdf=load_gencode(PC_FULLPATH,1)\n",
    "print(\"PC seqs loaded:\",len(pcdf))\n",
    "show_time()\n",
    "ncdf=load_gencode(NC_FULLPATH,0)\n",
    "print(\"NC seqs loaded:\",len(ncdf))\n",
    "show_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO: set aside a 10% test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CIpTrnH6j2US",
    "outputId": "5c847e21-17a3-4a37-b6b2-24ecb9a53d93"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-2d2070a80c5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Use code from our SimTools library.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_inputs_len_x_alphabet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpcdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mncdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mALPHABET\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# shuffles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Data ready.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Source/Soars2021/SimTools/RNA_prep.py\u001b[0m in \u001b[0;36mprepare_inputs_len_x_alphabet\u001b[0;34m(pc_seqs, nc_seqs, alphabet_size, with_shuffle)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# TO DO: eliminate alphabet_size and hard code the 4?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnc_seqs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpc_seqs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mseq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnc_seqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# TO DO: error on empty or non-uniform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mX_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malphabet_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "# Use code from our SimTools library.\n",
    "X,y = prepare_inputs_len_x_alphabet(pcdf,ncdf,ALPHABET) # shuffles\n",
    "print(\"Data ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7NvrVU8ij2UU",
    "outputId": "dd01d853-6791-4913-b12d-0e82f4041a9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make_DNN\n",
      "input shape: (1000, 4)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 1000, 32)          416       \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 1000, 32)          3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 500, 32)           3104      \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 500, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 250, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8000)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                128016    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 137,761\n",
      "Trainable params: 137,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def make_DNN():\n",
    "    print(\"make_DNN\")\n",
    "    print(\"input shape:\",INPUT_SHAPE)\n",
    "    dnn = Sequential()\n",
    "    #dnn.add(Embedding(input_dim=INPUT_SHAPE,output_dim=INPUT_SHAPE)) \n",
    "    dnn.add(Conv1D(filters=FILTERS,kernel_size=WIDTH,strides=STRIDE,padding=\"same\",\n",
    "            input_shape=INPUT_SHAPE))\n",
    "    dnn.add(Conv1D(filters=FILTERS,kernel_size=WIDTH,strides=STRIDE,padding=\"same\"))\n",
    "    dnn.add(MaxPooling1D())\n",
    "    dnn.add(Conv1D(filters=FILTERS,kernel_size=WIDTH,strides=STRIDE,padding=\"same\"))\n",
    "    dnn.add(Conv1D(filters=FILTERS,kernel_size=WIDTH,strides=STRIDE,padding=\"same\"))\n",
    "    dnn.add(MaxPooling1D())\n",
    "    dnn.add(Flatten())\n",
    "    dnn.add(Dense(NEURONS,activation=\"sigmoid\",dtype=np.float32))   \n",
    "    dnn.add(Dropout(DROP_RATE))\n",
    "    dnn.add(Dense(1,activation=\"sigmoid\",dtype=np.float32))   \n",
    "    dnn.compile(optimizer='adam',\n",
    "                loss=BinaryCrossentropy(from_logits=False),\n",
    "                metrics=['accuracy'])   # add to default metrics=loss\n",
    "    dnn.build(input_shape=INPUT_SHAPE)\n",
    "    #ln_rate = tf.keras.optimizers.Adam(learning_rate = LN_RATE)\n",
    "    #bc=tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "    #model.compile(loss=bc, optimizer=ln_rate, metrics=[\"accuracy\"])\n",
    "    return dnn\n",
    "model = make_DNN()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "nlVF0hR3j2UW"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "def do_cross_validation(X,y):\n",
    "    cv_scores = []\n",
    "    fold=0\n",
    "    mycallbacks = [ModelCheckpoint(\n",
    "        filepath=MODELPATH, save_best_only=True, \n",
    "        monitor='val_accuracy', mode='max')]   \n",
    "    splitter = KFold(n_splits=SPLITS)  # this does not shuffle\n",
    "    for train_index,valid_index in splitter.split(X):\n",
    "        if fold < FOLDS:\n",
    "            fold += 1\n",
    "            X_train=X[train_index] # inputs for training\n",
    "            y_train=y[train_index] # labels for training\n",
    "            X_valid=X[valid_index] # inputs for validation\n",
    "            y_valid=y[valid_index] # labels for validation\n",
    "            print(\"MODEL\")\n",
    "            # Call constructor on each CV. Else, continually improves the same model.\n",
    "            model = model = make_DNN()\n",
    "            print(\"FIT\")  # model.fit() implements learning\n",
    "            start_time=time.time()\n",
    "            history=model.fit(X_train, y_train, \n",
    "                    epochs=EPOCHS, \n",
    "                    verbose=1,  # ascii art while learning\n",
    "                    callbacks=mycallbacks,   # called at end of each epoch\n",
    "                    validation_data=(X_valid,y_valid))\n",
    "            end_time=time.time()\n",
    "            elapsed_time=(end_time-start_time)                        \n",
    "            print(\"Fold %d, %d epochs, %d sec\"%(fold,EPOCHS,elapsed_time))\n",
    "            # print(history.history.keys())  # all these keys will be shown in figure\n",
    "            pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "            plt.grid(True)\n",
    "            plt.gca().set_ylim(0,1) # any losses > 1 will be off the scale\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9Ggt4EsSj2UY",
    "outputId": "488a4de9-d043-4542-e75a-130c29c80773"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-aadbbc682a25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdo_cross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "do_cross_validation(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e-jG1h5fj2Ua",
    "outputId": "8a4e57b5-c379-48c8-e0df-9cbfc828d46b"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "pc_sim.set_reproducible(True)\n",
    "nc_sim.set_reproducible(True)\n",
    "pc_test = pc_sim.get_sequences(PC_TESTS)\n",
    "nc_test = nc_sim.get_sequences(NC_TESTS)\n",
    "X,y = prepare_inputs_len_x_alphabet(pc_test,nc_test,ALPHABET)\n",
    "best_model=load_model(MODELPATH)\n",
    "scores = best_model.evaluate(X, y, verbose=0)\n",
    "print(\"The best model parameters were saved during cross-validation.\")\n",
    "print(\"Best was defined as maximum validation accuracy at end of any epoch.\")\n",
    "print(\"Now re-load the best model and test it on previously unseen data.\")\n",
    "print(\"Test on\",len(pc_test),\"PC seqs\")\n",
    "print(\"Test on\",len(nc_test),\"NC seqs\")\n",
    "print(\"%s: %.2f%%\" % (best_model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "VycUnmvUj2Ue",
    "outputId": "b26172ab-07c5-4ce9-9402-12921abf1778"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "ns_probs = [0 for _ in range(len(y))]\n",
    "bm_probs = best_model.predict(X)\n",
    "ns_auc = roc_auc_score(y, ns_probs)\n",
    "bm_auc = roc_auc_score(y, bm_probs)\n",
    "ns_fpr, ns_tpr, _ = roc_curve(y, ns_probs)\n",
    "bm_fpr, bm_tpr, _ = roc_curve(y, bm_probs)\n",
    "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='Guess, auc=%.4f'%ns_auc)\n",
    "plt.plot(bm_fpr, bm_tpr, marker='.', label='Model, auc=%.4f'%bm_auc)\n",
    "plt.title('ROC')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(\"%s: %.2f%%\" %('AUC',bm_auc*100.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ORF_CNN_105.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
