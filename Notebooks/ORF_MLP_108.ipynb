{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ORF_MLP_108.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0asdcdunj2Tx"
      },
      "source": [
        "# ORF recognition by MLP\n",
        "\n",
        "So far, no MLP has exceeded 50% accurcy on any ORF problem.\n",
        "Here, try a variety of things.\n",
        "\n",
        "RNA length 16, CDS length 8.\n",
        "No luck with 32 neurons or 64 neurons\n",
        "Instead of sigmoid, tried tanh and relu.\n",
        "Instead of 4 layers, tried 1.\n",
        "RNA length 12, CDS length 6.\n",
        "2 layers of 32 neurons, sigmoid.\n",
        "Even 512 neurons, rectangular or triangular, didn't work.\n",
        "Move INPUT_SHAPE from compile() to first layer parameter. \n",
        "\n",
        "This works: All PC='AC'*, all NC='GT'*. \n",
        "100% accurate on one epoch with 2 layers of 12 neurons.\n",
        "\n",
        "Nothing works! Now suspect the data preparation is incorrect. Try trivializing the problem by always adding ATG or TAG."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "QP1VTRNQj2UO",
        "outputId": "33ed53ed-73ef-4e11-e18a-ec247304b156"
      },
      "source": [
        "import time \n",
        "t = time.time()\n",
        "time.strftime('%Y-%m-%d %H:%M:%S %Z', time.localtime(t))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2021-06-23 17:58:26 UTC'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nhz4GKonj2T_"
      },
      "source": [
        "PC_SEQUENCES=32000   # how many protein-coding sequences\n",
        "NC_SEQUENCES=32000   # how many non-coding sequences\n",
        "PC_TESTS=1000\n",
        "NC_TESTS=1000\n",
        "RNA_LEN=32            # how long is each sequence\n",
        "CDS_LEN=16           # min CDS len to be coding\n",
        "ALPHABET=4          # how many different letters are possible\n",
        "INPUT_SHAPE_2D = (RNA_LEN,ALPHABET,1) # Conv2D needs 3D inputs\n",
        "INPUT_SHAPE = (None,RNA_LEN,ALPHABET) # MLP requires batch size None\n",
        "FILTERS = 16   # how many different patterns the model looks for\n",
        "CELLS = 16\n",
        "NEURONS = 16\n",
        "DROP_RATE = 0.4\n",
        "WIDTH = 3   # how wide each pattern is, in bases\n",
        "STRIDE_2D = (1,1)  # For Conv2D how far in each direction\n",
        "STRIDE = 1 # For Conv1D, how far between pattern matches, in bases\n",
        "EPOCHS=50  # how many times to train on all the data\n",
        "SPLITS=3  # SPLITS=3 means train on 2/3 and validate on 1/3 \n",
        "FOLDS=3  # train the model this many times (range 1 to SPLITS)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lr7q90rxj2UE",
        "outputId": "47344528-6aec-4fd0-8a70-3ead38dc0218"
      },
      "source": [
        "import sys\n",
        "IN_COLAB = False\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    pass\n",
        "if IN_COLAB:\n",
        "    print(\"On Google CoLab, mount cloud-local file, get our code from GitHub.\")\n",
        "    PATH='/content/drive/'\n",
        "    #drive.mount(PATH,force_remount=True)  # hardly ever need this\n",
        "    #drive.mount(PATH)    # Google will require login credentials\n",
        "    DATAPATH=PATH+'My Drive/data/'  # must end in \"/\"\n",
        "    import requests\n",
        "    r = requests.get('https://raw.githubusercontent.com/ShepherdCode/Soars2021/master/SimTools/RNA_describe.py')\n",
        "    with open('RNA_describe.py', 'w') as f:\n",
        "        f.write(r.text)  \n",
        "    from RNA_describe import ORF_counter\n",
        "    from RNA_describe import Random_Base_Oracle\n",
        "    r = requests.get('https://raw.githubusercontent.com/ShepherdCode/Soars2021/master/SimTools/RNA_prep.py')\n",
        "    with open('RNA_prep.py', 'w') as f:\n",
        "        f.write(r.text)  \n",
        "    from RNA_prep import prepare_inputs_len_x_alphabet\n",
        "else:\n",
        "        print(\"CoLab not working. On my PC, use relative paths.\")\n",
        "        DATAPATH='data/'  # must end in \"/\"\n",
        "        sys.path.append(\"..\") # append parent dir in order to use sibling dirs\n",
        "        from SimTools.RNA_describe import ORF_counter,Random_Base_Oracle\n",
        "        from SimTools.RNA_prep import prepare_inputs_len_x_alphabet\n",
        "\n",
        "MODELPATH=\"BestModel\"  # saved on cloud instance and lost after logout\n",
        "#MODELPATH=DATAPATH+MODELPATH  # saved on Google Drive but requires login\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "On Google CoLab, mount cloud-local file, get our code from GitHub.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGDXH8Uwj2UM"
      },
      "source": [
        "from os import listdir\n",
        "import csv\n",
        "from zipfile import ZipFile\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats  # mode\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Embedding,Dropout\n",
        "from keras.layers import Conv1D,Conv2D\n",
        "from keras.layers import GRU,LSTM\n",
        "from keras.layers import Flatten,TimeDistributed\n",
        "from keras.layers import MaxPooling1D,MaxPooling2D\n",
        "from keras.losses import BinaryCrossentropy\n",
        "# tf.keras.losses.BinaryCrossentropy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import colors\n",
        "mycmap = colors.ListedColormap(['red','blue'])  # list color for label 0 then 1\n",
        "np.set_printoptions(precision=2)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUOG_jEvGtOm",
        "outputId": "ada1592c-078d-4888-fb7c-efb53ada1b17"
      },
      "source": [
        "rbo=Random_Base_Oracle(RNA_LEN,True)\n",
        "pc_all,nc_all = rbo.get_partitioned_sequences(CDS_LEN,10) # just testing\n",
        "pc_all,nc_all = rbo.get_partitioned_sequences(CDS_LEN,PC_SEQUENCES+PC_TESTS)\n",
        "print(\"Use\",len(pc_all),\"PC seqs\")\n",
        "print(\"Use\",len(nc_all),\"NC seqs\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "It took 33 trials to reach 10 per class.\n",
            "It took 143442 trials to reach 33000 per class.\n",
            "Use 33000 PC seqs\n",
            "Use 33000 NC seqs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIMcOB-9yEV6"
      },
      "source": [
        "# Make the problem super easy!\n",
        "def trivialize_sequences(list_of_seq,option):\n",
        "    num_seq = len(list_of_seq)\n",
        "    for i in range(0,num_seq):\n",
        "        seq = list_of_seq[i]\n",
        "        if option==0:\n",
        "            list_of_seq[i] = 'TTTTTT'+seq[6:]\n",
        "        else:\n",
        "            list_of_seq[i] = 'AAAAAA'+seq[6:]\n",
        "\n",
        "if False:\n",
        "    print(\"Trivialize...\")\n",
        "    trivialize_sequences(pc_all,1)\n",
        "    print(\"Trivial PC:\",pc_all[:5])\n",
        "    print(\"Trivial PC:\",pc_all[-5:])\n",
        "    trivialize_sequences(nc_all,0)\n",
        "    print(\"Trivial NC:\",nc_all[:5])\n",
        "    print(\"Trivial NC:\",nc_all[-5:])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-BmSXi2jUyl",
        "outputId": "8e20b96e-a557-4421-80c0-5365a688840a"
      },
      "source": [
        "# Describe the sequences\n",
        "def describe_sequences(list_of_seq):\n",
        "    oc = ORF_counter()\n",
        "    num_seq = len(list_of_seq)\n",
        "    rna_lens = np.zeros(num_seq)\n",
        "    orf_lens = np.zeros(num_seq)\n",
        "    for i in range(0,num_seq):\n",
        "        rna_len = len(list_of_seq[i])\n",
        "        rna_lens[i] = rna_len\n",
        "        oc.set_sequence(list_of_seq[i])\n",
        "        orf_len = oc.get_max_orf_len()\n",
        "        orf_lens[i] = orf_len\n",
        "    print (\"Average RNA length:\",rna_lens.mean())\n",
        "    print (\"Average ORF length:\",orf_lens.mean())\n",
        "    \n",
        "print(\"Simulated sequences prior to adjustment:\")\n",
        "print(\"PC seqs\")\n",
        "describe_sequences(pc_all)\n",
        "print(\"NC seqs\")\n",
        "describe_sequences(nc_all)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Simulated sequences prior to adjustment:\n",
            "PC seqs\n",
            "Average RNA length: 32.0\n",
            "Average ORF length: 19.671818181818182\n",
            "NC seqs\n",
            "Average RNA length: 32.0\n",
            "Average ORF length: 2.855909090909091\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iP1y7-J3jUys"
      },
      "source": [
        "pc_train=pc_all[:PC_SEQUENCES]\n",
        "nc_train=nc_all[:NC_SEQUENCES]\n",
        "pc_test=pc_all[PC_SEQUENCES:]\n",
        "nc_test=nc_all[NC_SEQUENCES:]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIpTrnH6j2US",
        "outputId": "7512e27f-1ea2-4f43-940c-07964182853d"
      },
      "source": [
        "# Use code from our SimTools library.\n",
        "X,y = prepare_inputs_len_x_alphabet(pc_train,nc_train,ALPHABET) # shuffles\n",
        "print(\"Data ready.\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data ready.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVhr6K95qil7",
        "outputId": "6408b64d-e15b-44c2-9257-f8e62cf1d577"
      },
      "source": [
        "print(len(X),\"sequences total\")\n",
        "print(len(X[0]),\"bases/sequence\")\n",
        "print(len(X[0][0]),\"dimensions/base\")\n",
        "#print(X[0])\n",
        "print(type(X[0]))\n",
        "print(X[0].shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "64000 sequences total\n",
            "32 bases/sequence\n",
            "4 dimensions/base\n",
            "<class 'numpy.ndarray'>\n",
            "(32, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NvrVU8ij2UU",
        "outputId": "17fe1f2d-2356-4b1b-dceb-bf166d97c85b"
      },
      "source": [
        "def make_DNN():\n",
        "    print(\"make_DNN\")\n",
        "    print(\"input shape:\",INPUT_SHAPE)\n",
        "    dnn = Sequential()\n",
        "    dnn.add(Flatten())\n",
        "    dnn.add(Dense(NEURONS,activation=\"sigmoid\",dtype=np.float32,\n",
        "                 input_shape=INPUT_SHAPE ))   \n",
        "    dnn.add(Dense(NEURONS,activation=\"sigmoid\",dtype=np.float32))   \n",
        "    dnn.add(Dense(NEURONS,activation=\"sigmoid\",dtype=np.float32))   \n",
        "    dnn.add(Dense(NEURONS,activation=\"sigmoid\",dtype=np.float32))   \n",
        "    #dnn.add(Dropout(DROP_RATE))\n",
        "    dnn.add(Dense(1,activation=\"sigmoid\",dtype=np.float32))   \n",
        "    dnn.compile(optimizer='adam',\n",
        "                loss=BinaryCrossentropy(from_logits=False),\n",
        "                metrics=['accuracy'])   # add to default metrics=loss\n",
        "    dnn.build(input_shape=INPUT_SHAPE) \n",
        "    #dnn.build() \n",
        "    #ln_rate = tf.keras.optimizers.Adam(learning_rate = LN_RATE)\n",
        "    #bc=tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "    #model.compile(loss=bc, optimizer=ln_rate, metrics=[\"accuracy\"])\n",
        "    return dnn\n",
        "\n",
        "model = make_DNN()\n",
        "print(model.summary())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "make_DNN\n",
            "input shape: (None, 32, 4)\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 16)                2064      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 2,897\n",
            "Trainable params: 2,897\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlVF0hR3j2UW"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "def do_cross_validation(X,y):\n",
        "    cv_scores = []\n",
        "    fold=0\n",
        "    mycallbacks = [ModelCheckpoint(\n",
        "        filepath=MODELPATH, save_best_only=True, \n",
        "        monitor='val_accuracy', mode='max')]   \n",
        "    splitter = KFold(n_splits=SPLITS)  # this does not shuffle\n",
        "    for train_index,valid_index in splitter.split(X):\n",
        "        if fold < FOLDS:\n",
        "            fold += 1\n",
        "            X_train=X[train_index] # inputs for training\n",
        "            y_train=y[train_index] # labels for training\n",
        "            X_valid=X[valid_index] # inputs for validation\n",
        "            y_valid=y[valid_index] # labels for validation\n",
        "            print(\"MODEL\")\n",
        "            # Call constructor on each CV. Else, continually improves the same model.\n",
        "            model = model = make_DNN()\n",
        "            print(\"FIT\")  # model.fit() implements learning\n",
        "            start_time=time.time()\n",
        "            history=model.fit(X_train, y_train, \n",
        "                    epochs=EPOCHS, \n",
        "                    verbose=1,  # ascii art while learning\n",
        "                    callbacks=mycallbacks,   # called at end of each epoch\n",
        "                    validation_data=(X_valid,y_valid))\n",
        "            end_time=time.time()\n",
        "            elapsed_time=(end_time-start_time)                        \n",
        "            print(\"Fold %d, %d epochs, %d sec\"%(fold,EPOCHS,elapsed_time))\n",
        "            # print(history.history.keys())  # all these keys will be shown in figure\n",
        "            pd.DataFrame(history.history).plot(figsize=(8,5))\n",
        "            plt.grid(True)\n",
        "            plt.gca().set_ylim(0,1) # any losses > 1 will be off the scale\n",
        "            plt.show()\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ggt4EsSj2UY",
        "outputId": "c9396107-2387-4b62-e153-44432d6e0c77"
      },
      "source": [
        "do_cross_validation(X,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MODEL\n",
            "make_DNN\n",
            "input shape: (None, 32, 4)\n",
            "FIT\n",
            "Epoch 1/50\n",
            "1334/1334 [==============================] - 17s 3ms/step - loss: 0.6601 - accuracy: 0.5969 - val_loss: 0.5797 - val_accuracy: 0.7062\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 2/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.5746 - accuracy: 0.7103 - val_loss: 0.5760 - val_accuracy: 0.7054\n",
            "Epoch 3/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.5699 - accuracy: 0.7116 - val_loss: 0.5677 - val_accuracy: 0.7094\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 4/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.5573 - accuracy: 0.7184 - val_loss: 0.5464 - val_accuracy: 0.7226\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 5/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.5256 - accuracy: 0.7403 - val_loss: 0.4922 - val_accuracy: 0.7616\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 6/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.4707 - accuracy: 0.7817 - val_loss: 0.4393 - val_accuracy: 0.7960\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 7/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.4229 - accuracy: 0.8049 - val_loss: 0.4217 - val_accuracy: 0.8052\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 8/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.4019 - accuracy: 0.8163 - val_loss: 0.4113 - val_accuracy: 0.8100\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 9/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.3925 - accuracy: 0.8225 - val_loss: 0.3954 - val_accuracy: 0.8208\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 10/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.3811 - accuracy: 0.8286 - val_loss: 0.3889 - val_accuracy: 0.8241\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 11/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.3723 - accuracy: 0.8298 - val_loss: 0.3853 - val_accuracy: 0.8252\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 12/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.3650 - accuracy: 0.8370 - val_loss: 0.3893 - val_accuracy: 0.8223\n",
            "Epoch 13/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.3527 - accuracy: 0.8431 - val_loss: 0.3807 - val_accuracy: 0.8287\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 14/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.3503 - accuracy: 0.8434 - val_loss: 0.3759 - val_accuracy: 0.8301\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 15/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.3474 - accuracy: 0.8455 - val_loss: 0.3745 - val_accuracy: 0.8305\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 16/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.3452 - accuracy: 0.8468 - val_loss: 0.3739 - val_accuracy: 0.8307\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 17/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.3422 - accuracy: 0.8476 - val_loss: 0.3678 - val_accuracy: 0.8339\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 18/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.3350 - accuracy: 0.8510 - val_loss: 0.3707 - val_accuracy: 0.8327\n",
            "Epoch 19/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.3375 - accuracy: 0.8517 - val_loss: 0.3633 - val_accuracy: 0.8349\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 20/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.3280 - accuracy: 0.8556 - val_loss: 0.3603 - val_accuracy: 0.8373\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 21/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.3247 - accuracy: 0.8551 - val_loss: 0.3578 - val_accuracy: 0.8379\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 22/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.3234 - accuracy: 0.8592 - val_loss: 0.3694 - val_accuracy: 0.8313\n",
            "Epoch 23/50\n",
            "1334/1334 [==============================] - 4s 3ms/step - loss: 0.3172 - accuracy: 0.8610 - val_loss: 0.3570 - val_accuracy: 0.8393\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 24/50\n",
            "1327/1334 [============================>.] - ETA: 0s - loss: 0.3190 - accuracy: 0.8611"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-jG1h5fj2Ua"
      },
      "source": [
        "from keras.models import load_model\n",
        "X,y = prepare_inputs_len_x_alphabet(pc_test,nc_test,ALPHABET)\n",
        "best_model=load_model(MODELPATH)\n",
        "scores = best_model.evaluate(X, y, verbose=0)\n",
        "print(\"The best model parameters were saved during cross-validation.\")\n",
        "print(\"Best was defined as maximum validation accuracy at end of any epoch.\")\n",
        "print(\"Now re-load the best model and test it on previously unseen data.\")\n",
        "print(\"Test on\",len(pc_test),\"PC seqs\")\n",
        "print(\"Test on\",len(nc_test),\"NC seqs\")\n",
        "print(\"%s: %.2f%%\" % (best_model.metrics_names[1], scores[1]*100))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VycUnmvUj2Ue"
      },
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "ns_probs = [0 for _ in range(len(y))]\n",
        "bm_probs = best_model.predict(X)\n",
        "ns_auc = roc_auc_score(y, ns_probs)\n",
        "bm_auc = roc_auc_score(y, bm_probs)\n",
        "ns_fpr, ns_tpr, _ = roc_curve(y, ns_probs)\n",
        "bm_fpr, bm_tpr, _ = roc_curve(y, bm_probs)\n",
        "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='Guess, auc=%.4f'%ns_auc)\n",
        "plt.plot(bm_fpr, bm_tpr, marker='.', label='Model, auc=%.4f'%bm_auc)\n",
        "plt.title('ROC')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "print(\"%s: %.2f%%\" %('AUC',bm_auc*100.0))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFMb6rGNj2Ug"
      },
      "source": [
        "t = time.time()\n",
        "time.strftime('%Y-%m-%d %H:%M:%S %Z', time.localtime(t))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-mEgDrQjUzF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}