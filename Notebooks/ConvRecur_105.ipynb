{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0asdcdunj2Tx"
   },
   "source": [
    "# ORF recognition by Convolutional/Recurrent\n",
    "\n",
    "Test CNN+LSTM on simulated RNA of length 100. \n",
    "\n",
    "Use new simulator class called Random_Base_Oracle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "QP1VTRNQj2UO",
    "outputId": "66e8237a-ea6d-402a-a622-1991790fa346"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021-06-21 08:35:47 EDT'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time \n",
    "t = time.time()\n",
    "time.strftime('%Y-%m-%d %H:%M:%S %Z', time.localtime(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Nhz4GKonj2T_"
   },
   "outputs": [],
   "source": [
    "PC_SEQUENCES=32000   # how many protein-coding sequences\n",
    "NC_SEQUENCES=32000   # how many non-coding sequences\n",
    "PC_TESTS=1000\n",
    "NC_TESTS=1000\n",
    "RNA_LEN=100            # how long is each sequence\n",
    "CDS_LEN=60            # min CDS len to be coding\n",
    "ALPHABET=4          # how many different letters are possible\n",
    "INPUT_SHAPE_2D = (RNA_LEN,ALPHABET,1) # Conv2D needs 3D inputs\n",
    "INPUT_SHAPE = (RNA_LEN,ALPHABET) # Conv1D needs 2D inputs\n",
    "FILTERS = 32   # how many different patterns the model looks for\n",
    "CELLS = 32\n",
    "NEURONS = 32\n",
    "DROP_RATE = 0.4\n",
    "WIDTH = 3   # how wide each pattern is, in bases\n",
    "STRIDE_2D = (1,1)  # For Conv2D how far in each direction\n",
    "STRIDE = 1 # For Conv1D, how far between pattern matches, in bases\n",
    "EPOCHS=100  # how many times to train on all the data\n",
    "SPLITS=3  # SPLITS=3 means train on 2/3 and validate on 1/3 \n",
    "FOLDS=3  # train the model this many times (range 1 to SPLITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lr7q90rxj2UE",
    "outputId": "9a0b1438-4adb-4bba-99cc-bf9d79b044e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoLab not working. On my PC, use relative paths.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    IN_COLAB = True\n",
    "    print(\"On Google CoLab, mount cloud-local file, get our code from GitHub.\")\n",
    "    PATH='/content/drive/'\n",
    "    #drive.mount(PATH,force_remount=True)  # hardly ever need this\n",
    "    #drive.mount(PATH)    # Google will require login credentials\n",
    "    DATAPATH=PATH+'My Drive/data/'  # must end in \"/\"\n",
    "    import requests\n",
    "    r = requests.get('https://raw.githubusercontent.com/ShepherdCode/Soars2021/master/SimTools/RNA_describe.py')\n",
    "    with open('RNA_describe.py', 'w') as f:\n",
    "        f.write(r.text)  \n",
    "    from RNA_describe import ORF_counter,Random_Base_Oracle\n",
    "    r = requests.get('https://raw.githubusercontent.com/ShepherdCode/Soars2021/master/SimTools/RNA_prep.py')\n",
    "    with open('RNA_prep.py', 'w') as f:\n",
    "        f.write(r.text)  \n",
    "    from RNA_prep import prepare_inputs_len_x_alphabet\n",
    "except:\n",
    "    print(\"CoLab not working. On my PC, use relative paths.\")\n",
    "    IN_COLAB = False\n",
    "    DATAPATH='data/'  # must end in \"/\"\n",
    "    sys.path.append(\"..\") # append parent dir in order to use sibling dirs\n",
    "    from SimTools.RNA_describe import ORF_counter,Random_Base_Oracle\n",
    "    from SimTools.RNA_prep import prepare_inputs_len_x_alphabet\n",
    "\n",
    "MODELPATH=\"BestModel\"  # saved on cloud instance and lost after logout\n",
    "#MODELPATH=DATAPATH+MODELPATH  # saved on Google Drive but requires login\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "EGDXH8Uwj2UM"
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import csv\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats  # mode\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Embedding,Dropout\n",
    "from keras.layers import Conv1D,Conv2D\n",
    "from keras.layers import GRU,LSTM\n",
    "from keras.layers import Flatten,TimeDistributed\n",
    "from keras.layers import MaxPooling1D,MaxPooling2D\n",
    "from keras.losses import BinaryCrossentropy\n",
    "# tf.keras.losses.BinaryCrossentropy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "mycmap = colors.ListedColormap(['red','blue'])  # list color for label 0 then 1\n",
    "np.set_printoptions(precision=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CUOG_jEvGtOm",
    "outputId": "32a5d919-32dd-4ab7-8401-860392bfaf9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 47 trials to reach 10 per class.\n",
      "It took 158823 trials to reach 33000 per class.\n",
      "Use 33000 PC seqs\n",
      "Use 33000 NC seqs\n"
     ]
    }
   ],
   "source": [
    "rbo=Random_Base_Oracle(RNA_LEN,True)\n",
    "pc_all,nc_all = rbo.get_partitioned_sequences(CDS_LEN,10) # just testing\n",
    "pc_all,nc_all = rbo.get_partitioned_sequences(CDS_LEN,PC_SEQUENCES+PC_TESTS)\n",
    "print(\"Use\",len(pc_all),\"PC seqs\")\n",
    "print(\"Use\",len(nc_all),\"NC seqs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q-BmSXi2jUyl",
    "outputId": "7bcbe52e-1eff-448a-e0d5-e51ca2071d34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated sequences prior to adjustment:\n",
      "PC seqs\n",
      "Average RNA length: 100.0\n",
      "Average ORF length: 67.53209090909091\n",
      "NC seqs\n",
      "Average RNA length: 100.0\n",
      "Average ORF length: 22.178272727272727\n"
     ]
    }
   ],
   "source": [
    "# Describe the sequences\n",
    "def describe_sequences(list_of_seq):\n",
    "    oc = ORF_counter()\n",
    "    num_seq = len(list_of_seq)\n",
    "    rna_lens = np.zeros(num_seq)\n",
    "    orf_lens = np.zeros(num_seq)\n",
    "    for i in range(0,num_seq):\n",
    "        rna_len = len(list_of_seq[i])\n",
    "        rna_lens[i] = rna_len\n",
    "        oc.set_sequence(list_of_seq[i])\n",
    "        orf_len = oc.get_max_orf_len()\n",
    "        orf_lens[i] = orf_len\n",
    "    print (\"Average RNA length:\",rna_lens.mean())\n",
    "    print (\"Average ORF length:\",orf_lens.mean())\n",
    "    \n",
    "print(\"Simulated sequences prior to adjustment:\")\n",
    "print(\"PC seqs\")\n",
    "describe_sequences(pc_all)\n",
    "print(\"NC seqs\")\n",
    "describe_sequences(nc_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "iP1y7-J3jUys"
   },
   "outputs": [],
   "source": [
    "pc_train=pc_all[:PC_SEQUENCES]\n",
    "nc_train=nc_all[:NC_SEQUENCES]\n",
    "pc_test=pc_all[PC_SEQUENCES:]\n",
    "nc_test=nc_all[NC_SEQUENCES:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CIpTrnH6j2US",
    "outputId": "331e8f23-2f8f-467e-b74f-141a131f0077"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data ready.\n"
     ]
    }
   ],
   "source": [
    "# Use code from our SimTools library.\n",
    "X,y = prepare_inputs_len_x_alphabet(pc_train,nc_train,ALPHABET) # shuffles\n",
    "print(\"Data ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7NvrVU8ij2UU",
    "outputId": "03f48bbb-ac8a-4ba4-b6da-2401800a50fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make_DNN\n",
      "input shape: (100, 4)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 100, 32)           416       \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 100, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 50, 32)            0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 50, 32)            8320      \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 21,249\n",
      "Trainable params: 21,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def make_DNN():\n",
    "    print(\"make_DNN\")\n",
    "    print(\"input shape:\",INPUT_SHAPE)\n",
    "    dnn = Sequential()\n",
    "    #dnn.add(Embedding(input_dim=INPUT_SHAPE,output_dim=INPUT_SHAPE)) \n",
    "    dnn.add(Conv1D(filters=FILTERS,kernel_size=WIDTH,strides=STRIDE,padding=\"same\",\n",
    "            input_shape=INPUT_SHAPE))\n",
    "    dnn.add(Conv1D(filters=FILTERS,kernel_size=WIDTH,strides=STRIDE,padding=\"same\"))\n",
    "    dnn.add(MaxPooling1D())\n",
    "    #dnn.add(Conv1D(filters=FILTERS,kernel_size=WIDTH,strides=STRIDE,padding=\"same\"))\n",
    "    #dnn.add(Conv1D(filters=FILTERS,kernel_size=WIDTH,strides=STRIDE,padding=\"same\"))\n",
    "    #dnn.add(MaxPooling1D())\n",
    "    #dnn.add(TimeDistributed(Flatten()))\n",
    "    dnn.add(LSTM(CELLS,return_sequences=True))\n",
    "    dnn.add(LSTM(CELLS,return_sequences=False))\n",
    "    dnn.add(Dense(NEURONS,activation=\"sigmoid\",dtype=np.float32))   \n",
    "    dnn.add(Dropout(DROP_RATE))\n",
    "    dnn.add(Dense(1,activation=\"sigmoid\",dtype=np.float32))   \n",
    "    dnn.compile(optimizer='adam',\n",
    "                loss=BinaryCrossentropy(from_logits=False),\n",
    "                metrics=['accuracy'])   # add to default metrics=loss\n",
    "    dnn.build(input_shape=INPUT_SHAPE)\n",
    "    #ln_rate = tf.keras.optimizers.Adam(learning_rate = LN_RATE)\n",
    "    #bc=tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "    #model.compile(loss=bc, optimizer=ln_rate, metrics=[\"accuracy\"])\n",
    "    return dnn\n",
    "model = make_DNN()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "nlVF0hR3j2UW"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "def do_cross_validation(X,y):\n",
    "    cv_scores = []\n",
    "    fold=0\n",
    "    mycallbacks = [ModelCheckpoint(\n",
    "        filepath=MODELPATH, save_best_only=True, \n",
    "        monitor='val_accuracy', mode='max')]   \n",
    "    splitter = KFold(n_splits=SPLITS)  # this does not shuffle\n",
    "    for train_index,valid_index in splitter.split(X):\n",
    "        if fold < FOLDS:\n",
    "            fold += 1\n",
    "            X_train=X[train_index] # inputs for training\n",
    "            y_train=y[train_index] # labels for training\n",
    "            X_valid=X[valid_index] # inputs for validation\n",
    "            y_valid=y[valid_index] # labels for validation\n",
    "            print(\"MODEL\")\n",
    "            # Call constructor on each CV. Else, continually improves the same model.\n",
    "            model = model = make_DNN()\n",
    "            print(\"FIT\")  # model.fit() implements learning\n",
    "            start_time=time.time()\n",
    "            history=model.fit(X_train, y_train, \n",
    "                    epochs=EPOCHS, \n",
    "                    verbose=1,  # ascii art while learning\n",
    "                    callbacks=mycallbacks,   # called at end of each epoch\n",
    "                    validation_data=(X_valid,y_valid))\n",
    "            end_time=time.time()\n",
    "            elapsed_time=(end_time-start_time)                        \n",
    "            print(\"Fold %d, %d epochs, %d sec\"%(fold,EPOCHS,elapsed_time))\n",
    "            # print(history.history.keys())  # all these keys will be shown in figure\n",
    "            pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "            plt.grid(True)\n",
    "            plt.gca().set_ylim(0,1) # any losses > 1 will be off the scale\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9Ggt4EsSj2UY",
    "outputId": "896a474f-949e-45ae-fc18-37ec292efbef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL\n",
      "make_DNN\n",
      "input shape: (100, 4)\n",
      "FIT\n",
      "Epoch 1/100\n",
      " 507/1334 [==========>...................] - ETA: 56s - loss: 0.7055 - accuracy: 0.5049"
     ]
    }
   ],
   "source": [
    "do_cross_validation(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e-jG1h5fj2Ua",
    "outputId": "2b11cbb8-ef1b-48c5-825f-a4459d7386c8"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "X,y = prepare_inputs_len_x_alphabet(pc_test,nc_test,ALPHABET)\n",
    "best_model=load_model(MODELPATH)\n",
    "scores = best_model.evaluate(X, y, verbose=0)\n",
    "print(\"The best model parameters were saved during cross-validation.\")\n",
    "print(\"Best was defined as maximum validation accuracy at end of any epoch.\")\n",
    "print(\"Now re-load the best model and test it on previously unseen data.\")\n",
    "print(\"Test on\",len(pc_test),\"PC seqs\")\n",
    "print(\"Test on\",len(nc_test),\"NC seqs\")\n",
    "print(\"%s: %.2f%%\" % (best_model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "VycUnmvUj2Ue",
    "outputId": "d898116c-7a5d-4ad6-a7fd-66f04e454b15"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "ns_probs = [0 for _ in range(len(y))]\n",
    "bm_probs = best_model.predict(X)\n",
    "ns_auc = roc_auc_score(y, ns_probs)\n",
    "bm_auc = roc_auc_score(y, bm_probs)\n",
    "ns_fpr, ns_tpr, _ = roc_curve(y, ns_probs)\n",
    "bm_fpr, bm_tpr, _ = roc_curve(y, bm_probs)\n",
    "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='Guess, auc=%.4f'%ns_auc)\n",
    "plt.plot(bm_fpr, bm_tpr, marker='.', label='Model, auc=%.4f'%bm_auc)\n",
    "plt.title('ROC')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(\"%s: %.2f%%\" %('AUC',bm_auc*100.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "kFMb6rGNj2Ug",
    "outputId": "2ad2c675-4c7e-4bd5-f077-267b907ee79c"
   },
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "time.strftime('%Y-%m-%d %H:%M:%S %Z', time.localtime(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e-mEgDrQjUzF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ConvRecur_105.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
