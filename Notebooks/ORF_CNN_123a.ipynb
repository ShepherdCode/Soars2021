{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ORF_CNN_123a.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0asdcdunj2Tx"
      },
      "source": [
        "# ORF recognition by CNN\n",
        "\n",
        "Use variable number of bases between START and STOP. Thus, ncRNA will have its STOP out-of-frame or too close to the START, and pcRNA will have its STOP in-frame and far from the START."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "QP1VTRNQj2UO",
        "outputId": "0bb3cbd5-e5cf-47ec-914a-844de5ab1c9d"
      },
      "source": [
        "import time \n",
        "t = time.time()\n",
        "time.strftime('%Y-%m-%d %H:%M:%S %Z', time.localtime(t))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2021-06-23 16:34:08 UTC'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nhz4GKonj2T_"
      },
      "source": [
        "PC_SEQUENCES=64000   # how many protein-coding sequences\n",
        "NC_SEQUENCES=64000   # how many non-coding sequences\n",
        "PC_TESTS=1000\n",
        "NC_TESTS=1000\n",
        "RNA_LEN=36            # how long is each sequence\n",
        "CDS_LEN=18            # min CDS len to be coding\n",
        "ALPHABET=4          # how many different letters are possible\n",
        "INPUT_SHAPE_2D = (RNA_LEN,ALPHABET,1) # Conv2D needs 3D inputs\n",
        "INPUT_SHAPE = (RNA_LEN,ALPHABET) # Conv1D needs 2D inputs\n",
        "FILTERS = 16   # how many different patterns the model looks for\n",
        "NEURONS = 16\n",
        "DROP_RATE = 0.4\n",
        "WIDTH = 3   # how wide each pattern is, in bases\n",
        "STRIDE_2D = (1,1)  # For Conv2D how far in each direction\n",
        "STRIDE = 1 # For Conv1D, how far between pattern matches, in bases\n",
        "EPOCHS=400  # how many times to train on all the data\n",
        "SPLITS=3  # SPLITS=3 means train on 2/3 and validate on 1/3 \n",
        "FOLDS=3  # train the model this many times (range 1 to SPLITS)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lr7q90rxj2UE",
        "outputId": "bc2c3659-e3f8-48d8-f243-1450b9c17119"
      },
      "source": [
        "import sys\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    IN_COLAB = True\n",
        "    print(\"On Google CoLab, mount cloud-local file, get our code from GitHub.\")\n",
        "    PATH='/content/drive/'\n",
        "    #drive.mount(PATH,force_remount=True)  # hardly ever need this\n",
        "    #drive.mount(PATH)    # Google will require login credentials\n",
        "    DATAPATH=PATH+'My Drive/data/'  # must end in \"/\"\n",
        "    import requests\n",
        "    r = requests.get('https://raw.githubusercontent.com/ShepherdCode/Soars2021/master/SimTools/RNA_gen.py')\n",
        "    with open('RNA_gen.py', 'w') as f:\n",
        "        f.write(r.text)  \n",
        "    from RNA_gen import *\n",
        "    r = requests.get('https://raw.githubusercontent.com/ShepherdCode/Soars2021/master/SimTools/RNA_describe.py')\n",
        "    with open('RNA_describe.py', 'w') as f:\n",
        "        f.write(r.text)  \n",
        "    from RNA_describe import ORF_counter\n",
        "    r = requests.get('https://raw.githubusercontent.com/ShepherdCode/Soars2021/master/SimTools/RNA_prep.py')\n",
        "    with open('RNA_prep.py', 'w') as f:\n",
        "        f.write(r.text)  \n",
        "    from RNA_prep import *\n",
        "except:\n",
        "    print(\"CoLab not working. On my PC, use relative paths.\")\n",
        "    IN_COLAB = False\n",
        "    DATAPATH='data/'  # must end in \"/\"\n",
        "    sys.path.append(\"..\") # append parent dir in order to use sibling dirs\n",
        "    from SimTools.RNA_gen import *\n",
        "    from SimTools.RNA_describe import ORF_counter\n",
        "    from SimTools.RNA_prep import *\n",
        "\n",
        "MODELPATH=\"BestModel\"  # saved on cloud instance and lost after logout\n",
        "#MODELPATH=DATAPATH+MODELPATH  # saved on Google Drive but requires login\n",
        "\n",
        "if not assert_imported_RNA_gen():\n",
        "    print(\"ERROR: Cannot use RNA_gen.\")\n",
        "if not assert_imported_RNA_prep():\n",
        "    print(\"ERROR: Cannot use RNA_prep.\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "On Google CoLab, mount cloud-local file, get our code from GitHub.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGDXH8Uwj2UM"
      },
      "source": [
        "from os import listdir\n",
        "import csv\n",
        "from zipfile import ZipFile\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats  # mode\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Embedding,Dropout\n",
        "from keras.layers import Conv1D,Conv2D\n",
        "from keras.layers import Flatten,MaxPooling1D,MaxPooling2D\n",
        "from keras.losses import BinaryCrossentropy\n",
        "# tf.keras.losses.BinaryCrossentropy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import colors\n",
        "mycmap = colors.ListedColormap(['red','blue'])  # list color for label 0 then 1\n",
        "np.set_printoptions(precision=2)\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUOG_jEvGtOm",
        "outputId": "bc7634ad-7dd7-47c4-9cab-84b8e5141b28"
      },
      "source": [
        "import random\n",
        "def partition_random_sequences(goal_per_class):\n",
        "    pc_seqs=[]\n",
        "    nc_seqs=[]\n",
        "    oc = ORF_counter()\n",
        "    trials = 0\n",
        "    pc_cnt = 0\n",
        "    nc_cnt = 0\n",
        "    bases=['A','C','G','T']\n",
        "    while pc_cnt<goal_per_class or nc_cnt<goal_per_class:\n",
        "        trials += 1        \n",
        "        between_bases = random.randint(0,RNA_LEN-6) \n",
        "        utr5_bases = (RNA_LEN - (between_bases + 6)) // 2\n",
        "        utr3_bases = RNA_LEN - (utr5_bases + (between_bases+6))\n",
        "        one_seq  = \"\".join(random.choices(bases,k=utr5_bases)) \n",
        "        one_seq += 'ATG'    \n",
        "        one_seq += \"\".join(random.choices(bases,k=between_bases)) \n",
        "        random_stop = random.choice(['TAA','TAG','TGA']) # random frame\n",
        "        one_seq += random_stop\n",
        "        one_seq += \"\".join(random.choices(bases,k=utr3_bases))  \n",
        "        if len(one_seq) != RNA_LEN:\n",
        "            print(\"WRONG LENGTH:\",len(one_seq),utr5_bases,between_bases,utr3_bases)\n",
        "        oc.set_sequence(one_seq)\n",
        "        cds_len = oc.get_max_cds_len() + 3\n",
        "        if cds_len >= CDS_LEN and pc_cnt<goal_per_class:\n",
        "            pc_cnt += 1\n",
        "            pc_seqs.append(one_seq)\n",
        "        elif cds_len < CDS_LEN and nc_cnt<goal_per_class:\n",
        "            nc_cnt += 1\n",
        "            nc_seqs.append(one_seq)\n",
        "    print (\"It took %d trials to reach %d per class.\"%(trials,goal_per_class))\n",
        "    return pc_seqs,nc_seqs\n",
        "pc_all,nc_all=partition_random_sequences(10)  # just testing\n",
        "pc_all,nc_all=partition_random_sequences(PC_SEQUENCES+PC_TESTS)\n",
        "print(\"Use\",len(pc_all),\"PC seqs\")\n",
        "print(\"Use\",len(nc_all),\"NC seqs\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "It took 20 trials to reach 10 per class.\n",
            "It took 181470 trials to reach 65000 per class.\n",
            "Use 65000 PC seqs\n",
            "Use 65000 NC seqs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-BmSXi2jUyl",
        "outputId": "79093866-eeaf-4433-be09-f126f268875b"
      },
      "source": [
        "# Describe the sequences\n",
        "def describe_sequences(list_of_seq):\n",
        "    oc = ORF_counter()\n",
        "    num_seq = len(list_of_seq)\n",
        "    rna_lens = np.zeros(num_seq)\n",
        "    orf_lens = np.zeros(num_seq)\n",
        "    for i in range(0,num_seq):\n",
        "        rna_len = len(list_of_seq[i])\n",
        "        rna_lens[i] = rna_len\n",
        "        oc.set_sequence(list_of_seq[i])\n",
        "        orf_len = oc.get_max_orf_len()\n",
        "        orf_lens[i] = orf_len\n",
        "    print (\"Average RNA length:\",rna_lens.mean())\n",
        "    print (\"Average ORF length:\",orf_lens.mean())\n",
        "    \n",
        "print(\"Simulated sequences prior to adjustment:\")\n",
        "print(\"PC seqs\")\n",
        "describe_sequences(pc_all)\n",
        "print(\"NC seqs\")\n",
        "describe_sequences(nc_all)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Simulated sequences prior to adjustment:\n",
            "PC seqs\n",
            "Average RNA length: 36.0\n",
            "Average ORF length: 19.920415384615385\n",
            "NC seqs\n",
            "Average RNA length: 36.0\n",
            "Average ORF length: 2.0004923076923076\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iP1y7-J3jUys"
      },
      "source": [
        "pc_train=pc_all[:PC_SEQUENCES]\n",
        "nc_train=nc_all[:NC_SEQUENCES]\n",
        "pc_test=pc_all[PC_SEQUENCES:]\n",
        "nc_test=nc_all[NC_SEQUENCES:]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIpTrnH6j2US",
        "outputId": "daad8445-2e99-420f-ab62-d847cfaea4d8"
      },
      "source": [
        "# Use code from our SimTools library.\n",
        "X,y = prepare_inputs_len_x_alphabet(pc_train,nc_train,ALPHABET) # shuffles\n",
        "print(\"Data ready.\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data ready.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NvrVU8ij2UU",
        "outputId": "5efbcee0-6873-4b2c-8d76-38de0fa49320"
      },
      "source": [
        "def make_DNN():\n",
        "    print(\"make_DNN\")\n",
        "    print(\"input shape:\",INPUT_SHAPE)\n",
        "    dnn = Sequential()\n",
        "    #dnn.add(Embedding(input_dim=INPUT_SHAPE,output_dim=INPUT_SHAPE)) \n",
        "    dnn.add(Conv1D(filters=FILTERS,kernel_size=WIDTH,strides=STRIDE,padding=\"same\",\n",
        "            input_shape=INPUT_SHAPE))\n",
        "    dnn.add(Conv1D(filters=FILTERS,kernel_size=WIDTH,strides=STRIDE,padding=\"same\"))\n",
        "    dnn.add(MaxPooling1D())\n",
        "    #dnn.add(Conv1D(filters=FILTERS,kernel_size=WIDTH,strides=STRIDE,padding=\"same\"))\n",
        "    #dnn.add(Conv1D(filters=FILTERS,kernel_size=WIDTH,strides=STRIDE,padding=\"same\"))\n",
        "    #dnn.add(MaxPooling1D())\n",
        "    dnn.add(Flatten())\n",
        "    dnn.add(Dense(NEURONS,activation=\"sigmoid\",dtype=np.float32))   \n",
        "    dnn.add(Dropout(DROP_RATE))\n",
        "    dnn.add(Dense(1,activation=\"sigmoid\",dtype=np.float32))   \n",
        "    dnn.compile(optimizer='adam',\n",
        "                loss=BinaryCrossentropy(from_logits=False),\n",
        "                metrics=['accuracy'])   # add to default metrics=loss\n",
        "    dnn.build(input_shape=INPUT_SHAPE)\n",
        "    #ln_rate = tf.keras.optimizers.Adam(learning_rate = LN_RATE)\n",
        "    #bc=tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "    #model.compile(loss=bc, optimizer=ln_rate, metrics=[\"accuracy\"])\n",
        "    return dnn\n",
        "model = make_DNN()\n",
        "print(model.summary())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "make_DNN\n",
            "input shape: (36, 4)\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_4 (Conv1D)            (None, 36, 16)            208       \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 36, 16)            784       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 18, 16)            0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 288)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 16)                4624      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 5,633\n",
            "Trainable params: 5,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlVF0hR3j2UW"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "def do_cross_validation(X,y):\n",
        "    cv_scores = []\n",
        "    fold=0\n",
        "    mycallbacks = [ModelCheckpoint(\n",
        "        filepath=MODELPATH, save_best_only=True, \n",
        "        monitor='val_accuracy', mode='max')]   \n",
        "    splitter = KFold(n_splits=SPLITS)  # this does not shuffle\n",
        "    for train_index,valid_index in splitter.split(X):\n",
        "        if fold < FOLDS:\n",
        "            fold += 1\n",
        "            X_train=X[train_index] # inputs for training\n",
        "            y_train=y[train_index] # labels for training\n",
        "            X_valid=X[valid_index] # inputs for validation\n",
        "            y_valid=y[valid_index] # labels for validation\n",
        "            print(\"MODEL\")\n",
        "            # Call constructor on each CV. Else, continually improves the same model.\n",
        "            model = model = make_DNN()\n",
        "            print(\"FIT\")  # model.fit() implements learning\n",
        "            start_time=time.time()\n",
        "            history=model.fit(X_train, y_train, \n",
        "                    epochs=EPOCHS, \n",
        "                    verbose=1,  # ascii art while learning\n",
        "                    callbacks=mycallbacks,   # called at end of each epoch\n",
        "                    validation_data=(X_valid,y_valid))\n",
        "            end_time=time.time()\n",
        "            elapsed_time=(end_time-start_time)                        \n",
        "            print(\"Fold %d, %d epochs, %d sec\"%(fold,EPOCHS,elapsed_time))\n",
        "            # print(history.history.keys())  # all these keys will be shown in figure\n",
        "            pd.DataFrame(history.history).plot(figsize=(8,5))\n",
        "            plt.grid(True)\n",
        "            plt.gca().set_ylim(0,1) # any losses > 1 will be off the scale\n",
        "            plt.show()\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9Ggt4EsSj2UY",
        "outputId": "a828e638-fabf-4913-a5fe-bbb3d0990a11"
      },
      "source": [
        "do_cross_validation(X,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MODEL\n",
            "make_DNN\n",
            "input shape: (36, 4)\n",
            "FIT\n",
            "Epoch 1/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.6392 - accuracy: 0.6211 - val_loss: 0.4992 - val_accuracy: 0.7574\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 2/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.5069 - accuracy: 0.7445 - val_loss: 0.4519 - val_accuracy: 0.7820\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 3/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.4767 - accuracy: 0.7621 - val_loss: 0.4212 - val_accuracy: 0.7925\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 4/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.4555 - accuracy: 0.7737 - val_loss: 0.4023 - val_accuracy: 0.8003\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 5/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.4425 - accuracy: 0.7768 - val_loss: 0.3881 - val_accuracy: 0.8058\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 6/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.4277 - accuracy: 0.7822 - val_loss: 0.3818 - val_accuracy: 0.8098\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 7/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.4234 - accuracy: 0.7826 - val_loss: 0.3680 - val_accuracy: 0.8151\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 8/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.4118 - accuracy: 0.7889 - val_loss: 0.3632 - val_accuracy: 0.8188\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 9/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.4052 - accuracy: 0.7921 - val_loss: 0.3606 - val_accuracy: 0.8203\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 10/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3997 - accuracy: 0.7907 - val_loss: 0.3528 - val_accuracy: 0.8235\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 11/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3954 - accuracy: 0.7944 - val_loss: 0.3486 - val_accuracy: 0.8270\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 12/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3913 - accuracy: 0.7955 - val_loss: 0.3391 - val_accuracy: 0.8301\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 13/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3891 - accuracy: 0.7956 - val_loss: 0.3390 - val_accuracy: 0.8285\n",
            "Epoch 14/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3837 - accuracy: 0.7983 - val_loss: 0.3361 - val_accuracy: 0.8302\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 15/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3816 - accuracy: 0.7983 - val_loss: 0.3308 - val_accuracy: 0.8515\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 16/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3809 - accuracy: 0.8009 - val_loss: 0.3280 - val_accuracy: 0.8448\n",
            "Epoch 17/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3797 - accuracy: 0.8026 - val_loss: 0.3268 - val_accuracy: 0.8381\n",
            "Epoch 18/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3754 - accuracy: 0.8010 - val_loss: 0.3256 - val_accuracy: 0.8548\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 19/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3736 - accuracy: 0.8027 - val_loss: 0.3217 - val_accuracy: 0.8375\n",
            "Epoch 20/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3728 - accuracy: 0.8053 - val_loss: 0.3227 - val_accuracy: 0.8352\n",
            "Epoch 21/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3715 - accuracy: 0.8041 - val_loss: 0.3227 - val_accuracy: 0.8628\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 22/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3707 - accuracy: 0.8125 - val_loss: 0.3149 - val_accuracy: 0.8578\n",
            "Epoch 23/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3677 - accuracy: 0.8092 - val_loss: 0.3126 - val_accuracy: 0.8532\n",
            "Epoch 24/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3627 - accuracy: 0.8080 - val_loss: 0.3104 - val_accuracy: 0.8632\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 25/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3650 - accuracy: 0.8141 - val_loss: 0.3101 - val_accuracy: 0.8656\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 26/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3594 - accuracy: 0.8163 - val_loss: 0.3165 - val_accuracy: 0.8682\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 27/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3598 - accuracy: 0.8164 - val_loss: 0.3093 - val_accuracy: 0.8645\n",
            "Epoch 28/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3616 - accuracy: 0.8144 - val_loss: 0.3038 - val_accuracy: 0.8669\n",
            "Epoch 29/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3615 - accuracy: 0.8182 - val_loss: 0.3102 - val_accuracy: 0.8702\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 30/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3542 - accuracy: 0.8228 - val_loss: 0.3145 - val_accuracy: 0.8699\n",
            "Epoch 31/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3572 - accuracy: 0.8228 - val_loss: 0.3129 - val_accuracy: 0.8706\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 32/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3558 - accuracy: 0.8173 - val_loss: 0.3102 - val_accuracy: 0.8698\n",
            "Epoch 33/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3573 - accuracy: 0.8147 - val_loss: 0.3047 - val_accuracy: 0.8707\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 34/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3522 - accuracy: 0.8175 - val_loss: 0.2997 - val_accuracy: 0.8742\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 35/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3536 - accuracy: 0.8227 - val_loss: 0.3019 - val_accuracy: 0.8742\n",
            "Epoch 36/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3514 - accuracy: 0.8177 - val_loss: 0.3007 - val_accuracy: 0.8556\n",
            "Epoch 37/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3542 - accuracy: 0.8195 - val_loss: 0.2972 - val_accuracy: 0.8719\n",
            "Epoch 38/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3522 - accuracy: 0.8215 - val_loss: 0.2959 - val_accuracy: 0.8732\n",
            "Epoch 39/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3541 - accuracy: 0.8207 - val_loss: 0.2969 - val_accuracy: 0.8684\n",
            "Epoch 40/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3547 - accuracy: 0.8199 - val_loss: 0.3011 - val_accuracy: 0.8697\n",
            "Epoch 41/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3525 - accuracy: 0.8180 - val_loss: 0.2964 - val_accuracy: 0.8694\n",
            "Epoch 42/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3482 - accuracy: 0.8219 - val_loss: 0.2972 - val_accuracy: 0.8682\n",
            "Epoch 43/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3510 - accuracy: 0.8215 - val_loss: 0.2960 - val_accuracy: 0.8732\n",
            "Epoch 44/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3538 - accuracy: 0.8212 - val_loss: 0.2978 - val_accuracy: 0.8715\n",
            "Epoch 45/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3464 - accuracy: 0.8223 - val_loss: 0.2920 - val_accuracy: 0.8699\n",
            "Epoch 46/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3492 - accuracy: 0.8216 - val_loss: 0.3100 - val_accuracy: 0.8748\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 47/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3469 - accuracy: 0.8243 - val_loss: 0.2963 - val_accuracy: 0.8783\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 48/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3481 - accuracy: 0.8230 - val_loss: 0.2880 - val_accuracy: 0.8772\n",
            "Epoch 49/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3460 - accuracy: 0.8215 - val_loss: 0.2893 - val_accuracy: 0.8793\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 50/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3452 - accuracy: 0.8243 - val_loss: 0.2878 - val_accuracy: 0.8781\n",
            "Epoch 51/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3467 - accuracy: 0.8203 - val_loss: 0.2885 - val_accuracy: 0.8783\n",
            "Epoch 52/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3476 - accuracy: 0.8218 - val_loss: 0.2881 - val_accuracy: 0.8784\n",
            "Epoch 53/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3460 - accuracy: 0.8233 - val_loss: 0.2882 - val_accuracy: 0.8763\n",
            "Epoch 54/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3462 - accuracy: 0.8226 - val_loss: 0.2879 - val_accuracy: 0.8776\n",
            "Epoch 55/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3459 - accuracy: 0.8239 - val_loss: 0.2880 - val_accuracy: 0.8803\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 56/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3399 - accuracy: 0.8258 - val_loss: 0.2830 - val_accuracy: 0.8784\n",
            "Epoch 57/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3448 - accuracy: 0.8258 - val_loss: 0.2962 - val_accuracy: 0.8777\n",
            "Epoch 58/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3421 - accuracy: 0.8266 - val_loss: 0.2862 - val_accuracy: 0.8691\n",
            "Epoch 59/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3426 - accuracy: 0.8220 - val_loss: 0.2813 - val_accuracy: 0.8831\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 60/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3394 - accuracy: 0.8257 - val_loss: 0.2821 - val_accuracy: 0.8779\n",
            "Epoch 61/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3400 - accuracy: 0.8224 - val_loss: 0.2878 - val_accuracy: 0.8800\n",
            "Epoch 62/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3419 - accuracy: 0.8261 - val_loss: 0.2807 - val_accuracy: 0.8813\n",
            "Epoch 63/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3384 - accuracy: 0.8265 - val_loss: 0.2796 - val_accuracy: 0.8810\n",
            "Epoch 64/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3378 - accuracy: 0.8267 - val_loss: 0.2827 - val_accuracy: 0.8824\n",
            "Epoch 65/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3400 - accuracy: 0.8287 - val_loss: 0.2822 - val_accuracy: 0.8767\n",
            "Epoch 66/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3369 - accuracy: 0.8312 - val_loss: 0.2883 - val_accuracy: 0.8783\n",
            "Epoch 67/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3369 - accuracy: 0.8256 - val_loss: 0.2927 - val_accuracy: 0.8819\n",
            "Epoch 68/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3380 - accuracy: 0.8237 - val_loss: 0.2826 - val_accuracy: 0.8789\n",
            "Epoch 69/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3387 - accuracy: 0.8257 - val_loss: 0.2812 - val_accuracy: 0.8788\n",
            "Epoch 70/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3377 - accuracy: 0.8264 - val_loss: 0.2843 - val_accuracy: 0.8834\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 71/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3384 - accuracy: 0.8288 - val_loss: 0.2804 - val_accuracy: 0.8829\n",
            "Epoch 72/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3358 - accuracy: 0.8285 - val_loss: 0.2742 - val_accuracy: 0.8837\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 73/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3377 - accuracy: 0.8279 - val_loss: 0.2848 - val_accuracy: 0.8816\n",
            "Epoch 74/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3393 - accuracy: 0.8278 - val_loss: 0.2837 - val_accuracy: 0.8812\n",
            "Epoch 75/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3319 - accuracy: 0.8298 - val_loss: 0.2808 - val_accuracy: 0.8814\n",
            "Epoch 76/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3362 - accuracy: 0.8294 - val_loss: 0.2772 - val_accuracy: 0.8829\n",
            "Epoch 77/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3309 - accuracy: 0.8315 - val_loss: 0.2784 - val_accuracy: 0.8825\n",
            "Epoch 78/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3341 - accuracy: 0.8305 - val_loss: 0.2803 - val_accuracy: 0.8828\n",
            "Epoch 79/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3341 - accuracy: 0.8264 - val_loss: 0.2840 - val_accuracy: 0.8853\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 80/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3325 - accuracy: 0.8319 - val_loss: 0.2760 - val_accuracy: 0.8839\n",
            "Epoch 81/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3324 - accuracy: 0.8304 - val_loss: 0.2766 - val_accuracy: 0.8853\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 82/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3353 - accuracy: 0.8307 - val_loss: 0.2864 - val_accuracy: 0.8792\n",
            "Epoch 83/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3349 - accuracy: 0.8293 - val_loss: 0.2752 - val_accuracy: 0.8835\n",
            "Epoch 84/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3383 - accuracy: 0.8258 - val_loss: 0.2769 - val_accuracy: 0.8785\n",
            "Epoch 85/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3328 - accuracy: 0.8320 - val_loss: 0.2829 - val_accuracy: 0.8837\n",
            "Epoch 86/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3318 - accuracy: 0.8304 - val_loss: 0.2782 - val_accuracy: 0.8847\n",
            "Epoch 87/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3360 - accuracy: 0.8288 - val_loss: 0.2769 - val_accuracy: 0.8834\n",
            "Epoch 88/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3311 - accuracy: 0.8286 - val_loss: 0.2782 - val_accuracy: 0.8876\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 89/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3341 - accuracy: 0.8299 - val_loss: 0.2749 - val_accuracy: 0.8849\n",
            "Epoch 90/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3330 - accuracy: 0.8299 - val_loss: 0.2755 - val_accuracy: 0.8846\n",
            "Epoch 91/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3340 - accuracy: 0.8306 - val_loss: 0.2742 - val_accuracy: 0.8842\n",
            "Epoch 92/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3321 - accuracy: 0.8303 - val_loss: 0.2814 - val_accuracy: 0.8845\n",
            "Epoch 93/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3303 - accuracy: 0.8323 - val_loss: 0.2746 - val_accuracy: 0.8861\n",
            "Epoch 94/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3288 - accuracy: 0.8310 - val_loss: 0.2744 - val_accuracy: 0.8850\n",
            "Epoch 95/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3326 - accuracy: 0.8302 - val_loss: 0.2710 - val_accuracy: 0.8881\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 96/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3335 - accuracy: 0.8305 - val_loss: 0.2713 - val_accuracy: 0.8859\n",
            "Epoch 97/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3297 - accuracy: 0.8321 - val_loss: 0.2729 - val_accuracy: 0.8858\n",
            "Epoch 98/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3314 - accuracy: 0.8306 - val_loss: 0.2694 - val_accuracy: 0.8875\n",
            "Epoch 99/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3309 - accuracy: 0.8300 - val_loss: 0.2726 - val_accuracy: 0.8853\n",
            "Epoch 100/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3293 - accuracy: 0.8311 - val_loss: 0.2803 - val_accuracy: 0.8864\n",
            "Epoch 101/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3313 - accuracy: 0.8300 - val_loss: 0.2807 - val_accuracy: 0.8861\n",
            "Epoch 102/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3296 - accuracy: 0.8332 - val_loss: 0.2721 - val_accuracy: 0.8844\n",
            "Epoch 103/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3281 - accuracy: 0.8331 - val_loss: 0.2724 - val_accuracy: 0.8888\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 104/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3298 - accuracy: 0.8309 - val_loss: 0.2732 - val_accuracy: 0.8880\n",
            "Epoch 105/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3282 - accuracy: 0.8318 - val_loss: 0.2698 - val_accuracy: 0.8872\n",
            "Epoch 106/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3280 - accuracy: 0.8343 - val_loss: 0.2704 - val_accuracy: 0.8888\n",
            "Epoch 107/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3308 - accuracy: 0.8302 - val_loss: 0.2766 - val_accuracy: 0.8881\n",
            "Epoch 108/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3288 - accuracy: 0.8309 - val_loss: 0.2780 - val_accuracy: 0.8845\n",
            "Epoch 109/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3347 - accuracy: 0.8302 - val_loss: 0.2759 - val_accuracy: 0.8864\n",
            "Epoch 110/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3272 - accuracy: 0.8335 - val_loss: 0.2719 - val_accuracy: 0.8896\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 111/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3309 - accuracy: 0.8314 - val_loss: 0.2745 - val_accuracy: 0.8872\n",
            "Epoch 112/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3331 - accuracy: 0.8298 - val_loss: 0.2706 - val_accuracy: 0.8852\n",
            "Epoch 113/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3291 - accuracy: 0.8340 - val_loss: 0.2713 - val_accuracy: 0.8846\n",
            "Epoch 114/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3282 - accuracy: 0.8325 - val_loss: 0.2691 - val_accuracy: 0.8871\n",
            "Epoch 115/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3295 - accuracy: 0.8306 - val_loss: 0.2703 - val_accuracy: 0.8885\n",
            "Epoch 116/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3303 - accuracy: 0.8291 - val_loss: 0.2728 - val_accuracy: 0.8873\n",
            "Epoch 117/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3277 - accuracy: 0.8310 - val_loss: 0.2705 - val_accuracy: 0.8844\n",
            "Epoch 118/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3310 - accuracy: 0.8317 - val_loss: 0.2702 - val_accuracy: 0.8877\n",
            "Epoch 119/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3283 - accuracy: 0.8326 - val_loss: 0.2700 - val_accuracy: 0.8869\n",
            "Epoch 120/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3266 - accuracy: 0.8306 - val_loss: 0.2693 - val_accuracy: 0.8896\n",
            "Epoch 121/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3294 - accuracy: 0.8319 - val_loss: 0.2718 - val_accuracy: 0.8893\n",
            "Epoch 122/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3238 - accuracy: 0.8334 - val_loss: 0.2706 - val_accuracy: 0.8875\n",
            "Epoch 123/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3250 - accuracy: 0.8334 - val_loss: 0.2697 - val_accuracy: 0.8891\n",
            "Epoch 124/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3252 - accuracy: 0.8336 - val_loss: 0.2693 - val_accuracy: 0.8868\n",
            "Epoch 125/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3263 - accuracy: 0.8331 - val_loss: 0.2870 - val_accuracy: 0.8824\n",
            "Epoch 126/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3220 - accuracy: 0.8363 - val_loss: 0.2648 - val_accuracy: 0.8893\n",
            "Epoch 127/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3232 - accuracy: 0.8347 - val_loss: 0.2753 - val_accuracy: 0.8856\n",
            "Epoch 128/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3248 - accuracy: 0.8348 - val_loss: 0.2713 - val_accuracy: 0.8877\n",
            "Epoch 129/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3258 - accuracy: 0.8323 - val_loss: 0.2683 - val_accuracy: 0.8866\n",
            "Epoch 130/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3240 - accuracy: 0.8363 - val_loss: 0.2676 - val_accuracy: 0.8903\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 131/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3258 - accuracy: 0.8330 - val_loss: 0.2734 - val_accuracy: 0.8889\n",
            "Epoch 132/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3247 - accuracy: 0.8334 - val_loss: 0.2734 - val_accuracy: 0.8886\n",
            "Epoch 133/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3210 - accuracy: 0.8350 - val_loss: 0.2711 - val_accuracy: 0.8886\n",
            "Epoch 134/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3248 - accuracy: 0.8330 - val_loss: 0.2648 - val_accuracy: 0.8883\n",
            "Epoch 135/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3251 - accuracy: 0.8352 - val_loss: 0.2703 - val_accuracy: 0.8878\n",
            "Epoch 136/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3240 - accuracy: 0.8337 - val_loss: 0.2654 - val_accuracy: 0.8892\n",
            "Epoch 137/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3210 - accuracy: 0.8362 - val_loss: 0.2731 - val_accuracy: 0.8867\n",
            "Epoch 138/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3216 - accuracy: 0.8347 - val_loss: 0.2755 - val_accuracy: 0.8881\n",
            "Epoch 139/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3259 - accuracy: 0.8337 - val_loss: 0.2653 - val_accuracy: 0.8898\n",
            "Epoch 140/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3248 - accuracy: 0.8340 - val_loss: 0.2634 - val_accuracy: 0.8912\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 141/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3228 - accuracy: 0.8347 - val_loss: 0.2705 - val_accuracy: 0.8891\n",
            "Epoch 142/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3201 - accuracy: 0.8370 - val_loss: 0.2734 - val_accuracy: 0.8885\n",
            "Epoch 143/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3244 - accuracy: 0.8350 - val_loss: 0.2699 - val_accuracy: 0.8875\n",
            "Epoch 144/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3223 - accuracy: 0.8332 - val_loss: 0.2712 - val_accuracy: 0.8879\n",
            "Epoch 145/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3234 - accuracy: 0.8353 - val_loss: 0.2624 - val_accuracy: 0.8909\n",
            "Epoch 146/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3246 - accuracy: 0.8357 - val_loss: 0.2676 - val_accuracy: 0.8897\n",
            "Epoch 147/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3215 - accuracy: 0.8356 - val_loss: 0.2666 - val_accuracy: 0.8891\n",
            "Epoch 148/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3239 - accuracy: 0.8348 - val_loss: 0.2706 - val_accuracy: 0.8854\n",
            "Epoch 149/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3194 - accuracy: 0.8382 - val_loss: 0.2651 - val_accuracy: 0.8916\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 150/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3229 - accuracy: 0.8351 - val_loss: 0.2660 - val_accuracy: 0.8897\n",
            "Epoch 151/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3231 - accuracy: 0.8341 - val_loss: 0.2623 - val_accuracy: 0.8900\n",
            "Epoch 152/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3231 - accuracy: 0.8345 - val_loss: 0.2596 - val_accuracy: 0.8923\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 153/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3252 - accuracy: 0.8360 - val_loss: 0.2663 - val_accuracy: 0.8932\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 154/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3223 - accuracy: 0.8353 - val_loss: 0.2624 - val_accuracy: 0.8928\n",
            "Epoch 155/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3228 - accuracy: 0.8333 - val_loss: 0.2617 - val_accuracy: 0.8934\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 156/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3280 - accuracy: 0.8342 - val_loss: 0.2655 - val_accuracy: 0.8918\n",
            "Epoch 157/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3226 - accuracy: 0.8358 - val_loss: 0.2608 - val_accuracy: 0.8932\n",
            "Epoch 158/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3196 - accuracy: 0.8347 - val_loss: 0.2646 - val_accuracy: 0.8918\n",
            "Epoch 159/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3215 - accuracy: 0.8356 - val_loss: 0.2625 - val_accuracy: 0.8925\n",
            "Epoch 160/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3182 - accuracy: 0.8372 - val_loss: 0.2619 - val_accuracy: 0.8911\n",
            "Epoch 161/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3196 - accuracy: 0.8394 - val_loss: 0.2630 - val_accuracy: 0.8895\n",
            "Epoch 162/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3225 - accuracy: 0.8365 - val_loss: 0.2630 - val_accuracy: 0.8908\n",
            "Epoch 163/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3190 - accuracy: 0.8371 - val_loss: 0.2720 - val_accuracy: 0.8883\n",
            "Epoch 164/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3203 - accuracy: 0.8342 - val_loss: 0.2599 - val_accuracy: 0.8940\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 165/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3211 - accuracy: 0.8392 - val_loss: 0.2597 - val_accuracy: 0.8916\n",
            "Epoch 166/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3154 - accuracy: 0.8391 - val_loss: 0.2596 - val_accuracy: 0.8929\n",
            "Epoch 167/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3190 - accuracy: 0.8375 - val_loss: 0.2642 - val_accuracy: 0.8905\n",
            "Epoch 168/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3218 - accuracy: 0.8357 - val_loss: 0.2577 - val_accuracy: 0.8929\n",
            "Epoch 169/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3168 - accuracy: 0.8385 - val_loss: 0.2648 - val_accuracy: 0.8902\n",
            "Epoch 170/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3219 - accuracy: 0.8352 - val_loss: 0.2626 - val_accuracy: 0.8922\n",
            "Epoch 171/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3218 - accuracy: 0.8374 - val_loss: 0.2607 - val_accuracy: 0.8913\n",
            "Epoch 172/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3199 - accuracy: 0.8346 - val_loss: 0.2571 - val_accuracy: 0.8942\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 173/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3215 - accuracy: 0.8365 - val_loss: 0.2695 - val_accuracy: 0.8904\n",
            "Epoch 174/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3192 - accuracy: 0.8376 - val_loss: 0.2606 - val_accuracy: 0.8913\n",
            "Epoch 175/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3181 - accuracy: 0.8378 - val_loss: 0.2594 - val_accuracy: 0.8957\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 176/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3180 - accuracy: 0.8378 - val_loss: 0.2554 - val_accuracy: 0.8943\n",
            "Epoch 177/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3180 - accuracy: 0.8376 - val_loss: 0.2587 - val_accuracy: 0.8937\n",
            "Epoch 178/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3183 - accuracy: 0.8379 - val_loss: 0.2580 - val_accuracy: 0.8934\n",
            "Epoch 179/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3163 - accuracy: 0.8380 - val_loss: 0.2576 - val_accuracy: 0.8948\n",
            "Epoch 180/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3152 - accuracy: 0.8409 - val_loss: 0.2582 - val_accuracy: 0.8948\n",
            "Epoch 181/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3128 - accuracy: 0.8420 - val_loss: 0.2542 - val_accuracy: 0.8953\n",
            "Epoch 182/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3156 - accuracy: 0.8382 - val_loss: 0.2559 - val_accuracy: 0.8947\n",
            "Epoch 183/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3163 - accuracy: 0.8384 - val_loss: 0.2604 - val_accuracy: 0.8935\n",
            "Epoch 184/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3181 - accuracy: 0.8399 - val_loss: 0.2531 - val_accuracy: 0.8960\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 185/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3136 - accuracy: 0.8399 - val_loss: 0.2556 - val_accuracy: 0.8955\n",
            "Epoch 186/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3140 - accuracy: 0.8400 - val_loss: 0.2603 - val_accuracy: 0.8920\n",
            "Epoch 187/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3171 - accuracy: 0.8388 - val_loss: 0.2532 - val_accuracy: 0.8946\n",
            "Epoch 188/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3186 - accuracy: 0.8359 - val_loss: 0.2523 - val_accuracy: 0.8968\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 189/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3145 - accuracy: 0.8403 - val_loss: 0.2577 - val_accuracy: 0.8935\n",
            "Epoch 190/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3145 - accuracy: 0.8403 - val_loss: 0.2526 - val_accuracy: 0.8945\n",
            "Epoch 191/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3166 - accuracy: 0.8382 - val_loss: 0.2533 - val_accuracy: 0.8948\n",
            "Epoch 192/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3099 - accuracy: 0.8413 - val_loss: 0.2512 - val_accuracy: 0.8965\n",
            "Epoch 193/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3101 - accuracy: 0.8428 - val_loss: 0.2527 - val_accuracy: 0.8938\n",
            "Epoch 194/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3136 - accuracy: 0.8387 - val_loss: 0.2485 - val_accuracy: 0.8974\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 195/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3133 - accuracy: 0.8367 - val_loss: 0.2516 - val_accuracy: 0.8973\n",
            "Epoch 196/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3106 - accuracy: 0.8410 - val_loss: 0.2570 - val_accuracy: 0.8945\n",
            "Epoch 197/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3099 - accuracy: 0.8400 - val_loss: 0.2637 - val_accuracy: 0.8883\n",
            "Epoch 198/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3132 - accuracy: 0.8397 - val_loss: 0.2548 - val_accuracy: 0.8935\n",
            "Epoch 199/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3133 - accuracy: 0.8379 - val_loss: 0.2488 - val_accuracy: 0.8979\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 200/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3160 - accuracy: 0.8383 - val_loss: 0.2552 - val_accuracy: 0.8957\n",
            "Epoch 201/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3097 - accuracy: 0.8404 - val_loss: 0.2509 - val_accuracy: 0.8958\n",
            "Epoch 202/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3128 - accuracy: 0.8406 - val_loss: 0.2501 - val_accuracy: 0.8977\n",
            "Epoch 203/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3099 - accuracy: 0.8412 - val_loss: 0.2483 - val_accuracy: 0.8986\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 204/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3080 - accuracy: 0.8409 - val_loss: 0.2507 - val_accuracy: 0.8959\n",
            "Epoch 205/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3075 - accuracy: 0.8434 - val_loss: 0.2486 - val_accuracy: 0.8977\n",
            "Epoch 206/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3116 - accuracy: 0.8407 - val_loss: 0.2557 - val_accuracy: 0.8939\n",
            "Epoch 207/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3127 - accuracy: 0.8397 - val_loss: 0.2483 - val_accuracy: 0.8976\n",
            "Epoch 208/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3120 - accuracy: 0.8404 - val_loss: 0.2492 - val_accuracy: 0.8974\n",
            "Epoch 209/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3122 - accuracy: 0.8405 - val_loss: 0.2483 - val_accuracy: 0.8964\n",
            "Epoch 210/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3116 - accuracy: 0.8406 - val_loss: 0.2601 - val_accuracy: 0.8924\n",
            "Epoch 211/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3085 - accuracy: 0.8411 - val_loss: 0.2450 - val_accuracy: 0.8992\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 212/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3077 - accuracy: 0.8415 - val_loss: 0.2466 - val_accuracy: 0.8999\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 213/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3083 - accuracy: 0.8436 - val_loss: 0.2485 - val_accuracy: 0.8953\n",
            "Epoch 214/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3082 - accuracy: 0.8419 - val_loss: 0.2482 - val_accuracy: 0.8970\n",
            "Epoch 215/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3069 - accuracy: 0.8411 - val_loss: 0.2441 - val_accuracy: 0.8997\n",
            "Epoch 216/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3063 - accuracy: 0.8443 - val_loss: 0.2540 - val_accuracy: 0.8949\n",
            "Epoch 217/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3078 - accuracy: 0.8427 - val_loss: 0.2478 - val_accuracy: 0.8981\n",
            "Epoch 218/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3102 - accuracy: 0.8417 - val_loss: 0.2468 - val_accuracy: 0.8990\n",
            "Epoch 219/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3069 - accuracy: 0.8425 - val_loss: 0.2447 - val_accuracy: 0.8986\n",
            "Epoch 220/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3067 - accuracy: 0.8410 - val_loss: 0.2448 - val_accuracy: 0.8996\n",
            "Epoch 221/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3086 - accuracy: 0.8427 - val_loss: 0.2420 - val_accuracy: 0.8995\n",
            "Epoch 222/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3056 - accuracy: 0.8430 - val_loss: 0.2391 - val_accuracy: 0.9021\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 223/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3048 - accuracy: 0.8427 - val_loss: 0.2457 - val_accuracy: 0.9006\n",
            "Epoch 224/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3069 - accuracy: 0.8417 - val_loss: 0.2449 - val_accuracy: 0.8977\n",
            "Epoch 225/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3079 - accuracy: 0.8400 - val_loss: 0.2429 - val_accuracy: 0.9000\n",
            "Epoch 226/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3043 - accuracy: 0.8455 - val_loss: 0.2405 - val_accuracy: 0.9007\n",
            "Epoch 227/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3054 - accuracy: 0.8426 - val_loss: 0.2476 - val_accuracy: 0.8990\n",
            "Epoch 228/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3085 - accuracy: 0.8427 - val_loss: 0.2404 - val_accuracy: 0.9003\n",
            "Epoch 229/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3017 - accuracy: 0.8466 - val_loss: 0.2431 - val_accuracy: 0.9004\n",
            "Epoch 230/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3025 - accuracy: 0.8456 - val_loss: 0.2423 - val_accuracy: 0.9006\n",
            "Epoch 231/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3077 - accuracy: 0.8419 - val_loss: 0.2409 - val_accuracy: 0.8996\n",
            "Epoch 232/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3011 - accuracy: 0.8450 - val_loss: 0.2457 - val_accuracy: 0.8973\n",
            "Epoch 233/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3072 - accuracy: 0.8439 - val_loss: 0.2402 - val_accuracy: 0.9032\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 234/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3061 - accuracy: 0.8443 - val_loss: 0.2400 - val_accuracy: 0.9019\n",
            "Epoch 235/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3032 - accuracy: 0.8452 - val_loss: 0.2421 - val_accuracy: 0.9003\n",
            "Epoch 236/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3046 - accuracy: 0.8432 - val_loss: 0.2466 - val_accuracy: 0.8967\n",
            "Epoch 237/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3040 - accuracy: 0.8447 - val_loss: 0.2378 - val_accuracy: 0.9028\n",
            "Epoch 238/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3021 - accuracy: 0.8461 - val_loss: 0.2397 - val_accuracy: 0.9010\n",
            "Epoch 239/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3021 - accuracy: 0.8450 - val_loss: 0.2355 - val_accuracy: 0.9054\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 240/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3041 - accuracy: 0.8451 - val_loss: 0.2434 - val_accuracy: 0.8996\n",
            "Epoch 241/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3019 - accuracy: 0.8439 - val_loss: 0.2408 - val_accuracy: 0.9036\n",
            "Epoch 242/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3069 - accuracy: 0.8432 - val_loss: 0.2346 - val_accuracy: 0.9044\n",
            "Epoch 243/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3034 - accuracy: 0.8446 - val_loss: 0.2426 - val_accuracy: 0.9000\n",
            "Epoch 244/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3019 - accuracy: 0.8439 - val_loss: 0.2359 - val_accuracy: 0.9030\n",
            "Epoch 245/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2993 - accuracy: 0.8450 - val_loss: 0.2399 - val_accuracy: 0.8994\n",
            "Epoch 246/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3006 - accuracy: 0.8457 - val_loss: 0.2365 - val_accuracy: 0.9042\n",
            "Epoch 247/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3028 - accuracy: 0.8454 - val_loss: 0.2389 - val_accuracy: 0.9014\n",
            "Epoch 248/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2987 - accuracy: 0.8484 - val_loss: 0.2356 - val_accuracy: 0.9038\n",
            "Epoch 249/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3005 - accuracy: 0.8459 - val_loss: 0.2366 - val_accuracy: 0.9040\n",
            "Epoch 250/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3027 - accuracy: 0.8431 - val_loss: 0.2376 - val_accuracy: 0.9024\n",
            "Epoch 251/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3009 - accuracy: 0.8454 - val_loss: 0.2394 - val_accuracy: 0.8989\n",
            "Epoch 252/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2985 - accuracy: 0.8466 - val_loss: 0.2378 - val_accuracy: 0.9022\n",
            "Epoch 253/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3006 - accuracy: 0.8446 - val_loss: 0.2320 - val_accuracy: 0.9060\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 254/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3015 - accuracy: 0.8451 - val_loss: 0.2371 - val_accuracy: 0.9024\n",
            "Epoch 255/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2996 - accuracy: 0.8440 - val_loss: 0.2355 - val_accuracy: 0.9043\n",
            "Epoch 256/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.2992 - accuracy: 0.8465 - val_loss: 0.2351 - val_accuracy: 0.9019\n",
            "Epoch 257/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.2991 - accuracy: 0.8482 - val_loss: 0.2342 - val_accuracy: 0.9031\n",
            "Epoch 258/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2994 - accuracy: 0.8468 - val_loss: 0.2367 - val_accuracy: 0.9039\n",
            "Epoch 259/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3021 - accuracy: 0.8430 - val_loss: 0.2370 - val_accuracy: 0.9042\n",
            "Epoch 260/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2972 - accuracy: 0.8467 - val_loss: 0.2334 - val_accuracy: 0.9024\n",
            "Epoch 261/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.2977 - accuracy: 0.8455 - val_loss: 0.2342 - val_accuracy: 0.9044\n",
            "Epoch 262/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3038 - accuracy: 0.8410 - val_loss: 0.2337 - val_accuracy: 0.9029\n",
            "Epoch 263/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2990 - accuracy: 0.8463 - val_loss: 0.2307 - val_accuracy: 0.9052\n",
            "Epoch 264/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2988 - accuracy: 0.8470 - val_loss: 0.2367 - val_accuracy: 0.9019\n",
            "Epoch 265/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2981 - accuracy: 0.8455 - val_loss: 0.2328 - val_accuracy: 0.9052\n",
            "Epoch 266/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2992 - accuracy: 0.8451 - val_loss: 0.2467 - val_accuracy: 0.8946\n",
            "Epoch 267/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3014 - accuracy: 0.8458 - val_loss: 0.2344 - val_accuracy: 0.9032\n",
            "Epoch 268/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2950 - accuracy: 0.8478 - val_loss: 0.2363 - val_accuracy: 0.9015\n",
            "Epoch 269/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2956 - accuracy: 0.8475 - val_loss: 0.2472 - val_accuracy: 0.8964\n",
            "Epoch 270/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2998 - accuracy: 0.8463 - val_loss: 0.2322 - val_accuracy: 0.9054\n",
            "Epoch 271/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.2984 - accuracy: 0.8458 - val_loss: 0.2361 - val_accuracy: 0.9023\n",
            "Epoch 272/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.2979 - accuracy: 0.8439 - val_loss: 0.2316 - val_accuracy: 0.9057\n",
            "Epoch 273/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2967 - accuracy: 0.8462 - val_loss: 0.2332 - val_accuracy: 0.9040\n",
            "Epoch 274/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2988 - accuracy: 0.8440 - val_loss: 0.2307 - val_accuracy: 0.9059\n",
            "Epoch 275/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2959 - accuracy: 0.8469 - val_loss: 0.2334 - val_accuracy: 0.9055\n",
            "Epoch 276/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2986 - accuracy: 0.8432 - val_loss: 0.2305 - val_accuracy: 0.9069\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 277/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2967 - accuracy: 0.8477 - val_loss: 0.2302 - val_accuracy: 0.9055\n",
            "Epoch 278/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2954 - accuracy: 0.8481 - val_loss: 0.2402 - val_accuracy: 0.8995\n",
            "Epoch 279/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2946 - accuracy: 0.8476 - val_loss: 0.2304 - val_accuracy: 0.9062\n",
            "Epoch 280/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2985 - accuracy: 0.8449 - val_loss: 0.2283 - val_accuracy: 0.9074\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 281/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2961 - accuracy: 0.8459 - val_loss: 0.2313 - val_accuracy: 0.9054\n",
            "Epoch 282/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2965 - accuracy: 0.8455 - val_loss: 0.2301 - val_accuracy: 0.9056\n",
            "Epoch 283/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2960 - accuracy: 0.8476 - val_loss: 0.2275 - val_accuracy: 0.9080\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 284/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2947 - accuracy: 0.8453 - val_loss: 0.2314 - val_accuracy: 0.9060\n",
            "Epoch 285/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2942 - accuracy: 0.8471 - val_loss: 0.2311 - val_accuracy: 0.9058\n",
            "Epoch 286/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2932 - accuracy: 0.8465 - val_loss: 0.2313 - val_accuracy: 0.9041\n",
            "Epoch 287/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2970 - accuracy: 0.8449 - val_loss: 0.2313 - val_accuracy: 0.9039\n",
            "Epoch 288/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2982 - accuracy: 0.8454 - val_loss: 0.2454 - val_accuracy: 0.8936\n",
            "Epoch 289/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2974 - accuracy: 0.8462 - val_loss: 0.2332 - val_accuracy: 0.9030\n",
            "Epoch 290/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2918 - accuracy: 0.8484 - val_loss: 0.2273 - val_accuracy: 0.9066\n",
            "Epoch 291/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2928 - accuracy: 0.8466 - val_loss: 0.2261 - val_accuracy: 0.9068\n",
            "Epoch 292/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2908 - accuracy: 0.8492 - val_loss: 0.2288 - val_accuracy: 0.9059\n",
            "Epoch 293/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2948 - accuracy: 0.8477 - val_loss: 0.2287 - val_accuracy: 0.9060\n",
            "Epoch 294/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2952 - accuracy: 0.8472 - val_loss: 0.2330 - val_accuracy: 0.9040\n",
            "Epoch 295/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2930 - accuracy: 0.8479 - val_loss: 0.2320 - val_accuracy: 0.9056\n",
            "Epoch 296/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2968 - accuracy: 0.8469 - val_loss: 0.2302 - val_accuracy: 0.9057\n",
            "Epoch 297/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2931 - accuracy: 0.8484 - val_loss: 0.2255 - val_accuracy: 0.9069\n",
            "Epoch 298/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2949 - accuracy: 0.8469 - val_loss: 0.2263 - val_accuracy: 0.9070\n",
            "Epoch 299/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2963 - accuracy: 0.8445 - val_loss: 0.2339 - val_accuracy: 0.9029\n",
            "Epoch 300/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2941 - accuracy: 0.8475 - val_loss: 0.2294 - val_accuracy: 0.9075\n",
            "Epoch 301/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2950 - accuracy: 0.8484 - val_loss: 0.2267 - val_accuracy: 0.9064\n",
            "Epoch 302/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2910 - accuracy: 0.8495 - val_loss: 0.2287 - val_accuracy: 0.9056\n",
            "Epoch 303/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2930 - accuracy: 0.8470 - val_loss: 0.2253 - val_accuracy: 0.9069\n",
            "Epoch 304/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2955 - accuracy: 0.8452 - val_loss: 0.2250 - val_accuracy: 0.9090\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 305/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2901 - accuracy: 0.8499 - val_loss: 0.2242 - val_accuracy: 0.9073\n",
            "Epoch 306/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2918 - accuracy: 0.8481 - val_loss: 0.2284 - val_accuracy: 0.9060\n",
            "Epoch 307/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2914 - accuracy: 0.8466 - val_loss: 0.2276 - val_accuracy: 0.9070\n",
            "Epoch 308/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2928 - accuracy: 0.8496 - val_loss: 0.2219 - val_accuracy: 0.9091\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 309/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2894 - accuracy: 0.8509 - val_loss: 0.2245 - val_accuracy: 0.9083\n",
            "Epoch 310/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2911 - accuracy: 0.8506 - val_loss: 0.2222 - val_accuracy: 0.9091\n",
            "Epoch 311/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2895 - accuracy: 0.8482 - val_loss: 0.2237 - val_accuracy: 0.9083\n",
            "Epoch 312/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2946 - accuracy: 0.8476 - val_loss: 0.2245 - val_accuracy: 0.9090\n",
            "Epoch 313/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2909 - accuracy: 0.8495 - val_loss: 0.2238 - val_accuracy: 0.9081\n",
            "Epoch 314/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2907 - accuracy: 0.8509 - val_loss: 0.2220 - val_accuracy: 0.9096\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 315/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2901 - accuracy: 0.8503 - val_loss: 0.2241 - val_accuracy: 0.9082\n",
            "Epoch 316/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2904 - accuracy: 0.8492 - val_loss: 0.2208 - val_accuracy: 0.9087\n",
            "Epoch 317/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2926 - accuracy: 0.8472 - val_loss: 0.2214 - val_accuracy: 0.9092\n",
            "Epoch 318/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2885 - accuracy: 0.8520 - val_loss: 0.2227 - val_accuracy: 0.9098\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 319/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2915 - accuracy: 0.8467 - val_loss: 0.2262 - val_accuracy: 0.9089\n",
            "Epoch 320/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2889 - accuracy: 0.8509 - val_loss: 0.2217 - val_accuracy: 0.9100\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 321/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2903 - accuracy: 0.8497 - val_loss: 0.2306 - val_accuracy: 0.9059\n",
            "Epoch 322/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2885 - accuracy: 0.8498 - val_loss: 0.2200 - val_accuracy: 0.9100\n",
            "Epoch 323/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2905 - accuracy: 0.8502 - val_loss: 0.2223 - val_accuracy: 0.9078\n",
            "Epoch 324/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2871 - accuracy: 0.8506 - val_loss: 0.2232 - val_accuracy: 0.9078\n",
            "Epoch 325/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2895 - accuracy: 0.8518 - val_loss: 0.2183 - val_accuracy: 0.9115\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 326/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2904 - accuracy: 0.8502 - val_loss: 0.2304 - val_accuracy: 0.9015\n",
            "Epoch 327/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2877 - accuracy: 0.8490 - val_loss: 0.2366 - val_accuracy: 0.9003\n",
            "Epoch 328/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2921 - accuracy: 0.8490 - val_loss: 0.2249 - val_accuracy: 0.9082\n",
            "Epoch 329/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2892 - accuracy: 0.8489 - val_loss: 0.2199 - val_accuracy: 0.9109\n",
            "Epoch 330/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2888 - accuracy: 0.8496 - val_loss: 0.2167 - val_accuracy: 0.9128\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 331/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2847 - accuracy: 0.8496 - val_loss: 0.2215 - val_accuracy: 0.9099\n",
            "Epoch 332/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2867 - accuracy: 0.8511 - val_loss: 0.2207 - val_accuracy: 0.9101\n",
            "Epoch 333/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2848 - accuracy: 0.8508 - val_loss: 0.2183 - val_accuracy: 0.9108\n",
            "Epoch 334/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2864 - accuracy: 0.8526 - val_loss: 0.2205 - val_accuracy: 0.9105\n",
            "Epoch 335/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2803 - accuracy: 0.8531 - val_loss: 0.2166 - val_accuracy: 0.9111\n",
            "Epoch 336/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2852 - accuracy: 0.8530 - val_loss: 0.2191 - val_accuracy: 0.9107\n",
            "Epoch 337/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2863 - accuracy: 0.8507 - val_loss: 0.2208 - val_accuracy: 0.9078\n",
            "Epoch 338/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2888 - accuracy: 0.8486 - val_loss: 0.2195 - val_accuracy: 0.9094\n",
            "Epoch 339/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2875 - accuracy: 0.8495 - val_loss: 0.2178 - val_accuracy: 0.9103\n",
            "Epoch 340/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2917 - accuracy: 0.8469 - val_loss: 0.2192 - val_accuracy: 0.9104\n",
            "Epoch 341/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2851 - accuracy: 0.8525 - val_loss: 0.2186 - val_accuracy: 0.9110\n",
            "Epoch 342/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2838 - accuracy: 0.8521 - val_loss: 0.2193 - val_accuracy: 0.9104\n",
            "Epoch 343/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2874 - accuracy: 0.8495 - val_loss: 0.2229 - val_accuracy: 0.9067\n",
            "Epoch 344/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2821 - accuracy: 0.8533 - val_loss: 0.2237 - val_accuracy: 0.9070\n",
            "Epoch 345/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2886 - accuracy: 0.8502 - val_loss: 0.2187 - val_accuracy: 0.9096\n",
            "Epoch 346/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2874 - accuracy: 0.8490 - val_loss: 0.2202 - val_accuracy: 0.9090\n",
            "Epoch 347/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2904 - accuracy: 0.8475 - val_loss: 0.2188 - val_accuracy: 0.9102\n",
            "Epoch 348/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2838 - accuracy: 0.8519 - val_loss: 0.2164 - val_accuracy: 0.9113\n",
            "Epoch 349/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2839 - accuracy: 0.8537 - val_loss: 0.2171 - val_accuracy: 0.9091\n",
            "Epoch 350/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2855 - accuracy: 0.8530 - val_loss: 0.2159 - val_accuracy: 0.9114\n",
            "Epoch 351/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2812 - accuracy: 0.8545 - val_loss: 0.2175 - val_accuracy: 0.9123\n",
            "Epoch 352/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2794 - accuracy: 0.8534 - val_loss: 0.2170 - val_accuracy: 0.9087\n",
            "Epoch 353/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2821 - accuracy: 0.8513 - val_loss: 0.2205 - val_accuracy: 0.9097\n",
            "Epoch 354/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2863 - accuracy: 0.8501 - val_loss: 0.2180 - val_accuracy: 0.9108\n",
            "Epoch 355/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2823 - accuracy: 0.8518 - val_loss: 0.2161 - val_accuracy: 0.9112\n",
            "Epoch 356/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2841 - accuracy: 0.8515 - val_loss: 0.2216 - val_accuracy: 0.9080\n",
            "Epoch 357/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2827 - accuracy: 0.8527 - val_loss: 0.2191 - val_accuracy: 0.9089\n",
            "Epoch 358/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2842 - accuracy: 0.8515 - val_loss: 0.2170 - val_accuracy: 0.9094\n",
            "Epoch 359/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2886 - accuracy: 0.8519 - val_loss: 0.2179 - val_accuracy: 0.9093\n",
            "Epoch 360/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2833 - accuracy: 0.8533 - val_loss: 0.2198 - val_accuracy: 0.9091\n",
            "Epoch 361/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2788 - accuracy: 0.8539 - val_loss: 0.2195 - val_accuracy: 0.9097\n",
            "Epoch 362/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2825 - accuracy: 0.8518 - val_loss: 0.2228 - val_accuracy: 0.9070\n",
            "Epoch 363/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2844 - accuracy: 0.8511 - val_loss: 0.2210 - val_accuracy: 0.9089\n",
            "Epoch 364/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2833 - accuracy: 0.8532 - val_loss: 0.2141 - val_accuracy: 0.9107\n",
            "Epoch 365/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2840 - accuracy: 0.8538 - val_loss: 0.2140 - val_accuracy: 0.9124\n",
            "Epoch 366/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2828 - accuracy: 0.8527 - val_loss: 0.2149 - val_accuracy: 0.9114\n",
            "Epoch 367/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2820 - accuracy: 0.8525 - val_loss: 0.2188 - val_accuracy: 0.9078\n",
            "Epoch 368/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2823 - accuracy: 0.8520 - val_loss: 0.2168 - val_accuracy: 0.9090\n",
            "Epoch 369/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2875 - accuracy: 0.8492 - val_loss: 0.2258 - val_accuracy: 0.9079\n",
            "Epoch 370/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2867 - accuracy: 0.8495 - val_loss: 0.2166 - val_accuracy: 0.9079\n",
            "Epoch 371/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2812 - accuracy: 0.8542 - val_loss: 0.2146 - val_accuracy: 0.9096\n",
            "Epoch 372/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2812 - accuracy: 0.8525 - val_loss: 0.2129 - val_accuracy: 0.9124\n",
            "Epoch 373/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2826 - accuracy: 0.8548 - val_loss: 0.2106 - val_accuracy: 0.9120\n",
            "Epoch 374/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2797 - accuracy: 0.8529 - val_loss: 0.2163 - val_accuracy: 0.9116\n",
            "Epoch 375/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2812 - accuracy: 0.8525 - val_loss: 0.2166 - val_accuracy: 0.9123\n",
            "Epoch 376/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2816 - accuracy: 0.8528 - val_loss: 0.2241 - val_accuracy: 0.9045\n",
            "Epoch 377/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2788 - accuracy: 0.8547 - val_loss: 0.2270 - val_accuracy: 0.9002\n",
            "Epoch 378/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2776 - accuracy: 0.8547 - val_loss: 0.2121 - val_accuracy: 0.9113\n",
            "Epoch 379/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2805 - accuracy: 0.8557 - val_loss: 0.2144 - val_accuracy: 0.9094\n",
            "Epoch 380/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2820 - accuracy: 0.8535 - val_loss: 0.2128 - val_accuracy: 0.9120\n",
            "Epoch 381/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2799 - accuracy: 0.8543 - val_loss: 0.2113 - val_accuracy: 0.9118\n",
            "Epoch 382/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2848 - accuracy: 0.8513 - val_loss: 0.2146 - val_accuracy: 0.9101\n",
            "Epoch 383/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2807 - accuracy: 0.8537 - val_loss: 0.2154 - val_accuracy: 0.9098\n",
            "Epoch 384/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2810 - accuracy: 0.8531 - val_loss: 0.2089 - val_accuracy: 0.9126\n",
            "Epoch 385/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2818 - accuracy: 0.8528 - val_loss: 0.2144 - val_accuracy: 0.9115\n",
            "Epoch 386/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2786 - accuracy: 0.8546 - val_loss: 0.2143 - val_accuracy: 0.9109\n",
            "Epoch 387/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2784 - accuracy: 0.8549 - val_loss: 0.2105 - val_accuracy: 0.9123\n",
            "Epoch 388/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2787 - accuracy: 0.8538 - val_loss: 0.2107 - val_accuracy: 0.9123\n",
            "Epoch 389/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2794 - accuracy: 0.8536 - val_loss: 0.2179 - val_accuracy: 0.9100\n",
            "Epoch 390/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2838 - accuracy: 0.8511 - val_loss: 0.2103 - val_accuracy: 0.9126\n",
            "Epoch 391/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2811 - accuracy: 0.8520 - val_loss: 0.2226 - val_accuracy: 0.9040\n",
            "Epoch 392/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2789 - accuracy: 0.8524 - val_loss: 0.2134 - val_accuracy: 0.9117\n",
            "Epoch 393/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2802 - accuracy: 0.8522 - val_loss: 0.2135 - val_accuracy: 0.9107\n",
            "Epoch 394/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2806 - accuracy: 0.8523 - val_loss: 0.2137 - val_accuracy: 0.9127\n",
            "Epoch 395/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2812 - accuracy: 0.8526 - val_loss: 0.2155 - val_accuracy: 0.9101\n",
            "Epoch 396/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2764 - accuracy: 0.8545 - val_loss: 0.2149 - val_accuracy: 0.9104\n",
            "Epoch 397/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2763 - accuracy: 0.8546 - val_loss: 0.2103 - val_accuracy: 0.9128\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Epoch 398/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2838 - accuracy: 0.8529 - val_loss: 0.2146 - val_accuracy: 0.9096\n",
            "Epoch 399/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2865 - accuracy: 0.8491 - val_loss: 0.2147 - val_accuracy: 0.9093\n",
            "Epoch 400/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.2810 - accuracy: 0.8528 - val_loss: 0.2091 - val_accuracy: 0.9138\n",
            "INFO:tensorflow:Assets written to: BestModel/assets\n",
            "Fold 1, 400 epochs, 4285 sec\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "MODEL\n",
            "make_DNN\n",
            "input shape: (36, 4)\n",
            "FIT\n",
            "Epoch 1/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.6370 - accuracy: 0.6273 - val_loss: 0.5148 - val_accuracy: 0.7473\n",
            "Epoch 2/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.5219 - accuracy: 0.7400 - val_loss: 0.4601 - val_accuracy: 0.7761\n",
            "Epoch 3/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.4816 - accuracy: 0.7604 - val_loss: 0.4281 - val_accuracy: 0.7903\n",
            "Epoch 4/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.4587 - accuracy: 0.7726 - val_loss: 0.4122 - val_accuracy: 0.7964\n",
            "Epoch 5/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.4453 - accuracy: 0.7806 - val_loss: 0.3968 - val_accuracy: 0.8043\n",
            "Epoch 6/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.4382 - accuracy: 0.7825 - val_loss: 0.3893 - val_accuracy: 0.8063\n",
            "Epoch 7/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.4293 - accuracy: 0.7858 - val_loss: 0.3812 - val_accuracy: 0.8103\n",
            "Epoch 8/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.4196 - accuracy: 0.7896 - val_loss: 0.3741 - val_accuracy: 0.8120\n",
            "Epoch 9/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.4164 - accuracy: 0.7896 - val_loss: 0.3684 - val_accuracy: 0.8153\n",
            "Epoch 10/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.4110 - accuracy: 0.7897 - val_loss: 0.3722 - val_accuracy: 0.8135\n",
            "Epoch 11/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.4119 - accuracy: 0.7894 - val_loss: 0.3697 - val_accuracy: 0.8127\n",
            "Epoch 12/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.4052 - accuracy: 0.7953 - val_loss: 0.3682 - val_accuracy: 0.8143\n",
            "Epoch 13/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.4035 - accuracy: 0.7964 - val_loss: 0.3582 - val_accuracy: 0.8169\n",
            "Epoch 14/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.4032 - accuracy: 0.7934 - val_loss: 0.3579 - val_accuracy: 0.8179\n",
            "Epoch 15/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3968 - accuracy: 0.7973 - val_loss: 0.3498 - val_accuracy: 0.8212\n",
            "Epoch 16/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3990 - accuracy: 0.7972 - val_loss: 0.3465 - val_accuracy: 0.8224\n",
            "Epoch 17/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3904 - accuracy: 0.8000 - val_loss: 0.3460 - val_accuracy: 0.8251\n",
            "Epoch 18/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3907 - accuracy: 0.8004 - val_loss: 0.3380 - val_accuracy: 0.8247\n",
            "Epoch 19/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3872 - accuracy: 0.8015 - val_loss: 0.3352 - val_accuracy: 0.8273\n",
            "Epoch 20/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3865 - accuracy: 0.8026 - val_loss: 0.3491 - val_accuracy: 0.8244\n",
            "Epoch 21/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3846 - accuracy: 0.8007 - val_loss: 0.3324 - val_accuracy: 0.8263\n",
            "Epoch 22/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3804 - accuracy: 0.8048 - val_loss: 0.3308 - val_accuracy: 0.8292\n",
            "Epoch 23/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3861 - accuracy: 0.8036 - val_loss: 0.3296 - val_accuracy: 0.8292\n",
            "Epoch 24/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3782 - accuracy: 0.8064 - val_loss: 0.3442 - val_accuracy: 0.8288\n",
            "Epoch 25/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3762 - accuracy: 0.8076 - val_loss: 0.3318 - val_accuracy: 0.8293\n",
            "Epoch 26/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3740 - accuracy: 0.8060 - val_loss: 0.3269 - val_accuracy: 0.8283\n",
            "Epoch 27/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3747 - accuracy: 0.8091 - val_loss: 0.3262 - val_accuracy: 0.8332\n",
            "Epoch 28/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3811 - accuracy: 0.8006 - val_loss: 0.3211 - val_accuracy: 0.8339\n",
            "Epoch 29/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3685 - accuracy: 0.8064 - val_loss: 0.3259 - val_accuracy: 0.8320\n",
            "Epoch 30/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3737 - accuracy: 0.8065 - val_loss: 0.3204 - val_accuracy: 0.8356\n",
            "Epoch 31/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3680 - accuracy: 0.8102 - val_loss: 0.3310 - val_accuracy: 0.8331\n",
            "Epoch 32/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3669 - accuracy: 0.8102 - val_loss: 0.3175 - val_accuracy: 0.8365\n",
            "Epoch 33/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3669 - accuracy: 0.8093 - val_loss: 0.3187 - val_accuracy: 0.8396\n",
            "Epoch 34/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3655 - accuracy: 0.8099 - val_loss: 0.3192 - val_accuracy: 0.8377\n",
            "Epoch 35/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3656 - accuracy: 0.8081 - val_loss: 0.3258 - val_accuracy: 0.8341\n",
            "Epoch 36/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3613 - accuracy: 0.8126 - val_loss: 0.3251 - val_accuracy: 0.8380\n",
            "Epoch 37/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3645 - accuracy: 0.8103 - val_loss: 0.3067 - val_accuracy: 0.8425\n",
            "Epoch 38/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3622 - accuracy: 0.8126 - val_loss: 0.3123 - val_accuracy: 0.8413\n",
            "Epoch 39/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3642 - accuracy: 0.8129 - val_loss: 0.3066 - val_accuracy: 0.8427\n",
            "Epoch 40/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3600 - accuracy: 0.8111 - val_loss: 0.3113 - val_accuracy: 0.8390\n",
            "Epoch 41/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3590 - accuracy: 0.8130 - val_loss: 0.3133 - val_accuracy: 0.8384\n",
            "Epoch 42/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3585 - accuracy: 0.8139 - val_loss: 0.2994 - val_accuracy: 0.8437\n",
            "Epoch 43/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3555 - accuracy: 0.8144 - val_loss: 0.2970 - val_accuracy: 0.8460\n",
            "Epoch 44/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3569 - accuracy: 0.8127 - val_loss: 0.2983 - val_accuracy: 0.8456\n",
            "Epoch 45/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3557 - accuracy: 0.8128 - val_loss: 0.2976 - val_accuracy: 0.8473\n",
            "Epoch 46/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3519 - accuracy: 0.8155 - val_loss: 0.3010 - val_accuracy: 0.8448\n",
            "Epoch 47/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3561 - accuracy: 0.8149 - val_loss: 0.2974 - val_accuracy: 0.8454\n",
            "Epoch 48/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3532 - accuracy: 0.8185 - val_loss: 0.2998 - val_accuracy: 0.8471\n",
            "Epoch 49/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3487 - accuracy: 0.8148 - val_loss: 0.2972 - val_accuracy: 0.8445\n",
            "Epoch 50/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3504 - accuracy: 0.8176 - val_loss: 0.3140 - val_accuracy: 0.8448\n",
            "Epoch 51/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3492 - accuracy: 0.8170 - val_loss: 0.2964 - val_accuracy: 0.8485\n",
            "Epoch 52/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3479 - accuracy: 0.8189 - val_loss: 0.2970 - val_accuracy: 0.8462\n",
            "Epoch 53/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3461 - accuracy: 0.8196 - val_loss: 0.2899 - val_accuracy: 0.8486\n",
            "Epoch 54/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3475 - accuracy: 0.8170 - val_loss: 0.2917 - val_accuracy: 0.8470\n",
            "Epoch 55/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3466 - accuracy: 0.8177 - val_loss: 0.2944 - val_accuracy: 0.8438\n",
            "Epoch 56/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3486 - accuracy: 0.8163 - val_loss: 0.2918 - val_accuracy: 0.8474\n",
            "Epoch 57/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3466 - accuracy: 0.8173 - val_loss: 0.2897 - val_accuracy: 0.8489\n",
            "Epoch 58/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3457 - accuracy: 0.8169 - val_loss: 0.2933 - val_accuracy: 0.8485\n",
            "Epoch 59/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3493 - accuracy: 0.8170 - val_loss: 0.2883 - val_accuracy: 0.8509\n",
            "Epoch 60/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3498 - accuracy: 0.8139 - val_loss: 0.2895 - val_accuracy: 0.8474\n",
            "Epoch 61/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3405 - accuracy: 0.8199 - val_loss: 0.2915 - val_accuracy: 0.8500\n",
            "Epoch 62/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3437 - accuracy: 0.8188 - val_loss: 0.2923 - val_accuracy: 0.8495\n",
            "Epoch 63/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3433 - accuracy: 0.8189 - val_loss: 0.2894 - val_accuracy: 0.8472\n",
            "Epoch 64/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3430 - accuracy: 0.8186 - val_loss: 0.2833 - val_accuracy: 0.8528\n",
            "Epoch 65/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3412 - accuracy: 0.8195 - val_loss: 0.2869 - val_accuracy: 0.8518\n",
            "Epoch 66/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3444 - accuracy: 0.8188 - val_loss: 0.2899 - val_accuracy: 0.8509\n",
            "Epoch 67/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3391 - accuracy: 0.8195 - val_loss: 0.2926 - val_accuracy: 0.8492\n",
            "Epoch 68/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3394 - accuracy: 0.8224 - val_loss: 0.2888 - val_accuracy: 0.8536\n",
            "Epoch 69/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3417 - accuracy: 0.8213 - val_loss: 0.2857 - val_accuracy: 0.8521\n",
            "Epoch 70/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3376 - accuracy: 0.8220 - val_loss: 0.2851 - val_accuracy: 0.8513\n",
            "Epoch 71/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3382 - accuracy: 0.8233 - val_loss: 0.2925 - val_accuracy: 0.8505\n",
            "Epoch 72/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3392 - accuracy: 0.8202 - val_loss: 0.2857 - val_accuracy: 0.8502\n",
            "Epoch 73/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3393 - accuracy: 0.8213 - val_loss: 0.2863 - val_accuracy: 0.8511\n",
            "Epoch 74/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3399 - accuracy: 0.8206 - val_loss: 0.2892 - val_accuracy: 0.8503\n",
            "Epoch 75/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3337 - accuracy: 0.8250 - val_loss: 0.2827 - val_accuracy: 0.8537\n",
            "Epoch 76/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3386 - accuracy: 0.8219 - val_loss: 0.2835 - val_accuracy: 0.8515\n",
            "Epoch 77/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3343 - accuracy: 0.8228 - val_loss: 0.2856 - val_accuracy: 0.8520\n",
            "Epoch 78/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3390 - accuracy: 0.8205 - val_loss: 0.2897 - val_accuracy: 0.8519\n",
            "Epoch 79/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3380 - accuracy: 0.8220 - val_loss: 0.2807 - val_accuracy: 0.8531\n",
            "Epoch 80/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3407 - accuracy: 0.8223 - val_loss: 0.2807 - val_accuracy: 0.8527\n",
            "Epoch 81/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3382 - accuracy: 0.8206 - val_loss: 0.2959 - val_accuracy: 0.8524\n",
            "Epoch 82/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3318 - accuracy: 0.8224 - val_loss: 0.2794 - val_accuracy: 0.8549\n",
            "Epoch 83/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3332 - accuracy: 0.8227 - val_loss: 0.2793 - val_accuracy: 0.8554\n",
            "Epoch 84/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3344 - accuracy: 0.8221 - val_loss: 0.2818 - val_accuracy: 0.8563\n",
            "Epoch 85/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3299 - accuracy: 0.8242 - val_loss: 0.2779 - val_accuracy: 0.8589\n",
            "Epoch 86/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3323 - accuracy: 0.8257 - val_loss: 0.2769 - val_accuracy: 0.8543\n",
            "Epoch 87/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3330 - accuracy: 0.8243 - val_loss: 0.2756 - val_accuracy: 0.8572\n",
            "Epoch 88/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3336 - accuracy: 0.8254 - val_loss: 0.2741 - val_accuracy: 0.8584\n",
            "Epoch 89/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3342 - accuracy: 0.8239 - val_loss: 0.2723 - val_accuracy: 0.8585\n",
            "Epoch 90/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3300 - accuracy: 0.8235 - val_loss: 0.2677 - val_accuracy: 0.8590\n",
            "Epoch 91/400\n",
            "2667/2667 [==============================] - 10s 4ms/step - loss: 0.3325 - accuracy: 0.8245 - val_loss: 0.2699 - val_accuracy: 0.8574\n",
            "Epoch 92/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3288 - accuracy: 0.8267 - val_loss: 0.2749 - val_accuracy: 0.8585\n",
            "Epoch 93/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3333 - accuracy: 0.8246 - val_loss: 0.2701 - val_accuracy: 0.8613\n",
            "Epoch 94/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3304 - accuracy: 0.8249 - val_loss: 0.2719 - val_accuracy: 0.8584\n",
            "Epoch 95/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3288 - accuracy: 0.8258 - val_loss: 0.2677 - val_accuracy: 0.8600\n",
            "Epoch 96/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3263 - accuracy: 0.8260 - val_loss: 0.2670 - val_accuracy: 0.8608\n",
            "Epoch 97/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3288 - accuracy: 0.8262 - val_loss: 0.2686 - val_accuracy: 0.8597\n",
            "Epoch 98/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3275 - accuracy: 0.8267 - val_loss: 0.2792 - val_accuracy: 0.8591\n",
            "Epoch 99/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3263 - accuracy: 0.8276 - val_loss: 0.2696 - val_accuracy: 0.8585\n",
            "Epoch 100/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3286 - accuracy: 0.8272 - val_loss: 0.2693 - val_accuracy: 0.8616\n",
            "Epoch 101/400\n",
            "2667/2667 [==============================] - 11s 4ms/step - loss: 0.3303 - accuracy: 0.8251 - val_loss: 0.2687 - val_accuracy: 0.8598\n",
            "Epoch 102/400\n",
            "2001/2667 [=====================>........] - ETA: 1s - loss: 0.3275 - accuracy: 0.8263"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-jG1h5fj2Ua"
      },
      "source": [
        "from keras.models import load_model\n",
        "X,y = prepare_inputs_len_x_alphabet(pc_test,nc_test,ALPHABET)\n",
        "best_model=load_model(MODELPATH)\n",
        "scores = best_model.evaluate(X, y, verbose=0)\n",
        "print(\"The best model parameters were saved during cross-validation.\")\n",
        "print(\"Best was defined as maximum validation accuracy at end of any epoch.\")\n",
        "print(\"Now re-load the best model and test it on previously unseen data.\")\n",
        "print(\"Test on\",len(pc_test),\"PC seqs\")\n",
        "print(\"Test on\",len(nc_test),\"NC seqs\")\n",
        "print(\"%s: %.2f%%\" % (best_model.metrics_names[1], scores[1]*100))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VycUnmvUj2Ue"
      },
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "ns_probs = [0 for _ in range(len(y))]\n",
        "bm_probs = best_model.predict(X)\n",
        "ns_auc = roc_auc_score(y, ns_probs)\n",
        "bm_auc = roc_auc_score(y, bm_probs)\n",
        "ns_fpr, ns_tpr, _ = roc_curve(y, ns_probs)\n",
        "bm_fpr, bm_tpr, _ = roc_curve(y, bm_probs)\n",
        "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='Guess, auc=%.4f'%ns_auc)\n",
        "plt.plot(bm_fpr, bm_tpr, marker='.', label='Model, auc=%.4f'%bm_auc)\n",
        "plt.title('ROC')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "print(\"%s: %.2f%%\" %('AUC',bm_auc*100.0))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFMb6rGNj2Ug"
      },
      "source": [
        "t = time.time()\n",
        "time.strftime('%Y-%m-%d %H:%M:%S %Z', time.localtime(t))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-mEgDrQjUzF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}