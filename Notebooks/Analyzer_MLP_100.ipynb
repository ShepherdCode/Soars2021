{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Analyzer_MLP_100.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxjDXgzOuzm9"
      },
      "source": [
        "# Analyzer\n",
        "\n",
        "Statistically, visually, and through machine learning compare mRNA and lncRNA sequences from GENCODE v38.\n",
        "\n",
        "Assume the user downloaded files from GENCODE v38 [FTP](http://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_38/)\n",
        "to a subdirectory called data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWH1hul6uKub"
      },
      "source": [
        "## Import Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMB8T39CuJ2Y",
        "outputId": "55561bdb-5ed3-45b2-cd2a-5a467bbf1ea4"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import pandas as pd\n",
        "import gzip\n",
        "from scipy.stats import chisquare, kstest\n",
        "import sys\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Embedding,Dropout\n",
        "from keras.layers import Flatten,TimeDistributed\n",
        "from keras.losses import BinaryCrossentropy\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    IN_COLAB = True\n",
        "    print(\"On Google CoLab, mount cloud-local file, get our code from GitHub.\")\n",
        "    PATH='/content/drive/'\n",
        "    #drive.mount(PATH,force_remount=True)  # hardly ever need this\n",
        "    drive.mount(PATH)    # Google will require login credentials\n",
        "    DATAPATH=PATH+'My Drive/data/'  # must end in \"/\"\n",
        "    import requests\n",
        "    s = requests.get('https://raw.githubusercontent.com/ShepherdCode/Soars2021/master/SimTools/RNA_describe.py')\n",
        "    with open('RNA_describe.py', 'w') as f:\n",
        "      f.write(s.text)  # writes to cloud local, delete the file later?\n",
        "    s = requests.get('https://raw.githubusercontent.com/ShepherdCode/Soars2021/master/SimTools/GenCodeTools.py')\n",
        "    with open ('GenCodeTools.py', 'w') as f:\n",
        "      f.write(s.text)\n",
        "    s = requests.get('https://raw.githubusercontent.com/ShepherdCode/Soars2021/master/SimTools/plot_generator.py')\n",
        "    with open('plot_generator.py', 'w') as f:\n",
        "      f.write(s.text)\n",
        "    s = requests.get('https://raw.githubusercontent.com/ShepherdCode/Soars2021/master/SimTools/KmerTools.py')\n",
        "    with open('KmerTools.py', 'w') as f:\n",
        "      f.write(s.text)  \n",
        "    from KmerTools import KmerTools\n",
        "    from RNA_describe import *\n",
        "    from GenCodeTools import *\n",
        "    from plot_generator import *\n",
        "except:\n",
        "    print(\"CoLab not working. On my PC, use relative paths.\")\n",
        "    IN_COLAB = False\n",
        "    DATAPATH='../data/'  # must end in \"/\"\n",
        "    sys.path.append(\"..\") # append parent dir in order to use sibling dirs\n",
        "    from SimTools.RNA_describe import *\n",
        "    from SimTools.GenCodeTools import *\n",
        "    from SimTools.plot_generator import *\n",
        "    from SimTools.KmerTools import KmerTools\n",
        "\n",
        "MODELPATH=\"BestModel\"  # saved on cloud instance and lost after logout\n",
        "#MODELPATH=DATAPATH+MODELPATH  # saved on Google Drive but requires login\n",
        "\n",
        "if not assert_imported_RNA_describe():\n",
        "    print(\"ERROR: Cannot use RNA_describe.\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "On Google CoLab, mount cloud-local file, get our code from GitHub.\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8RNNlZGsZN5"
      },
      "source": [
        "## Load GENCODE Data\n",
        "Loads GENCODE v38 data.\n",
        "\n",
        "Filters out mRNA sequences based on UTR check."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37JnfHgWt_-U",
        "outputId": "0f5e3a06-8f89-49aa-887b-394378e206cb"
      },
      "source": [
        "PC_FILENAME='gencode.v38.pc_transcripts.fa.gz'\n",
        "NC_FILENAME='gencode.v38.lncRNA_transcripts.fa.gz'\n",
        "PC_FULLPATH=DATAPATH+PC_FILENAME\n",
        "NC_FULLPATH=DATAPATH+NC_FILENAME\n",
        "loader=GenCodeLoader()\n",
        "loader.set_label(1)\n",
        "loader.set_check_list(None) \n",
        "loader.set_check_utr(True)\n",
        "pcdf=loader.load_file(PC_FULLPATH)\n",
        "print(\"PC seqs loaded:\",len(pcdf))\n",
        "loader.set_label(0)\n",
        "loader.set_check_list(None)\n",
        "loader.set_check_utr(False)\n",
        "ncdf=loader.load_file(NC_FULLPATH)\n",
        "print(\"NC seqs loaded:\",len(ncdf))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PC seqs loaded: 70825\n",
            "NC seqs loaded: 48752\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0y1XAPLvr_G"
      },
      "source": [
        "## Process Sequences\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "si3kGF7kTZ3M"
      },
      "source": [
        "Generate Sample of GENCODE Data Set\n",
        "\n",
        "Apply Length Constraints\n",
        "\n",
        "Validate Sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6V7WMCLN3l1q"
      },
      "source": [
        "APPLY_SUBSET = True             #Option to subset the data\n",
        "MINIMUM_SEQUENCE_LENGTH = 200   #Minimum exclusive length to filter out sequences by\n",
        "MAXIMUM_SEQUENCE_LENGTH = 4000  #Maximum inclusive length to filter out sequences by\n",
        "SAMPLE_FRACTION = 1             #What fraction of the GenCode data set to take a sample of\n",
        "REPRODUCABILITY_SEED = 314159   #Use to reproduce random sampling"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANtZknso53FT",
        "outputId": "6829fcbc-fd8a-4bce-9893-1f2ad73bd143"
      },
      "source": [
        "if APPLY_SUBSET:\n",
        "    pcdf = pcdf.sample(frac=SAMPLE_FRACTION, random_state=REPRODUCABILITY_SEED)\n",
        "    ncdf = ncdf.sample(frac=SAMPLE_FRACTION, random_state=REPRODUCABILITY_SEED)\n",
        "\n",
        "    print('PC sample size:', len(pcdf))\n",
        "    print('NC sample size:', len(ncdf))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PC sample size: 70825\n",
            "NC sample size: 48752\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xe5boK2NTWH1"
      },
      "source": [
        "Apply Length Constraints"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ga4K3Aw4sJd"
      },
      "source": [
        "def subset_list_by_len_bounds(input_list, min_len, max_len):\n",
        "  return list(filter(lambda x: len(x) > min_len and len(x) <= max_len, input_list))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7pejW0g1lnR",
        "outputId": "f77ea024-2c15-49aa-d8bc-9801c768ce34"
      },
      "source": [
        "pc_sequences = pcdf['sequence'].tolist()\n",
        "nc_sequences = ncdf['sequence'].tolist()\n",
        "\n",
        "if APPLY_SUBSET:\n",
        "    pc_sequences = subset_list_by_len_bounds(pc_sequences, MINIMUM_SEQUENCE_LENGTH, MAXIMUM_SEQUENCE_LENGTH)\n",
        "    nc_sequences = subset_list_by_len_bounds(nc_sequences, MINIMUM_SEQUENCE_LENGTH, MAXIMUM_SEQUENCE_LENGTH)\n",
        "\n",
        "    print('PC seqs in length range','('+str(MINIMUM_SEQUENCE_LENGTH),'-',str(MAXIMUM_SEQUENCE_LENGTH)+'):', len(pc_sequences))\n",
        "    print('NC seqs in length range','('+str(MINIMUM_SEQUENCE_LENGTH),'-',str(MAXIMUM_SEQUENCE_LENGTH)+'):', len(nc_sequences))\n",
        "\n",
        "#Garbage collection\n",
        "pcdf = None\n",
        "ncdf = None"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PC seqs in length range (200 - 4000): 55381\n",
            "NC seqs in length range (200 - 4000): 46912\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlFZ2BHDS_kJ"
      },
      "source": [
        "Validate Sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYBUZyfxSRZs",
        "outputId": "bd72bca4-237d-4544-de17-cf7fca584d7c"
      },
      "source": [
        "def valid_sequence(seq):\n",
        "    \"\"\"\n",
        "    Checks if the given sequences if valid.\n",
        "    \"\"\"\n",
        "    for chr in seq:\n",
        "        if not (chr == 'A' or chr == 'C' or chr == 'G' or chr == 'T'):\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "def validate_sequences(sequences):\n",
        "    \"\"\"\n",
        "    Validate the given list of sequences\n",
        "    \"\"\"\n",
        "    i = 0\n",
        "    while i < len(sequences):\n",
        "        if valid_sequence(sequences[i]):\n",
        "            i += 1\n",
        "        else:\n",
        "            sequences.remove(sequences[i])\n",
        "\n",
        "validate_sequences(pc_sequences)\n",
        "validate_sequences(nc_sequences)\n",
        "\n",
        "print('Valid PC seqs:', len(pc_sequences))\n",
        "print('Valid NC seqs:', len(nc_sequences))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Valid PC seqs: 55381\n",
            "Valid NC seqs: 46911\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVWspW8e4v2b"
      },
      "source": [
        "## Set Up MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNxOORWM41Xi"
      },
      "source": [
        "RATIO_TRAIN_TO_TEST = 0.99\n",
        "INPUT_SHAPE = (None, 4**3 + 4**2 + 4**1)\n",
        "MAX_K = 3\n",
        "NEURONS = 16\n",
        "DROP_RATE = 0.1\n",
        "EPOCHS = 1500\n",
        "SPLITS = 5\n",
        "FOLDS = 1"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nf_MTH3a63ZA"
      },
      "source": [
        "Define what is training data and what is testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2mKPv1B5oIR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "105ceec0-fc18-4c9e-e90c-be9c21e20c4e"
      },
      "source": [
        "NUM_PC = len(pc_sequences)\n",
        "NUM_PC_TRAIN = int(NUM_PC * RATIO_TRAIN_TO_TEST)\n",
        "NUM_NC = len(nc_sequences)\n",
        "NUM_NC_TRAIN = int(NUM_NC * RATIO_TRAIN_TO_TEST)\n",
        "\n",
        "pc_train = pc_sequences[:NUM_PC_TRAIN]\n",
        "pc_test = pc_sequences[NUM_PC_TRAIN:]\n",
        "nc_train = nc_sequences[:NUM_NC_TRAIN]\n",
        "nc_test = nc_sequences[NUM_NC_TRAIN:]\n",
        "\n",
        "print('PC TRAIN:', len(pc_train))\n",
        "print('NC TRAIN', len(nc_train))\n",
        "print('PC TEST:', len(pc_test))\n",
        "print('NC TEST:', len(nc_test))\n",
        "\n",
        "#Garbage Collection (this makes re-running the MLP a pain)\n",
        "#pc_sequences = None\n",
        "#nc_sequences = None"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PC TRAIN: 54827\n",
            "NC TRAIN 46441\n",
            "PC TEST: 554\n",
            "NC TEST: 470\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DOlou8Z7XU_"
      },
      "source": [
        "Prepare the Inputs and the Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MVxtNEc69NO"
      },
      "source": [
        "def prepare_x_and_y(seqs1, seqs0):\n",
        "    \"\"\"\n",
        "    From Miller's MLP_GenCode_1??.\n",
        "    \"\"\"\n",
        "    len1=len(seqs1)\n",
        "    len0=len(seqs0)\n",
        "    total=len1+len0\n",
        "    L1=np.ones(len1,dtype=np.int8)\n",
        "    L0=np.zeros(len0,dtype=np.int8)\n",
        "    S1 = np.asarray(seqs1)\n",
        "    S0 = np.asarray(seqs0)\n",
        "    all_labels = np.concatenate((L1,L0))\n",
        "    all_seqs = np.concatenate((S1,S0))  \n",
        "    for i in range(0,len0):\n",
        "        all_labels[i*2] = L0[i]\n",
        "        all_seqs[i*2] = S0[i]\n",
        "        all_labels[i*2+1] = L1[i]\n",
        "        all_seqs[i*2+1] = S1[i]\n",
        "    return all_seqs,all_labels\n",
        "Xseq, y = prepare_x_and_y(pc_train, nc_train)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g46xCFPZ7xqF"
      },
      "source": [
        "def seqs_to_kmer_freqs(seqs, max_K):\n",
        "    \"\"\"\n",
        "    From Miller's MLP_GenCode_1??.\n",
        "    \"\"\"\n",
        "    tool = KmerTools()  # from SimTools\n",
        "    collection = []\n",
        "    for seq in seqs:\n",
        "        counts = tool.make_dict_upto_K(max_K)\n",
        "        # Last param should be True when using Harvester.\n",
        "        counts = tool.update_count_one_K(counts, max_K, seq, True)\n",
        "        # Given counts for K=3, Harvester fills in counts for K=1,2.\n",
        "        counts = tool.harvest_counts_from_K(counts, max_K)\n",
        "        fdict = tool.count_to_frequency(counts, max_K)\n",
        "        freqs = list(fdict.values())\n",
        "        collection.append(freqs)\n",
        "    return np.asarray(collection)\n",
        "\n",
        "Xfrq = seqs_to_kmer_freqs(Xseq, MAX_K)\n",
        "\n",
        "#Garbage Collection\n",
        "Xseq = None"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TS9xAqP8ClN"
      },
      "source": [
        "## Make and Train MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFI-Jwgc8Gv4",
        "outputId": "87d155f1-315f-4e88-8be7-b8ed5266fc72"
      },
      "source": [
        "def make_DNN():\n",
        "    \"\"\"\n",
        "    From Miller's MLP_GenCode_1??.\n",
        "    \"\"\"\n",
        "    dt=np.float32\n",
        "    print(\"make_DNN\")\n",
        "    print(\"input shape:\",INPUT_SHAPE)\n",
        "    dnn = Sequential()\n",
        "\n",
        "    dnn.add(Dense(NEURONS, activation=\"sigmoid\", dtype=dt))  # relu doesn't work as well\n",
        "    dnn.add(Dropout(DROP_RATE))\n",
        "\n",
        "    dnn.add(Dense(NEURONS, activation=\"sigmoid\", dtype=dt)) \n",
        "    dnn.add(Dropout(DROP_RATE))\n",
        "\n",
        "    dnn.add(Dense(1, activation=\"sigmoid\", dtype=dt))  \n",
        "\n",
        "    dnn.compile(optimizer='adam',    # adadelta doesn't work as well\n",
        "        loss=BinaryCrossentropy(from_logits=False),\n",
        "        metrics=['accuracy'])   # add to default metrics=loss\n",
        "    dnn.build(input_shape=INPUT_SHAPE) \n",
        "    return dnn\n",
        "model = make_DNN()\n",
        "print(model.summary())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "make_DNN\n",
            "input shape: (None, 84)\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 16)                1360      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 1,649\n",
            "Trainable params: 1,649\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIEUYjE18dQT"
      },
      "source": [
        "def do_cross_validation(X,y):\n",
        "    \"\"\"\n",
        "    From Miller's MLP_GenCode_1??.\n",
        "    \"\"\"\n",
        "    cv_scores = []\n",
        "    fold=0\n",
        "    #mycallbacks = [ModelCheckpoint(\n",
        "    #    filepath=MODELPATH, save_best_only=True, \n",
        "    #    monitor='val_accuracy', mode='max')]   \n",
        "    # When shuffle=True, the valid indices are a random subset.\n",
        "    splitter = KFold(n_splits=SPLITS, shuffle=True) \n",
        "    model = None\n",
        "    for train_index, valid_index in splitter.split(X):\n",
        "        if fold < FOLDS:\n",
        "            fold += 1\n",
        "            X_train=X[train_index] # inputs for training\n",
        "            y_train=y[train_index] # labels for training\n",
        "            X_valid=X[valid_index] # inputs for validation\n",
        "            y_valid=y[valid_index] # labels for validation\n",
        "            print(\"MODEL\")\n",
        "            # Call constructor on each CV. Else, continually improves the same model.\n",
        "            model = model = make_DNN()\n",
        "            print(\"FIT\")  # model.fit() implements learning\n",
        "            start_time=time.time()\n",
        "            history=model.fit(X_train, y_train, \n",
        "                epochs=EPOCHS, \n",
        "                verbose=1,  # ascii art while learning\n",
        "                # callbacks=mycallbacks,   # called at end of each epoch\n",
        "                validation_data=(X_valid,y_valid))\n",
        "            end_time=time.time()\n",
        "            elapsed_time=(end_time-start_time)                        \n",
        "            print(\"Fold %d, %d epochs, %d sec\"%(fold,EPOCHS,elapsed_time))\n",
        "            # print(history.history.keys())  # all these keys will be shown in figure\n",
        "            pd.DataFrame(history.history).plot(figsize=(8,5))\n",
        "            plt.grid(True)\n",
        "            plt.gca().set_ylim(0,1) # any losses > 1 will be off the scale\n",
        "            plt.show()\n",
        "    return model  # parameters at end of training"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6on9fVhr8ux_",
        "outputId": "20f2aa12-f520-4fa3-d1c6-db5442a5c385"
      },
      "source": [
        "last_model = do_cross_validation(Xfrq, y)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MODEL\n",
            "make_DNN\n",
            "input shape: (None, 84)\n",
            "FIT\n",
            "Epoch 1/1500\n",
            "2532/2532 [==============================] - 21s 2ms/step - loss: 0.6852 - accuracy: 0.5506 - val_loss: 0.6308 - val_accuracy: 0.6609\n",
            "Epoch 2/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.6327 - accuracy: 0.6495 - val_loss: 0.6109 - val_accuracy: 0.6737\n",
            "Epoch 3/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.6146 - accuracy: 0.6699 - val_loss: 0.5918 - val_accuracy: 0.6897\n",
            "Epoch 4/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5974 - accuracy: 0.6873 - val_loss: 0.5706 - val_accuracy: 0.7119\n",
            "Epoch 5/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5850 - accuracy: 0.6970 - val_loss: 0.5564 - val_accuracy: 0.7206\n",
            "Epoch 6/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5718 - accuracy: 0.7106 - val_loss: 0.5475 - val_accuracy: 0.7281\n",
            "Epoch 7/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5636 - accuracy: 0.7188 - val_loss: 0.5407 - val_accuracy: 0.7317\n",
            "Epoch 8/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5585 - accuracy: 0.7228 - val_loss: 0.5358 - val_accuracy: 0.7362\n",
            "Epoch 9/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5548 - accuracy: 0.7266 - val_loss: 0.5312 - val_accuracy: 0.7426\n",
            "Epoch 10/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5493 - accuracy: 0.7310 - val_loss: 0.5262 - val_accuracy: 0.7429\n",
            "Epoch 11/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5478 - accuracy: 0.7308 - val_loss: 0.5235 - val_accuracy: 0.7464\n",
            "Epoch 12/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5400 - accuracy: 0.7371 - val_loss: 0.5207 - val_accuracy: 0.7487\n",
            "Epoch 13/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5366 - accuracy: 0.7406 - val_loss: 0.5190 - val_accuracy: 0.7487\n",
            "Epoch 14/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5367 - accuracy: 0.7396 - val_loss: 0.5165 - val_accuracy: 0.7489\n",
            "Epoch 15/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5306 - accuracy: 0.7436 - val_loss: 0.5129 - val_accuracy: 0.7535\n",
            "Epoch 16/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5304 - accuracy: 0.7438 - val_loss: 0.5107 - val_accuracy: 0.7550\n",
            "Epoch 17/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5310 - accuracy: 0.7433 - val_loss: 0.5100 - val_accuracy: 0.7553\n",
            "Epoch 18/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5264 - accuracy: 0.7449 - val_loss: 0.5086 - val_accuracy: 0.7572\n",
            "Epoch 19/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5236 - accuracy: 0.7475 - val_loss: 0.5055 - val_accuracy: 0.7587\n",
            "Epoch 20/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5218 - accuracy: 0.7486 - val_loss: 0.5041 - val_accuracy: 0.7602\n",
            "Epoch 21/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5172 - accuracy: 0.7525 - val_loss: 0.5022 - val_accuracy: 0.7602\n",
            "Epoch 22/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5184 - accuracy: 0.7501 - val_loss: 0.5018 - val_accuracy: 0.7630\n",
            "Epoch 23/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5182 - accuracy: 0.7509 - val_loss: 0.4989 - val_accuracy: 0.7622\n",
            "Epoch 24/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5188 - accuracy: 0.7521 - val_loss: 0.4976 - val_accuracy: 0.7636\n",
            "Epoch 25/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5148 - accuracy: 0.7514 - val_loss: 0.4986 - val_accuracy: 0.7663\n",
            "Epoch 26/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5174 - accuracy: 0.7508 - val_loss: 0.4948 - val_accuracy: 0.7647\n",
            "Epoch 27/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5111 - accuracy: 0.7584 - val_loss: 0.4929 - val_accuracy: 0.7661\n",
            "Epoch 28/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5095 - accuracy: 0.7572 - val_loss: 0.4916 - val_accuracy: 0.7681\n",
            "Epoch 29/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5105 - accuracy: 0.7560 - val_loss: 0.4894 - val_accuracy: 0.7685\n",
            "Epoch 30/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5036 - accuracy: 0.7617 - val_loss: 0.4885 - val_accuracy: 0.7697\n",
            "Epoch 31/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5070 - accuracy: 0.7575 - val_loss: 0.4867 - val_accuracy: 0.7700\n",
            "Epoch 32/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5018 - accuracy: 0.7625 - val_loss: 0.4858 - val_accuracy: 0.7713\n",
            "Epoch 33/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5054 - accuracy: 0.7602 - val_loss: 0.4845 - val_accuracy: 0.7718\n",
            "Epoch 34/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5004 - accuracy: 0.7634 - val_loss: 0.4837 - val_accuracy: 0.7719\n",
            "Epoch 35/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4958 - accuracy: 0.7656 - val_loss: 0.4815 - val_accuracy: 0.7758\n",
            "Epoch 36/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5001 - accuracy: 0.7629 - val_loss: 0.4803 - val_accuracy: 0.7768\n",
            "Epoch 37/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4968 - accuracy: 0.7640 - val_loss: 0.4796 - val_accuracy: 0.7772\n",
            "Epoch 38/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4986 - accuracy: 0.7642 - val_loss: 0.4773 - val_accuracy: 0.7776\n",
            "Epoch 39/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4987 - accuracy: 0.7635 - val_loss: 0.4757 - val_accuracy: 0.7789\n",
            "Epoch 40/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4926 - accuracy: 0.7688 - val_loss: 0.4758 - val_accuracy: 0.7755\n",
            "Epoch 41/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4948 - accuracy: 0.7653 - val_loss: 0.4727 - val_accuracy: 0.7799\n",
            "Epoch 42/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4921 - accuracy: 0.7662 - val_loss: 0.4736 - val_accuracy: 0.7775\n",
            "Epoch 43/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4957 - accuracy: 0.7647 - val_loss: 0.4715 - val_accuracy: 0.7777\n",
            "Epoch 44/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4880 - accuracy: 0.7699 - val_loss: 0.4694 - val_accuracy: 0.7813\n",
            "Epoch 45/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4898 - accuracy: 0.7698 - val_loss: 0.4676 - val_accuracy: 0.7821\n",
            "Epoch 46/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4891 - accuracy: 0.7696 - val_loss: 0.4675 - val_accuracy: 0.7815\n",
            "Epoch 47/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4871 - accuracy: 0.7703 - val_loss: 0.4668 - val_accuracy: 0.7826\n",
            "Epoch 48/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4867 - accuracy: 0.7687 - val_loss: 0.4654 - val_accuracy: 0.7832\n",
            "Epoch 49/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4838 - accuracy: 0.7735 - val_loss: 0.4643 - val_accuracy: 0.7847\n",
            "Epoch 50/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4854 - accuracy: 0.7695 - val_loss: 0.4628 - val_accuracy: 0.7850\n",
            "Epoch 51/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4839 - accuracy: 0.7712 - val_loss: 0.4622 - val_accuracy: 0.7838\n",
            "Epoch 52/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4846 - accuracy: 0.7713 - val_loss: 0.4616 - val_accuracy: 0.7851\n",
            "Epoch 53/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4795 - accuracy: 0.7719 - val_loss: 0.4611 - val_accuracy: 0.7854\n",
            "Epoch 54/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4802 - accuracy: 0.7729 - val_loss: 0.4607 - val_accuracy: 0.7843\n",
            "Epoch 55/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4852 - accuracy: 0.7701 - val_loss: 0.4601 - val_accuracy: 0.7861\n",
            "Epoch 56/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4775 - accuracy: 0.7757 - val_loss: 0.4617 - val_accuracy: 0.7811\n",
            "Epoch 57/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4783 - accuracy: 0.7763 - val_loss: 0.4582 - val_accuracy: 0.7877\n",
            "Epoch 58/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4763 - accuracy: 0.7751 - val_loss: 0.4569 - val_accuracy: 0.7858\n",
            "Epoch 59/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4756 - accuracy: 0.7767 - val_loss: 0.4570 - val_accuracy: 0.7856\n",
            "Epoch 60/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4781 - accuracy: 0.7741 - val_loss: 0.4578 - val_accuracy: 0.7846\n",
            "Epoch 61/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4737 - accuracy: 0.7772 - val_loss: 0.4558 - val_accuracy: 0.7872\n",
            "Epoch 62/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4728 - accuracy: 0.7776 - val_loss: 0.4549 - val_accuracy: 0.7874\n",
            "Epoch 63/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4751 - accuracy: 0.7741 - val_loss: 0.4553 - val_accuracy: 0.7872\n",
            "Epoch 64/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4692 - accuracy: 0.7796 - val_loss: 0.4532 - val_accuracy: 0.7903\n",
            "Epoch 65/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4716 - accuracy: 0.7789 - val_loss: 0.4542 - val_accuracy: 0.7886\n",
            "Epoch 66/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4728 - accuracy: 0.7765 - val_loss: 0.4524 - val_accuracy: 0.7904\n",
            "Epoch 67/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4723 - accuracy: 0.7771 - val_loss: 0.4543 - val_accuracy: 0.7878\n",
            "Epoch 68/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4685 - accuracy: 0.7788 - val_loss: 0.4515 - val_accuracy: 0.7903\n",
            "Epoch 69/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4672 - accuracy: 0.7822 - val_loss: 0.4505 - val_accuracy: 0.7909\n",
            "Epoch 70/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4721 - accuracy: 0.7762 - val_loss: 0.4489 - val_accuracy: 0.7917\n",
            "Epoch 71/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4681 - accuracy: 0.7795 - val_loss: 0.4491 - val_accuracy: 0.7916\n",
            "Epoch 72/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4663 - accuracy: 0.7818 - val_loss: 0.4489 - val_accuracy: 0.7923\n",
            "Epoch 73/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4687 - accuracy: 0.7808 - val_loss: 0.4475 - val_accuracy: 0.7914\n",
            "Epoch 74/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4644 - accuracy: 0.7834 - val_loss: 0.4467 - val_accuracy: 0.7933\n",
            "Epoch 75/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4647 - accuracy: 0.7824 - val_loss: 0.4462 - val_accuracy: 0.7927\n",
            "Epoch 76/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4697 - accuracy: 0.7803 - val_loss: 0.4455 - val_accuracy: 0.7940\n",
            "Epoch 77/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4616 - accuracy: 0.7839 - val_loss: 0.4461 - val_accuracy: 0.7960\n",
            "Epoch 78/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4642 - accuracy: 0.7823 - val_loss: 0.4444 - val_accuracy: 0.7949\n",
            "Epoch 79/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4647 - accuracy: 0.7824 - val_loss: 0.4448 - val_accuracy: 0.7944\n",
            "Epoch 80/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4622 - accuracy: 0.7854 - val_loss: 0.4437 - val_accuracy: 0.7945\n",
            "Epoch 81/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4665 - accuracy: 0.7826 - val_loss: 0.4425 - val_accuracy: 0.7955\n",
            "Epoch 82/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4601 - accuracy: 0.7871 - val_loss: 0.4425 - val_accuracy: 0.7968\n",
            "Epoch 83/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4558 - accuracy: 0.7892 - val_loss: 0.4418 - val_accuracy: 0.7967\n",
            "Epoch 84/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4564 - accuracy: 0.7882 - val_loss: 0.4419 - val_accuracy: 0.7974\n",
            "Epoch 85/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4602 - accuracy: 0.7875 - val_loss: 0.4400 - val_accuracy: 0.7980\n",
            "Epoch 86/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4596 - accuracy: 0.7871 - val_loss: 0.4397 - val_accuracy: 0.7983\n",
            "Epoch 87/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4586 - accuracy: 0.7859 - val_loss: 0.4407 - val_accuracy: 0.7975\n",
            "Epoch 88/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4567 - accuracy: 0.7864 - val_loss: 0.4399 - val_accuracy: 0.7969\n",
            "Epoch 89/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4579 - accuracy: 0.7873 - val_loss: 0.4391 - val_accuracy: 0.7984\n",
            "Epoch 90/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4589 - accuracy: 0.7872 - val_loss: 0.4375 - val_accuracy: 0.7996\n",
            "Epoch 91/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4611 - accuracy: 0.7874 - val_loss: 0.4371 - val_accuracy: 0.7994\n",
            "Epoch 92/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4572 - accuracy: 0.7876 - val_loss: 0.4370 - val_accuracy: 0.7995\n",
            "Epoch 93/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4556 - accuracy: 0.7916 - val_loss: 0.4380 - val_accuracy: 0.7989\n",
            "Epoch 94/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4540 - accuracy: 0.7896 - val_loss: 0.4376 - val_accuracy: 0.7991\n",
            "Epoch 95/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4542 - accuracy: 0.7910 - val_loss: 0.4358 - val_accuracy: 0.7998\n",
            "Epoch 96/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4527 - accuracy: 0.7918 - val_loss: 0.4371 - val_accuracy: 0.8001\n",
            "Epoch 97/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4519 - accuracy: 0.7918 - val_loss: 0.4356 - val_accuracy: 0.7997\n",
            "Epoch 98/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4526 - accuracy: 0.7905 - val_loss: 0.4352 - val_accuracy: 0.8001\n",
            "Epoch 99/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4534 - accuracy: 0.7909 - val_loss: 0.4351 - val_accuracy: 0.8014\n",
            "Epoch 100/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4523 - accuracy: 0.7909 - val_loss: 0.4342 - val_accuracy: 0.8011\n",
            "Epoch 101/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4534 - accuracy: 0.7897 - val_loss: 0.4339 - val_accuracy: 0.8007\n",
            "Epoch 102/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4514 - accuracy: 0.7936 - val_loss: 0.4334 - val_accuracy: 0.8011\n",
            "Epoch 103/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4502 - accuracy: 0.7927 - val_loss: 0.4345 - val_accuracy: 0.8017\n",
            "Epoch 104/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4486 - accuracy: 0.7946 - val_loss: 0.4332 - val_accuracy: 0.8020\n",
            "Epoch 105/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4502 - accuracy: 0.7929 - val_loss: 0.4328 - val_accuracy: 0.8022\n",
            "Epoch 106/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.4515 - accuracy: 0.7906 - val_loss: 0.4328 - val_accuracy: 0.8025\n",
            "Epoch 107/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4494 - accuracy: 0.7935 - val_loss: 0.4329 - val_accuracy: 0.8026\n",
            "Epoch 108/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4496 - accuracy: 0.7941 - val_loss: 0.4325 - val_accuracy: 0.8015\n",
            "Epoch 109/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4505 - accuracy: 0.7925 - val_loss: 0.4317 - val_accuracy: 0.8016\n",
            "Epoch 110/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4515 - accuracy: 0.7912 - val_loss: 0.4309 - val_accuracy: 0.8031\n",
            "Epoch 111/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4491 - accuracy: 0.7936 - val_loss: 0.4304 - val_accuracy: 0.8039\n",
            "Epoch 112/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4443 - accuracy: 0.7969 - val_loss: 0.4304 - val_accuracy: 0.8036\n",
            "Epoch 113/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4465 - accuracy: 0.7943 - val_loss: 0.4300 - val_accuracy: 0.8036\n",
            "Epoch 114/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4465 - accuracy: 0.7963 - val_loss: 0.4292 - val_accuracy: 0.8037\n",
            "Epoch 115/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4452 - accuracy: 0.7966 - val_loss: 0.4308 - val_accuracy: 0.8040\n",
            "Epoch 116/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4452 - accuracy: 0.7962 - val_loss: 0.4296 - val_accuracy: 0.8043\n",
            "Epoch 117/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4444 - accuracy: 0.7961 - val_loss: 0.4290 - val_accuracy: 0.8056\n",
            "Epoch 118/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4501 - accuracy: 0.7926 - val_loss: 0.4287 - val_accuracy: 0.8041\n",
            "Epoch 119/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4470 - accuracy: 0.7955 - val_loss: 0.4281 - val_accuracy: 0.8054\n",
            "Epoch 120/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4449 - accuracy: 0.7955 - val_loss: 0.4277 - val_accuracy: 0.8056\n",
            "Epoch 121/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4440 - accuracy: 0.7981 - val_loss: 0.4290 - val_accuracy: 0.8039\n",
            "Epoch 122/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4461 - accuracy: 0.7941 - val_loss: 0.4294 - val_accuracy: 0.8031\n",
            "Epoch 123/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4416 - accuracy: 0.7982 - val_loss: 0.4272 - val_accuracy: 0.8052\n",
            "Epoch 124/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4414 - accuracy: 0.7993 - val_loss: 0.4279 - val_accuracy: 0.8050\n",
            "Epoch 125/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4445 - accuracy: 0.7956 - val_loss: 0.4276 - val_accuracy: 0.8054\n",
            "Epoch 126/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4426 - accuracy: 0.7981 - val_loss: 0.4272 - val_accuracy: 0.8044\n",
            "Epoch 127/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4448 - accuracy: 0.7979 - val_loss: 0.4263 - val_accuracy: 0.8065\n",
            "Epoch 128/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4425 - accuracy: 0.7984 - val_loss: 0.4263 - val_accuracy: 0.8051\n",
            "Epoch 129/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4386 - accuracy: 0.8023 - val_loss: 0.4265 - val_accuracy: 0.8072\n",
            "Epoch 130/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4404 - accuracy: 0.7998 - val_loss: 0.4250 - val_accuracy: 0.8067\n",
            "Epoch 131/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4447 - accuracy: 0.7964 - val_loss: 0.4255 - val_accuracy: 0.8075\n",
            "Epoch 132/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4427 - accuracy: 0.7959 - val_loss: 0.4248 - val_accuracy: 0.8066\n",
            "Epoch 133/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4403 - accuracy: 0.7979 - val_loss: 0.4268 - val_accuracy: 0.8073\n",
            "Epoch 134/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4425 - accuracy: 0.7984 - val_loss: 0.4244 - val_accuracy: 0.8071\n",
            "Epoch 135/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4403 - accuracy: 0.8017 - val_loss: 0.4249 - val_accuracy: 0.8065\n",
            "Epoch 136/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4403 - accuracy: 0.7983 - val_loss: 0.4255 - val_accuracy: 0.8073\n",
            "Epoch 137/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4440 - accuracy: 0.7969 - val_loss: 0.4242 - val_accuracy: 0.8081\n",
            "Epoch 138/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4415 - accuracy: 0.7989 - val_loss: 0.4232 - val_accuracy: 0.8078\n",
            "Epoch 139/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4366 - accuracy: 0.8028 - val_loss: 0.4235 - val_accuracy: 0.8082\n",
            "Epoch 140/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4408 - accuracy: 0.8003 - val_loss: 0.4231 - val_accuracy: 0.8079\n",
            "Epoch 141/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4391 - accuracy: 0.8003 - val_loss: 0.4233 - val_accuracy: 0.8080\n",
            "Epoch 142/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4350 - accuracy: 0.8035 - val_loss: 0.4238 - val_accuracy: 0.8070\n",
            "Epoch 143/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4352 - accuracy: 0.8014 - val_loss: 0.4222 - val_accuracy: 0.8076\n",
            "Epoch 144/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4332 - accuracy: 0.8028 - val_loss: 0.4221 - val_accuracy: 0.8090\n",
            "Epoch 145/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4399 - accuracy: 0.7989 - val_loss: 0.4226 - val_accuracy: 0.8081\n",
            "Epoch 146/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4358 - accuracy: 0.8014 - val_loss: 0.4218 - val_accuracy: 0.8087\n",
            "Epoch 147/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4383 - accuracy: 0.8014 - val_loss: 0.4224 - val_accuracy: 0.8093\n",
            "Epoch 148/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4393 - accuracy: 0.8004 - val_loss: 0.4211 - val_accuracy: 0.8090\n",
            "Epoch 149/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4369 - accuracy: 0.8020 - val_loss: 0.4209 - val_accuracy: 0.8091\n",
            "Epoch 150/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4318 - accuracy: 0.8043 - val_loss: 0.4221 - val_accuracy: 0.8103\n",
            "Epoch 151/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4385 - accuracy: 0.8007 - val_loss: 0.4204 - val_accuracy: 0.8104\n",
            "Epoch 152/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4395 - accuracy: 0.8004 - val_loss: 0.4197 - val_accuracy: 0.8102\n",
            "Epoch 153/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4384 - accuracy: 0.7999 - val_loss: 0.4212 - val_accuracy: 0.8098\n",
            "Epoch 154/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4367 - accuracy: 0.8032 - val_loss: 0.4205 - val_accuracy: 0.8104\n",
            "Epoch 155/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4338 - accuracy: 0.8026 - val_loss: 0.4206 - val_accuracy: 0.8089\n",
            "Epoch 156/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4388 - accuracy: 0.8000 - val_loss: 0.4193 - val_accuracy: 0.8105\n",
            "Epoch 157/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4326 - accuracy: 0.8036 - val_loss: 0.4194 - val_accuracy: 0.8100\n",
            "Epoch 158/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4322 - accuracy: 0.8036 - val_loss: 0.4192 - val_accuracy: 0.8105\n",
            "Epoch 159/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4375 - accuracy: 0.8016 - val_loss: 0.4185 - val_accuracy: 0.8109\n",
            "Epoch 160/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4335 - accuracy: 0.8056 - val_loss: 0.4188 - val_accuracy: 0.8119\n",
            "Epoch 161/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4335 - accuracy: 0.8031 - val_loss: 0.4181 - val_accuracy: 0.8101\n",
            "Epoch 162/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4330 - accuracy: 0.8040 - val_loss: 0.4182 - val_accuracy: 0.8102\n",
            "Epoch 163/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4322 - accuracy: 0.8040 - val_loss: 0.4178 - val_accuracy: 0.8117\n",
            "Epoch 164/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4314 - accuracy: 0.8063 - val_loss: 0.4183 - val_accuracy: 0.8126\n",
            "Epoch 165/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4319 - accuracy: 0.8056 - val_loss: 0.4188 - val_accuracy: 0.8111\n",
            "Epoch 166/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4338 - accuracy: 0.8046 - val_loss: 0.4200 - val_accuracy: 0.8095\n",
            "Epoch 167/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4321 - accuracy: 0.8047 - val_loss: 0.4175 - val_accuracy: 0.8121\n",
            "Epoch 168/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4340 - accuracy: 0.8026 - val_loss: 0.4180 - val_accuracy: 0.8112\n",
            "Epoch 169/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4303 - accuracy: 0.8044 - val_loss: 0.4191 - val_accuracy: 0.8110\n",
            "Epoch 170/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4314 - accuracy: 0.8045 - val_loss: 0.4176 - val_accuracy: 0.8113\n",
            "Epoch 171/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4340 - accuracy: 0.8043 - val_loss: 0.4177 - val_accuracy: 0.8111\n",
            "Epoch 172/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4298 - accuracy: 0.8064 - val_loss: 0.4181 - val_accuracy: 0.8116\n",
            "Epoch 173/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4311 - accuracy: 0.8051 - val_loss: 0.4165 - val_accuracy: 0.8127\n",
            "Epoch 174/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4308 - accuracy: 0.8058 - val_loss: 0.4161 - val_accuracy: 0.8134\n",
            "Epoch 175/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4318 - accuracy: 0.8058 - val_loss: 0.4160 - val_accuracy: 0.8128\n",
            "Epoch 176/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4281 - accuracy: 0.8071 - val_loss: 0.4168 - val_accuracy: 0.8113\n",
            "Epoch 177/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4268 - accuracy: 0.8080 - val_loss: 0.4150 - val_accuracy: 0.8132\n",
            "Epoch 178/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4297 - accuracy: 0.8053 - val_loss: 0.4153 - val_accuracy: 0.8127\n",
            "Epoch 179/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4293 - accuracy: 0.8056 - val_loss: 0.4152 - val_accuracy: 0.8124\n",
            "Epoch 180/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4286 - accuracy: 0.8082 - val_loss: 0.4153 - val_accuracy: 0.8125\n",
            "Epoch 181/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4290 - accuracy: 0.8064 - val_loss: 0.4163 - val_accuracy: 0.8127\n",
            "Epoch 182/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4280 - accuracy: 0.8098 - val_loss: 0.4150 - val_accuracy: 0.8120\n",
            "Epoch 183/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4270 - accuracy: 0.8088 - val_loss: 0.4166 - val_accuracy: 0.8116\n",
            "Epoch 184/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4267 - accuracy: 0.8076 - val_loss: 0.4148 - val_accuracy: 0.8132\n",
            "Epoch 185/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4281 - accuracy: 0.8063 - val_loss: 0.4142 - val_accuracy: 0.8128\n",
            "Epoch 186/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4261 - accuracy: 0.8101 - val_loss: 0.4149 - val_accuracy: 0.8145\n",
            "Epoch 187/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4287 - accuracy: 0.8048 - val_loss: 0.4146 - val_accuracy: 0.8128\n",
            "Epoch 188/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4298 - accuracy: 0.8078 - val_loss: 0.4141 - val_accuracy: 0.8133\n",
            "Epoch 189/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4300 - accuracy: 0.8069 - val_loss: 0.4143 - val_accuracy: 0.8127\n",
            "Epoch 190/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4271 - accuracy: 0.8090 - val_loss: 0.4148 - val_accuracy: 0.8132\n",
            "Epoch 191/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4285 - accuracy: 0.8076 - val_loss: 0.4156 - val_accuracy: 0.8129\n",
            "Epoch 192/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4252 - accuracy: 0.8085 - val_loss: 0.4132 - val_accuracy: 0.8142\n",
            "Epoch 193/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4273 - accuracy: 0.8068 - val_loss: 0.4138 - val_accuracy: 0.8144\n",
            "Epoch 194/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4289 - accuracy: 0.8055 - val_loss: 0.4133 - val_accuracy: 0.8140\n",
            "Epoch 195/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4236 - accuracy: 0.8091 - val_loss: 0.4145 - val_accuracy: 0.8129\n",
            "Epoch 196/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4231 - accuracy: 0.8095 - val_loss: 0.4127 - val_accuracy: 0.8147\n",
            "Epoch 197/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4260 - accuracy: 0.8105 - val_loss: 0.4125 - val_accuracy: 0.8159\n",
            "Epoch 198/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4230 - accuracy: 0.8105 - val_loss: 0.4126 - val_accuracy: 0.8149\n",
            "Epoch 199/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4309 - accuracy: 0.8059 - val_loss: 0.4128 - val_accuracy: 0.8148\n",
            "Epoch 200/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4264 - accuracy: 0.8085 - val_loss: 0.4132 - val_accuracy: 0.8140\n",
            "Epoch 201/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4245 - accuracy: 0.8083 - val_loss: 0.4123 - val_accuracy: 0.8149\n",
            "Epoch 202/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4266 - accuracy: 0.8084 - val_loss: 0.4123 - val_accuracy: 0.8154\n",
            "Epoch 203/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4247 - accuracy: 0.8090 - val_loss: 0.4121 - val_accuracy: 0.8154\n",
            "Epoch 204/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4227 - accuracy: 0.8111 - val_loss: 0.4116 - val_accuracy: 0.8157\n",
            "Epoch 205/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4234 - accuracy: 0.8094 - val_loss: 0.4118 - val_accuracy: 0.8152\n",
            "Epoch 206/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4253 - accuracy: 0.8098 - val_loss: 0.4112 - val_accuracy: 0.8155\n",
            "Epoch 207/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4246 - accuracy: 0.8089 - val_loss: 0.4111 - val_accuracy: 0.8163\n",
            "Epoch 208/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4230 - accuracy: 0.8086 - val_loss: 0.4108 - val_accuracy: 0.8165\n",
            "Epoch 209/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4218 - accuracy: 0.8116 - val_loss: 0.4111 - val_accuracy: 0.8157\n",
            "Epoch 210/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4247 - accuracy: 0.8087 - val_loss: 0.4111 - val_accuracy: 0.8166\n",
            "Epoch 211/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4200 - accuracy: 0.8115 - val_loss: 0.4111 - val_accuracy: 0.8164\n",
            "Epoch 212/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4223 - accuracy: 0.8128 - val_loss: 0.4103 - val_accuracy: 0.8168\n",
            "Epoch 213/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4228 - accuracy: 0.8099 - val_loss: 0.4103 - val_accuracy: 0.8160\n",
            "Epoch 214/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4231 - accuracy: 0.8109 - val_loss: 0.4139 - val_accuracy: 0.8140\n",
            "Epoch 215/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4204 - accuracy: 0.8115 - val_loss: 0.4108 - val_accuracy: 0.8165\n",
            "Epoch 216/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4232 - accuracy: 0.8119 - val_loss: 0.4099 - val_accuracy: 0.8172\n",
            "Epoch 217/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4198 - accuracy: 0.8113 - val_loss: 0.4103 - val_accuracy: 0.8170\n",
            "Epoch 218/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4248 - accuracy: 0.8077 - val_loss: 0.4100 - val_accuracy: 0.8165\n",
            "Epoch 219/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4214 - accuracy: 0.8106 - val_loss: 0.4119 - val_accuracy: 0.8149\n",
            "Epoch 220/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4265 - accuracy: 0.8077 - val_loss: 0.4088 - val_accuracy: 0.8176\n",
            "Epoch 221/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4215 - accuracy: 0.8110 - val_loss: 0.4094 - val_accuracy: 0.8172\n",
            "Epoch 222/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4202 - accuracy: 0.8143 - val_loss: 0.4094 - val_accuracy: 0.8178\n",
            "Epoch 223/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4188 - accuracy: 0.8136 - val_loss: 0.4090 - val_accuracy: 0.8175\n",
            "Epoch 224/1500\n",
            "2532/2532 [==============================] - 8s 3ms/step - loss: 0.4240 - accuracy: 0.8102 - val_loss: 0.4092 - val_accuracy: 0.8180\n",
            "Epoch 225/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4197 - accuracy: 0.8125 - val_loss: 0.4087 - val_accuracy: 0.8177\n",
            "Epoch 226/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4246 - accuracy: 0.8086 - val_loss: 0.4083 - val_accuracy: 0.8178\n",
            "Epoch 227/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4247 - accuracy: 0.8104 - val_loss: 0.4079 - val_accuracy: 0.8185\n",
            "Epoch 228/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4222 - accuracy: 0.8108 - val_loss: 0.4084 - val_accuracy: 0.8178\n",
            "Epoch 229/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4214 - accuracy: 0.8125 - val_loss: 0.4076 - val_accuracy: 0.8187\n",
            "Epoch 230/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4219 - accuracy: 0.8100 - val_loss: 0.4086 - val_accuracy: 0.8173\n",
            "Epoch 231/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4198 - accuracy: 0.8125 - val_loss: 0.4082 - val_accuracy: 0.8185\n",
            "Epoch 232/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4188 - accuracy: 0.8140 - val_loss: 0.4087 - val_accuracy: 0.8179\n",
            "Epoch 233/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4210 - accuracy: 0.8104 - val_loss: 0.4099 - val_accuracy: 0.8164\n",
            "Epoch 234/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4198 - accuracy: 0.8129 - val_loss: 0.4082 - val_accuracy: 0.8185\n",
            "Epoch 235/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4201 - accuracy: 0.8115 - val_loss: 0.4077 - val_accuracy: 0.8189\n",
            "Epoch 236/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4168 - accuracy: 0.8154 - val_loss: 0.4085 - val_accuracy: 0.8186\n",
            "Epoch 237/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4226 - accuracy: 0.8102 - val_loss: 0.4081 - val_accuracy: 0.8185\n",
            "Epoch 238/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4194 - accuracy: 0.8137 - val_loss: 0.4064 - val_accuracy: 0.8198\n",
            "Epoch 239/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4204 - accuracy: 0.8131 - val_loss: 0.4072 - val_accuracy: 0.8193\n",
            "Epoch 240/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4226 - accuracy: 0.8126 - val_loss: 0.4069 - val_accuracy: 0.8198\n",
            "Epoch 241/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4183 - accuracy: 0.8152 - val_loss: 0.4078 - val_accuracy: 0.8179\n",
            "Epoch 242/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4180 - accuracy: 0.8158 - val_loss: 0.4092 - val_accuracy: 0.8172\n",
            "Epoch 243/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4207 - accuracy: 0.8102 - val_loss: 0.4070 - val_accuracy: 0.8192\n",
            "Epoch 244/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4179 - accuracy: 0.8152 - val_loss: 0.4068 - val_accuracy: 0.8201\n",
            "Epoch 245/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4185 - accuracy: 0.8126 - val_loss: 0.4072 - val_accuracy: 0.8184\n",
            "Epoch 246/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4181 - accuracy: 0.8130 - val_loss: 0.4077 - val_accuracy: 0.8184\n",
            "Epoch 247/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4190 - accuracy: 0.8158 - val_loss: 0.4072 - val_accuracy: 0.8194\n",
            "Epoch 248/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4195 - accuracy: 0.8131 - val_loss: 0.4068 - val_accuracy: 0.8194\n",
            "Epoch 249/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4192 - accuracy: 0.8154 - val_loss: 0.4076 - val_accuracy: 0.8188\n",
            "Epoch 250/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4175 - accuracy: 0.8144 - val_loss: 0.4076 - val_accuracy: 0.8181\n",
            "Epoch 251/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4158 - accuracy: 0.8158 - val_loss: 0.4063 - val_accuracy: 0.8198\n",
            "Epoch 252/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4201 - accuracy: 0.8121 - val_loss: 0.4069 - val_accuracy: 0.8189\n",
            "Epoch 253/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4183 - accuracy: 0.8115 - val_loss: 0.4061 - val_accuracy: 0.8207\n",
            "Epoch 254/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4169 - accuracy: 0.8139 - val_loss: 0.4053 - val_accuracy: 0.8214\n",
            "Epoch 255/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4178 - accuracy: 0.8111 - val_loss: 0.4058 - val_accuracy: 0.8201\n",
            "Epoch 256/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4178 - accuracy: 0.8127 - val_loss: 0.4061 - val_accuracy: 0.8192\n",
            "Epoch 257/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4173 - accuracy: 0.8143 - val_loss: 0.4065 - val_accuracy: 0.8193\n",
            "Epoch 258/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4146 - accuracy: 0.8173 - val_loss: 0.4058 - val_accuracy: 0.8209\n",
            "Epoch 259/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4178 - accuracy: 0.8137 - val_loss: 0.4055 - val_accuracy: 0.8218\n",
            "Epoch 260/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4213 - accuracy: 0.8108 - val_loss: 0.4048 - val_accuracy: 0.8223\n",
            "Epoch 261/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4202 - accuracy: 0.8137 - val_loss: 0.4072 - val_accuracy: 0.8188\n",
            "Epoch 262/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4201 - accuracy: 0.8138 - val_loss: 0.4076 - val_accuracy: 0.8187\n",
            "Epoch 263/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4189 - accuracy: 0.8133 - val_loss: 0.4073 - val_accuracy: 0.8184\n",
            "Epoch 264/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4180 - accuracy: 0.8131 - val_loss: 0.4051 - val_accuracy: 0.8211\n",
            "Epoch 265/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4166 - accuracy: 0.8124 - val_loss: 0.4054 - val_accuracy: 0.8195\n",
            "Epoch 266/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4159 - accuracy: 0.8164 - val_loss: 0.4059 - val_accuracy: 0.8197\n",
            "Epoch 267/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4141 - accuracy: 0.8174 - val_loss: 0.4040 - val_accuracy: 0.8221\n",
            "Epoch 268/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4165 - accuracy: 0.8141 - val_loss: 0.4055 - val_accuracy: 0.8205\n",
            "Epoch 269/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4157 - accuracy: 0.8151 - val_loss: 0.4050 - val_accuracy: 0.8214\n",
            "Epoch 270/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4172 - accuracy: 0.8140 - val_loss: 0.4055 - val_accuracy: 0.8201\n",
            "Epoch 271/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4138 - accuracy: 0.8163 - val_loss: 0.4051 - val_accuracy: 0.8206\n",
            "Epoch 272/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4134 - accuracy: 0.8162 - val_loss: 0.4043 - val_accuracy: 0.8217\n",
            "Epoch 273/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4200 - accuracy: 0.8126 - val_loss: 0.4043 - val_accuracy: 0.8208\n",
            "Epoch 274/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4158 - accuracy: 0.8155 - val_loss: 0.4042 - val_accuracy: 0.8218\n",
            "Epoch 275/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4147 - accuracy: 0.8159 - val_loss: 0.4049 - val_accuracy: 0.8216\n",
            "Epoch 276/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4172 - accuracy: 0.8132 - val_loss: 0.4048 - val_accuracy: 0.8201\n",
            "Epoch 277/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4193 - accuracy: 0.8132 - val_loss: 0.4034 - val_accuracy: 0.8224\n",
            "Epoch 278/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4141 - accuracy: 0.8157 - val_loss: 0.4039 - val_accuracy: 0.8226\n",
            "Epoch 279/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4201 - accuracy: 0.8130 - val_loss: 0.4047 - val_accuracy: 0.8199\n",
            "Epoch 280/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4115 - accuracy: 0.8178 - val_loss: 0.4040 - val_accuracy: 0.8219\n",
            "Epoch 281/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4116 - accuracy: 0.8181 - val_loss: 0.4055 - val_accuracy: 0.8192\n",
            "Epoch 282/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4176 - accuracy: 0.8146 - val_loss: 0.4041 - val_accuracy: 0.8207\n",
            "Epoch 283/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4140 - accuracy: 0.8169 - val_loss: 0.4034 - val_accuracy: 0.8216\n",
            "Epoch 284/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4149 - accuracy: 0.8175 - val_loss: 0.4037 - val_accuracy: 0.8222\n",
            "Epoch 285/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4122 - accuracy: 0.8178 - val_loss: 0.4033 - val_accuracy: 0.8219\n",
            "Epoch 286/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4155 - accuracy: 0.8156 - val_loss: 0.4040 - val_accuracy: 0.8211\n",
            "Epoch 287/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4168 - accuracy: 0.8145 - val_loss: 0.4026 - val_accuracy: 0.8227\n",
            "Epoch 288/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4143 - accuracy: 0.8160 - val_loss: 0.4050 - val_accuracy: 0.8188\n",
            "Epoch 289/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4161 - accuracy: 0.8186 - val_loss: 0.4037 - val_accuracy: 0.8211\n",
            "Epoch 290/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4146 - accuracy: 0.8139 - val_loss: 0.4034 - val_accuracy: 0.8209\n",
            "Epoch 291/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4135 - accuracy: 0.8143 - val_loss: 0.4025 - val_accuracy: 0.8226\n",
            "Epoch 292/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4176 - accuracy: 0.8155 - val_loss: 0.4037 - val_accuracy: 0.8211\n",
            "Epoch 293/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4143 - accuracy: 0.8179 - val_loss: 0.4019 - val_accuracy: 0.8228\n",
            "Epoch 294/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4155 - accuracy: 0.8156 - val_loss: 0.4026 - val_accuracy: 0.8226\n",
            "Epoch 295/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4132 - accuracy: 0.8173 - val_loss: 0.4031 - val_accuracy: 0.8216\n",
            "Epoch 296/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4144 - accuracy: 0.8163 - val_loss: 0.4035 - val_accuracy: 0.8212\n",
            "Epoch 297/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4149 - accuracy: 0.8151 - val_loss: 0.4028 - val_accuracy: 0.8219\n",
            "Epoch 298/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4090 - accuracy: 0.8201 - val_loss: 0.4029 - val_accuracy: 0.8217\n",
            "Epoch 299/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4158 - accuracy: 0.8152 - val_loss: 0.4021 - val_accuracy: 0.8225\n",
            "Epoch 300/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4130 - accuracy: 0.8179 - val_loss: 0.4022 - val_accuracy: 0.8222\n",
            "Epoch 301/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4147 - accuracy: 0.8167 - val_loss: 0.4023 - val_accuracy: 0.8226\n",
            "Epoch 302/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4145 - accuracy: 0.8157 - val_loss: 0.4026 - val_accuracy: 0.8221\n",
            "Epoch 303/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4115 - accuracy: 0.8173 - val_loss: 0.4019 - val_accuracy: 0.8228\n",
            "Epoch 304/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4129 - accuracy: 0.8174 - val_loss: 0.4038 - val_accuracy: 0.8198\n",
            "Epoch 305/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4125 - accuracy: 0.8176 - val_loss: 0.4042 - val_accuracy: 0.8201\n",
            "Epoch 306/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4112 - accuracy: 0.8190 - val_loss: 0.4021 - val_accuracy: 0.8228\n",
            "Epoch 307/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4087 - accuracy: 0.8184 - val_loss: 0.4032 - val_accuracy: 0.8207\n",
            "Epoch 308/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4129 - accuracy: 0.8165 - val_loss: 0.4007 - val_accuracy: 0.8231\n",
            "Epoch 309/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4141 - accuracy: 0.8159 - val_loss: 0.4020 - val_accuracy: 0.8222\n",
            "Epoch 310/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4109 - accuracy: 0.8182 - val_loss: 0.4011 - val_accuracy: 0.8226\n",
            "Epoch 311/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4143 - accuracy: 0.8164 - val_loss: 0.4013 - val_accuracy: 0.8231\n",
            "Epoch 312/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4107 - accuracy: 0.8178 - val_loss: 0.4019 - val_accuracy: 0.8223\n",
            "Epoch 313/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.4119 - accuracy: 0.8165 - val_loss: 0.4023 - val_accuracy: 0.8211\n",
            "Epoch 314/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4108 - accuracy: 0.8186 - val_loss: 0.4022 - val_accuracy: 0.8222\n",
            "Epoch 315/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4133 - accuracy: 0.8153 - val_loss: 0.4020 - val_accuracy: 0.8222\n",
            "Epoch 316/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4112 - accuracy: 0.8194 - val_loss: 0.4011 - val_accuracy: 0.8233\n",
            "Epoch 317/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4104 - accuracy: 0.8199 - val_loss: 0.4012 - val_accuracy: 0.8233\n",
            "Epoch 318/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4140 - accuracy: 0.8173 - val_loss: 0.4009 - val_accuracy: 0.8232\n",
            "Epoch 319/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4102 - accuracy: 0.8185 - val_loss: 0.4004 - val_accuracy: 0.8237\n",
            "Epoch 320/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4117 - accuracy: 0.8188 - val_loss: 0.4009 - val_accuracy: 0.8235\n",
            "Epoch 321/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4151 - accuracy: 0.8150 - val_loss: 0.4012 - val_accuracy: 0.8228\n",
            "Epoch 322/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4145 - accuracy: 0.8163 - val_loss: 0.4011 - val_accuracy: 0.8232\n",
            "Epoch 323/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4120 - accuracy: 0.8180 - val_loss: 0.3996 - val_accuracy: 0.8238\n",
            "Epoch 324/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4136 - accuracy: 0.8176 - val_loss: 0.3997 - val_accuracy: 0.8239\n",
            "Epoch 325/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4119 - accuracy: 0.8203 - val_loss: 0.4009 - val_accuracy: 0.8219\n",
            "Epoch 326/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4111 - accuracy: 0.8182 - val_loss: 0.3998 - val_accuracy: 0.8242\n",
            "Epoch 327/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4103 - accuracy: 0.8194 - val_loss: 0.4005 - val_accuracy: 0.8233\n",
            "Epoch 328/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4091 - accuracy: 0.8190 - val_loss: 0.4003 - val_accuracy: 0.8243\n",
            "Epoch 329/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4067 - accuracy: 0.8214 - val_loss: 0.3998 - val_accuracy: 0.8237\n",
            "Epoch 330/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4088 - accuracy: 0.8198 - val_loss: 0.3995 - val_accuracy: 0.8235\n",
            "Epoch 331/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4109 - accuracy: 0.8167 - val_loss: 0.3999 - val_accuracy: 0.8238\n",
            "Epoch 332/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4114 - accuracy: 0.8168 - val_loss: 0.4000 - val_accuracy: 0.8230\n",
            "Epoch 333/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4097 - accuracy: 0.8220 - val_loss: 0.3998 - val_accuracy: 0.8239\n",
            "Epoch 334/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4093 - accuracy: 0.8192 - val_loss: 0.3993 - val_accuracy: 0.8242\n",
            "Epoch 335/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4122 - accuracy: 0.8168 - val_loss: 0.4000 - val_accuracy: 0.8236\n",
            "Epoch 336/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4114 - accuracy: 0.8181 - val_loss: 0.3991 - val_accuracy: 0.8236\n",
            "Epoch 337/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4143 - accuracy: 0.8162 - val_loss: 0.3996 - val_accuracy: 0.8239\n",
            "Epoch 338/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4110 - accuracy: 0.8190 - val_loss: 0.3995 - val_accuracy: 0.8236\n",
            "Epoch 339/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4077 - accuracy: 0.8205 - val_loss: 0.3993 - val_accuracy: 0.8241\n",
            "Epoch 340/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4114 - accuracy: 0.8178 - val_loss: 0.3987 - val_accuracy: 0.8235\n",
            "Epoch 341/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4092 - accuracy: 0.8187 - val_loss: 0.3990 - val_accuracy: 0.8238\n",
            "Epoch 342/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4095 - accuracy: 0.8181 - val_loss: 0.3988 - val_accuracy: 0.8243\n",
            "Epoch 343/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4141 - accuracy: 0.8176 - val_loss: 0.3990 - val_accuracy: 0.8244\n",
            "Epoch 344/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4089 - accuracy: 0.8209 - val_loss: 0.3994 - val_accuracy: 0.8243\n",
            "Epoch 345/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4095 - accuracy: 0.8188 - val_loss: 0.3990 - val_accuracy: 0.8247\n",
            "Epoch 346/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4099 - accuracy: 0.8194 - val_loss: 0.3994 - val_accuracy: 0.8242\n",
            "Epoch 347/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4079 - accuracy: 0.8185 - val_loss: 0.3993 - val_accuracy: 0.8235\n",
            "Epoch 348/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4099 - accuracy: 0.8180 - val_loss: 0.3991 - val_accuracy: 0.8245\n",
            "Epoch 349/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4106 - accuracy: 0.8189 - val_loss: 0.3992 - val_accuracy: 0.8238\n",
            "Epoch 350/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4063 - accuracy: 0.8214 - val_loss: 0.3994 - val_accuracy: 0.8237\n",
            "Epoch 351/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4125 - accuracy: 0.8162 - val_loss: 0.3991 - val_accuracy: 0.8240\n",
            "Epoch 352/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4052 - accuracy: 0.8216 - val_loss: 0.3985 - val_accuracy: 0.8252\n",
            "Epoch 353/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4078 - accuracy: 0.8186 - val_loss: 0.3984 - val_accuracy: 0.8245\n",
            "Epoch 354/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4085 - accuracy: 0.8197 - val_loss: 0.3992 - val_accuracy: 0.8232\n",
            "Epoch 355/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4103 - accuracy: 0.8193 - val_loss: 0.3979 - val_accuracy: 0.8247\n",
            "Epoch 356/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4065 - accuracy: 0.8213 - val_loss: 0.3974 - val_accuracy: 0.8252\n",
            "Epoch 357/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4075 - accuracy: 0.8211 - val_loss: 0.3981 - val_accuracy: 0.8247\n",
            "Epoch 358/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4079 - accuracy: 0.8221 - val_loss: 0.3972 - val_accuracy: 0.8254\n",
            "Epoch 359/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4089 - accuracy: 0.8192 - val_loss: 0.3992 - val_accuracy: 0.8242\n",
            "Epoch 360/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4069 - accuracy: 0.8205 - val_loss: 0.3980 - val_accuracy: 0.8251\n",
            "Epoch 361/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4081 - accuracy: 0.8196 - val_loss: 0.3974 - val_accuracy: 0.8258\n",
            "Epoch 362/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4087 - accuracy: 0.8208 - val_loss: 0.3979 - val_accuracy: 0.8250\n",
            "Epoch 363/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4095 - accuracy: 0.8198 - val_loss: 0.3970 - val_accuracy: 0.8249\n",
            "Epoch 364/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4083 - accuracy: 0.8210 - val_loss: 0.3975 - val_accuracy: 0.8246\n",
            "Epoch 365/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4067 - accuracy: 0.8229 - val_loss: 0.3980 - val_accuracy: 0.8243\n",
            "Epoch 366/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4063 - accuracy: 0.8211 - val_loss: 0.3971 - val_accuracy: 0.8255\n",
            "Epoch 367/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4090 - accuracy: 0.8187 - val_loss: 0.3986 - val_accuracy: 0.8241\n",
            "Epoch 368/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4055 - accuracy: 0.8232 - val_loss: 0.3967 - val_accuracy: 0.8259\n",
            "Epoch 369/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4064 - accuracy: 0.8222 - val_loss: 0.3981 - val_accuracy: 0.8251\n",
            "Epoch 370/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4074 - accuracy: 0.8210 - val_loss: 0.3975 - val_accuracy: 0.8250\n",
            "Epoch 371/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4103 - accuracy: 0.8204 - val_loss: 0.3982 - val_accuracy: 0.8245\n",
            "Epoch 372/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4086 - accuracy: 0.8203 - val_loss: 0.3979 - val_accuracy: 0.8240\n",
            "Epoch 373/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4075 - accuracy: 0.8203 - val_loss: 0.3972 - val_accuracy: 0.8256\n",
            "Epoch 374/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4112 - accuracy: 0.8173 - val_loss: 0.3976 - val_accuracy: 0.8241\n",
            "Epoch 375/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4080 - accuracy: 0.8206 - val_loss: 0.3966 - val_accuracy: 0.8251\n",
            "Epoch 376/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4036 - accuracy: 0.8226 - val_loss: 0.3959 - val_accuracy: 0.8258\n",
            "Epoch 377/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4072 - accuracy: 0.8211 - val_loss: 0.3966 - val_accuracy: 0.8245\n",
            "Epoch 378/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4128 - accuracy: 0.8170 - val_loss: 0.3970 - val_accuracy: 0.8249\n",
            "Epoch 379/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4036 - accuracy: 0.8213 - val_loss: 0.3952 - val_accuracy: 0.8267\n",
            "Epoch 380/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4053 - accuracy: 0.8222 - val_loss: 0.3963 - val_accuracy: 0.8258\n",
            "Epoch 381/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4050 - accuracy: 0.8217 - val_loss: 0.3957 - val_accuracy: 0.8259\n",
            "Epoch 382/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4084 - accuracy: 0.8214 - val_loss: 0.3966 - val_accuracy: 0.8263\n",
            "Epoch 383/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4057 - accuracy: 0.8200 - val_loss: 0.3960 - val_accuracy: 0.8263\n",
            "Epoch 384/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4058 - accuracy: 0.8224 - val_loss: 0.3961 - val_accuracy: 0.8256\n",
            "Epoch 385/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4086 - accuracy: 0.8201 - val_loss: 0.3955 - val_accuracy: 0.8259\n",
            "Epoch 386/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4051 - accuracy: 0.8220 - val_loss: 0.3954 - val_accuracy: 0.8259\n",
            "Epoch 387/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4018 - accuracy: 0.8249 - val_loss: 0.3960 - val_accuracy: 0.8271\n",
            "Epoch 388/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4049 - accuracy: 0.8206 - val_loss: 0.3955 - val_accuracy: 0.8273\n",
            "Epoch 389/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4088 - accuracy: 0.8195 - val_loss: 0.3949 - val_accuracy: 0.8264\n",
            "Epoch 390/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4032 - accuracy: 0.8246 - val_loss: 0.3958 - val_accuracy: 0.8261\n",
            "Epoch 391/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4061 - accuracy: 0.8209 - val_loss: 0.3954 - val_accuracy: 0.8264\n",
            "Epoch 392/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4069 - accuracy: 0.8223 - val_loss: 0.3948 - val_accuracy: 0.8268\n",
            "Epoch 393/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4056 - accuracy: 0.8231 - val_loss: 0.3953 - val_accuracy: 0.8259\n",
            "Epoch 394/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4081 - accuracy: 0.8204 - val_loss: 0.3951 - val_accuracy: 0.8268\n",
            "Epoch 395/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4031 - accuracy: 0.8220 - val_loss: 0.3953 - val_accuracy: 0.8268\n",
            "Epoch 396/1500\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4044 - accuracy: 0.8204 - val_loss: 0.3952 - val_accuracy: 0.8260\n",
            "Epoch 397/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4030 - accuracy: 0.8222 - val_loss: 0.3947 - val_accuracy: 0.8264\n",
            "Epoch 398/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4019 - accuracy: 0.8250 - val_loss: 0.3961 - val_accuracy: 0.8257\n",
            "Epoch 399/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4025 - accuracy: 0.8229 - val_loss: 0.3946 - val_accuracy: 0.8274\n",
            "Epoch 400/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4034 - accuracy: 0.8232 - val_loss: 0.3951 - val_accuracy: 0.8274\n",
            "Epoch 401/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4052 - accuracy: 0.8233 - val_loss: 0.3956 - val_accuracy: 0.8262\n",
            "Epoch 402/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4029 - accuracy: 0.8226 - val_loss: 0.3942 - val_accuracy: 0.8271\n",
            "Epoch 403/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3992 - accuracy: 0.8266 - val_loss: 0.3960 - val_accuracy: 0.8258\n",
            "Epoch 404/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4030 - accuracy: 0.8217 - val_loss: 0.3940 - val_accuracy: 0.8277\n",
            "Epoch 405/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4015 - accuracy: 0.8238 - val_loss: 0.3948 - val_accuracy: 0.8272\n",
            "Epoch 406/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4066 - accuracy: 0.8207 - val_loss: 0.3946 - val_accuracy: 0.8282\n",
            "Epoch 407/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4043 - accuracy: 0.8206 - val_loss: 0.3949 - val_accuracy: 0.8264\n",
            "Epoch 408/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4064 - accuracy: 0.8205 - val_loss: 0.3944 - val_accuracy: 0.8266\n",
            "Epoch 409/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4034 - accuracy: 0.8216 - val_loss: 0.3942 - val_accuracy: 0.8268\n",
            "Epoch 410/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4035 - accuracy: 0.8241 - val_loss: 0.3942 - val_accuracy: 0.8271\n",
            "Epoch 411/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4003 - accuracy: 0.8257 - val_loss: 0.3933 - val_accuracy: 0.8283\n",
            "Epoch 412/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4039 - accuracy: 0.8230 - val_loss: 0.3937 - val_accuracy: 0.8278\n",
            "Epoch 413/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4055 - accuracy: 0.8215 - val_loss: 0.3939 - val_accuracy: 0.8276\n",
            "Epoch 414/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4033 - accuracy: 0.8237 - val_loss: 0.3932 - val_accuracy: 0.8279\n",
            "Epoch 415/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4063 - accuracy: 0.8221 - val_loss: 0.3936 - val_accuracy: 0.8273\n",
            "Epoch 416/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4029 - accuracy: 0.8228 - val_loss: 0.3941 - val_accuracy: 0.8286\n",
            "Epoch 417/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4046 - accuracy: 0.8220 - val_loss: 0.3935 - val_accuracy: 0.8287\n",
            "Epoch 418/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4025 - accuracy: 0.8227 - val_loss: 0.3936 - val_accuracy: 0.8280\n",
            "Epoch 419/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4051 - accuracy: 0.8220 - val_loss: 0.3929 - val_accuracy: 0.8285\n",
            "Epoch 420/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4034 - accuracy: 0.8237 - val_loss: 0.3938 - val_accuracy: 0.8273\n",
            "Epoch 421/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3997 - accuracy: 0.8268 - val_loss: 0.3932 - val_accuracy: 0.8288\n",
            "Epoch 422/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3998 - accuracy: 0.8257 - val_loss: 0.3951 - val_accuracy: 0.8268\n",
            "Epoch 423/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4022 - accuracy: 0.8239 - val_loss: 0.3942 - val_accuracy: 0.8268\n",
            "Epoch 424/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4033 - accuracy: 0.8228 - val_loss: 0.3926 - val_accuracy: 0.8293\n",
            "Epoch 425/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4048 - accuracy: 0.8231 - val_loss: 0.3927 - val_accuracy: 0.8290\n",
            "Epoch 426/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4039 - accuracy: 0.8242 - val_loss: 0.3929 - val_accuracy: 0.8284\n",
            "Epoch 427/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4062 - accuracy: 0.8231 - val_loss: 0.3925 - val_accuracy: 0.8290\n",
            "Epoch 428/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4009 - accuracy: 0.8260 - val_loss: 0.3938 - val_accuracy: 0.8275\n",
            "Epoch 429/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4056 - accuracy: 0.8228 - val_loss: 0.3927 - val_accuracy: 0.8295\n",
            "Epoch 430/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3990 - accuracy: 0.8263 - val_loss: 0.3933 - val_accuracy: 0.8283\n",
            "Epoch 431/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4035 - accuracy: 0.8215 - val_loss: 0.3928 - val_accuracy: 0.8290\n",
            "Epoch 432/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4005 - accuracy: 0.8234 - val_loss: 0.3928 - val_accuracy: 0.8288\n",
            "Epoch 433/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4041 - accuracy: 0.8241 - val_loss: 0.3932 - val_accuracy: 0.8281\n",
            "Epoch 434/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4000 - accuracy: 0.8248 - val_loss: 0.3920 - val_accuracy: 0.8292\n",
            "Epoch 435/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4005 - accuracy: 0.8258 - val_loss: 0.3930 - val_accuracy: 0.8290\n",
            "Epoch 436/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4048 - accuracy: 0.8235 - val_loss: 0.3927 - val_accuracy: 0.8283\n",
            "Epoch 437/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4037 - accuracy: 0.8246 - val_loss: 0.3930 - val_accuracy: 0.8277\n",
            "Epoch 438/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4005 - accuracy: 0.8260 - val_loss: 0.3920 - val_accuracy: 0.8292\n",
            "Epoch 439/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4032 - accuracy: 0.8240 - val_loss: 0.3923 - val_accuracy: 0.8285\n",
            "Epoch 440/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4002 - accuracy: 0.8251 - val_loss: 0.3926 - val_accuracy: 0.8289\n",
            "Epoch 441/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4016 - accuracy: 0.8258 - val_loss: 0.3924 - val_accuracy: 0.8299\n",
            "Epoch 442/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4028 - accuracy: 0.8230 - val_loss: 0.3924 - val_accuracy: 0.8294\n",
            "Epoch 443/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4012 - accuracy: 0.8239 - val_loss: 0.3919 - val_accuracy: 0.8296\n",
            "Epoch 444/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3980 - accuracy: 0.8264 - val_loss: 0.3927 - val_accuracy: 0.8282\n",
            "Epoch 445/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4039 - accuracy: 0.8234 - val_loss: 0.3931 - val_accuracy: 0.8283\n",
            "Epoch 446/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4010 - accuracy: 0.8229 - val_loss: 0.3923 - val_accuracy: 0.8299\n",
            "Epoch 447/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4030 - accuracy: 0.8227 - val_loss: 0.3932 - val_accuracy: 0.8278\n",
            "Epoch 448/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4019 - accuracy: 0.8242 - val_loss: 0.3919 - val_accuracy: 0.8305\n",
            "Epoch 449/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3991 - accuracy: 0.8267 - val_loss: 0.3916 - val_accuracy: 0.8297\n",
            "Epoch 450/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3988 - accuracy: 0.8247 - val_loss: 0.3911 - val_accuracy: 0.8296\n",
            "Epoch 451/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4018 - accuracy: 0.8234 - val_loss: 0.3919 - val_accuracy: 0.8294\n",
            "Epoch 452/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3969 - accuracy: 0.8255 - val_loss: 0.3912 - val_accuracy: 0.8300\n",
            "Epoch 453/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4008 - accuracy: 0.8237 - val_loss: 0.3916 - val_accuracy: 0.8301\n",
            "Epoch 454/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4068 - accuracy: 0.8233 - val_loss: 0.3913 - val_accuracy: 0.8297\n",
            "Epoch 455/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4014 - accuracy: 0.8239 - val_loss: 0.3912 - val_accuracy: 0.8296\n",
            "Epoch 456/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4002 - accuracy: 0.8238 - val_loss: 0.3911 - val_accuracy: 0.8304\n",
            "Epoch 457/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3985 - accuracy: 0.8255 - val_loss: 0.3921 - val_accuracy: 0.8294\n",
            "Epoch 458/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4012 - accuracy: 0.8246 - val_loss: 0.3920 - val_accuracy: 0.8302\n",
            "Epoch 459/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3966 - accuracy: 0.8257 - val_loss: 0.3911 - val_accuracy: 0.8303\n",
            "Epoch 460/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3995 - accuracy: 0.8249 - val_loss: 0.3930 - val_accuracy: 0.8281\n",
            "Epoch 461/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4012 - accuracy: 0.8253 - val_loss: 0.3914 - val_accuracy: 0.8298\n",
            "Epoch 462/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3997 - accuracy: 0.8252 - val_loss: 0.3914 - val_accuracy: 0.8298\n",
            "Epoch 463/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3996 - accuracy: 0.8261 - val_loss: 0.3916 - val_accuracy: 0.8299\n",
            "Epoch 464/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4026 - accuracy: 0.8230 - val_loss: 0.3909 - val_accuracy: 0.8307\n",
            "Epoch 465/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4002 - accuracy: 0.8259 - val_loss: 0.3911 - val_accuracy: 0.8299\n",
            "Epoch 466/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3999 - accuracy: 0.8242 - val_loss: 0.3908 - val_accuracy: 0.8306\n",
            "Epoch 467/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3984 - accuracy: 0.8271 - val_loss: 0.3910 - val_accuracy: 0.8294\n",
            "Epoch 468/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4006 - accuracy: 0.8247 - val_loss: 0.3899 - val_accuracy: 0.8312\n",
            "Epoch 469/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3995 - accuracy: 0.8248 - val_loss: 0.3918 - val_accuracy: 0.8293\n",
            "Epoch 470/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3962 - accuracy: 0.8287 - val_loss: 0.3911 - val_accuracy: 0.8298\n",
            "Epoch 471/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4001 - accuracy: 0.8247 - val_loss: 0.3902 - val_accuracy: 0.8302\n",
            "Epoch 472/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3992 - accuracy: 0.8265 - val_loss: 0.3905 - val_accuracy: 0.8306\n",
            "Epoch 473/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4001 - accuracy: 0.8238 - val_loss: 0.3916 - val_accuracy: 0.8289\n",
            "Epoch 474/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3975 - accuracy: 0.8268 - val_loss: 0.3911 - val_accuracy: 0.8286\n",
            "Epoch 475/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4029 - accuracy: 0.8235 - val_loss: 0.3900 - val_accuracy: 0.8305\n",
            "Epoch 476/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3955 - accuracy: 0.8272 - val_loss: 0.3915 - val_accuracy: 0.8293\n",
            "Epoch 477/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3980 - accuracy: 0.8265 - val_loss: 0.3900 - val_accuracy: 0.8303\n",
            "Epoch 478/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3981 - accuracy: 0.8270 - val_loss: 0.3906 - val_accuracy: 0.8299\n",
            "Epoch 479/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3952 - accuracy: 0.8282 - val_loss: 0.3899 - val_accuracy: 0.8308\n",
            "Epoch 480/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3988 - accuracy: 0.8267 - val_loss: 0.3909 - val_accuracy: 0.8295\n",
            "Epoch 481/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3971 - accuracy: 0.8281 - val_loss: 0.3899 - val_accuracy: 0.8299\n",
            "Epoch 482/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4000 - accuracy: 0.8257 - val_loss: 0.3897 - val_accuracy: 0.8306\n",
            "Epoch 483/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3967 - accuracy: 0.8277 - val_loss: 0.3908 - val_accuracy: 0.8299\n",
            "Epoch 484/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3955 - accuracy: 0.8297 - val_loss: 0.3906 - val_accuracy: 0.8305\n",
            "Epoch 485/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3972 - accuracy: 0.8276 - val_loss: 0.3902 - val_accuracy: 0.8308\n",
            "Epoch 486/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3974 - accuracy: 0.8266 - val_loss: 0.3901 - val_accuracy: 0.8304\n",
            "Epoch 487/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3945 - accuracy: 0.8283 - val_loss: 0.3902 - val_accuracy: 0.8304\n",
            "Epoch 488/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3965 - accuracy: 0.8267 - val_loss: 0.3899 - val_accuracy: 0.8308\n",
            "Epoch 489/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3941 - accuracy: 0.8287 - val_loss: 0.3897 - val_accuracy: 0.8302\n",
            "Epoch 490/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3973 - accuracy: 0.8264 - val_loss: 0.3903 - val_accuracy: 0.8305\n",
            "Epoch 491/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3979 - accuracy: 0.8264 - val_loss: 0.3899 - val_accuracy: 0.8306\n",
            "Epoch 492/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3970 - accuracy: 0.8266 - val_loss: 0.3904 - val_accuracy: 0.8307\n",
            "Epoch 493/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3967 - accuracy: 0.8272 - val_loss: 0.3902 - val_accuracy: 0.8299\n",
            "Epoch 494/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3953 - accuracy: 0.8278 - val_loss: 0.3892 - val_accuracy: 0.8313\n",
            "Epoch 495/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3950 - accuracy: 0.8291 - val_loss: 0.3902 - val_accuracy: 0.8302\n",
            "Epoch 496/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3963 - accuracy: 0.8265 - val_loss: 0.3897 - val_accuracy: 0.8311\n",
            "Epoch 497/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3989 - accuracy: 0.8265 - val_loss: 0.3884 - val_accuracy: 0.8310\n",
            "Epoch 498/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3936 - accuracy: 0.8301 - val_loss: 0.3900 - val_accuracy: 0.8307\n",
            "Epoch 499/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3977 - accuracy: 0.8261 - val_loss: 0.3912 - val_accuracy: 0.8293\n",
            "Epoch 500/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3952 - accuracy: 0.8273 - val_loss: 0.3896 - val_accuracy: 0.8307\n",
            "Epoch 501/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3983 - accuracy: 0.8257 - val_loss: 0.3893 - val_accuracy: 0.8314\n",
            "Epoch 502/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3954 - accuracy: 0.8276 - val_loss: 0.3883 - val_accuracy: 0.8324\n",
            "Epoch 503/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3956 - accuracy: 0.8268 - val_loss: 0.3913 - val_accuracy: 0.8296\n",
            "Epoch 504/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3940 - accuracy: 0.8277 - val_loss: 0.3885 - val_accuracy: 0.8317\n",
            "Epoch 505/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3992 - accuracy: 0.8274 - val_loss: 0.3886 - val_accuracy: 0.8317\n",
            "Epoch 506/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3960 - accuracy: 0.8254 - val_loss: 0.3893 - val_accuracy: 0.8305\n",
            "Epoch 507/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3944 - accuracy: 0.8307 - val_loss: 0.3896 - val_accuracy: 0.8306\n",
            "Epoch 508/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3994 - accuracy: 0.8246 - val_loss: 0.3891 - val_accuracy: 0.8315\n",
            "Epoch 509/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3987 - accuracy: 0.8261 - val_loss: 0.3891 - val_accuracy: 0.8308\n",
            "Epoch 510/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3950 - accuracy: 0.8270 - val_loss: 0.3884 - val_accuracy: 0.8315\n",
            "Epoch 511/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3974 - accuracy: 0.8275 - val_loss: 0.3886 - val_accuracy: 0.8315\n",
            "Epoch 512/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3989 - accuracy: 0.8250 - val_loss: 0.3884 - val_accuracy: 0.8308\n",
            "Epoch 513/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3947 - accuracy: 0.8290 - val_loss: 0.3891 - val_accuracy: 0.8309\n",
            "Epoch 514/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3976 - accuracy: 0.8263 - val_loss: 0.3896 - val_accuracy: 0.8315\n",
            "Epoch 515/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3952 - accuracy: 0.8278 - val_loss: 0.3887 - val_accuracy: 0.8317\n",
            "Epoch 516/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3965 - accuracy: 0.8263 - val_loss: 0.3883 - val_accuracy: 0.8317\n",
            "Epoch 517/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3963 - accuracy: 0.8268 - val_loss: 0.3882 - val_accuracy: 0.8313\n",
            "Epoch 518/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3968 - accuracy: 0.8272 - val_loss: 0.3879 - val_accuracy: 0.8315\n",
            "Epoch 519/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3996 - accuracy: 0.8252 - val_loss: 0.3878 - val_accuracy: 0.8315\n",
            "Epoch 520/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3964 - accuracy: 0.8273 - val_loss: 0.3884 - val_accuracy: 0.8312\n",
            "Epoch 521/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3940 - accuracy: 0.8270 - val_loss: 0.3884 - val_accuracy: 0.8310\n",
            "Epoch 522/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3993 - accuracy: 0.8266 - val_loss: 0.3871 - val_accuracy: 0.8319\n",
            "Epoch 523/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3972 - accuracy: 0.8253 - val_loss: 0.3875 - val_accuracy: 0.8320\n",
            "Epoch 524/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3969 - accuracy: 0.8290 - val_loss: 0.3887 - val_accuracy: 0.8317\n",
            "Epoch 525/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3940 - accuracy: 0.8268 - val_loss: 0.3889 - val_accuracy: 0.8312\n",
            "Epoch 526/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3988 - accuracy: 0.8259 - val_loss: 0.3872 - val_accuracy: 0.8319\n",
            "Epoch 527/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3942 - accuracy: 0.8279 - val_loss: 0.3878 - val_accuracy: 0.8316\n",
            "Epoch 528/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3961 - accuracy: 0.8266 - val_loss: 0.3879 - val_accuracy: 0.8316\n",
            "Epoch 529/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3960 - accuracy: 0.8259 - val_loss: 0.3876 - val_accuracy: 0.8321\n",
            "Epoch 530/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3941 - accuracy: 0.8287 - val_loss: 0.3862 - val_accuracy: 0.8322\n",
            "Epoch 531/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3939 - accuracy: 0.8290 - val_loss: 0.3888 - val_accuracy: 0.8313\n",
            "Epoch 532/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3978 - accuracy: 0.8257 - val_loss: 0.3882 - val_accuracy: 0.8314\n",
            "Epoch 533/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3974 - accuracy: 0.8276 - val_loss: 0.3876 - val_accuracy: 0.8319\n",
            "Epoch 534/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3945 - accuracy: 0.8276 - val_loss: 0.3871 - val_accuracy: 0.8317\n",
            "Epoch 535/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3951 - accuracy: 0.8265 - val_loss: 0.3876 - val_accuracy: 0.8320\n",
            "Epoch 536/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3968 - accuracy: 0.8272 - val_loss: 0.3875 - val_accuracy: 0.8324\n",
            "Epoch 537/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3955 - accuracy: 0.8285 - val_loss: 0.3869 - val_accuracy: 0.8318\n",
            "Epoch 538/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3955 - accuracy: 0.8273 - val_loss: 0.3876 - val_accuracy: 0.8317\n",
            "Epoch 539/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3921 - accuracy: 0.8287 - val_loss: 0.3871 - val_accuracy: 0.8328\n",
            "Epoch 540/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3955 - accuracy: 0.8304 - val_loss: 0.3873 - val_accuracy: 0.8323\n",
            "Epoch 541/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3948 - accuracy: 0.8266 - val_loss: 0.3877 - val_accuracy: 0.8321\n",
            "Epoch 542/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3900 - accuracy: 0.8294 - val_loss: 0.3871 - val_accuracy: 0.8323\n",
            "Epoch 543/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3942 - accuracy: 0.8285 - val_loss: 0.3888 - val_accuracy: 0.8311\n",
            "Epoch 544/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3947 - accuracy: 0.8292 - val_loss: 0.3866 - val_accuracy: 0.8325\n",
            "Epoch 545/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3962 - accuracy: 0.8287 - val_loss: 0.3872 - val_accuracy: 0.8317\n",
            "Epoch 546/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3956 - accuracy: 0.8284 - val_loss: 0.3863 - val_accuracy: 0.8324\n",
            "Epoch 547/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3956 - accuracy: 0.8256 - val_loss: 0.3866 - val_accuracy: 0.8322\n",
            "Epoch 548/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3976 - accuracy: 0.8270 - val_loss: 0.3862 - val_accuracy: 0.8321\n",
            "Epoch 549/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3946 - accuracy: 0.8273 - val_loss: 0.3856 - val_accuracy: 0.8330\n",
            "Epoch 550/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3880 - accuracy: 0.8307 - val_loss: 0.3860 - val_accuracy: 0.8327\n",
            "Epoch 551/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3933 - accuracy: 0.8293 - val_loss: 0.3863 - val_accuracy: 0.8323\n",
            "Epoch 552/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3946 - accuracy: 0.8292 - val_loss: 0.3867 - val_accuracy: 0.8316\n",
            "Epoch 553/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3941 - accuracy: 0.8290 - val_loss: 0.3871 - val_accuracy: 0.8327\n",
            "Epoch 554/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3919 - accuracy: 0.8292 - val_loss: 0.3863 - val_accuracy: 0.8330\n",
            "Epoch 555/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3950 - accuracy: 0.8293 - val_loss: 0.3855 - val_accuracy: 0.8334\n",
            "Epoch 556/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3970 - accuracy: 0.8278 - val_loss: 0.3853 - val_accuracy: 0.8334\n",
            "Epoch 557/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3930 - accuracy: 0.8295 - val_loss: 0.3853 - val_accuracy: 0.8328\n",
            "Epoch 558/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3921 - accuracy: 0.8284 - val_loss: 0.3856 - val_accuracy: 0.8325\n",
            "Epoch 559/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3927 - accuracy: 0.8285 - val_loss: 0.3858 - val_accuracy: 0.8330\n",
            "Epoch 560/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3928 - accuracy: 0.8291 - val_loss: 0.3855 - val_accuracy: 0.8333\n",
            "Epoch 561/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3887 - accuracy: 0.8305 - val_loss: 0.3871 - val_accuracy: 0.8315\n",
            "Epoch 562/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3922 - accuracy: 0.8293 - val_loss: 0.3869 - val_accuracy: 0.8332\n",
            "Epoch 563/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3904 - accuracy: 0.8298 - val_loss: 0.3865 - val_accuracy: 0.8330\n",
            "Epoch 564/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3953 - accuracy: 0.8269 - val_loss: 0.3858 - val_accuracy: 0.8331\n",
            "Epoch 565/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3937 - accuracy: 0.8293 - val_loss: 0.3863 - val_accuracy: 0.8331\n",
            "Epoch 566/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3965 - accuracy: 0.8262 - val_loss: 0.3879 - val_accuracy: 0.8321\n",
            "Epoch 567/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3940 - accuracy: 0.8269 - val_loss: 0.3847 - val_accuracy: 0.8329\n",
            "Epoch 568/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3958 - accuracy: 0.8276 - val_loss: 0.3852 - val_accuracy: 0.8331\n",
            "Epoch 569/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3965 - accuracy: 0.8274 - val_loss: 0.3856 - val_accuracy: 0.8336\n",
            "Epoch 570/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3921 - accuracy: 0.8302 - val_loss: 0.3858 - val_accuracy: 0.8331\n",
            "Epoch 571/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3954 - accuracy: 0.8286 - val_loss: 0.3858 - val_accuracy: 0.8331\n",
            "Epoch 572/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3904 - accuracy: 0.8313 - val_loss: 0.3850 - val_accuracy: 0.8340\n",
            "Epoch 573/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3940 - accuracy: 0.8281 - val_loss: 0.3851 - val_accuracy: 0.8338\n",
            "Epoch 574/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3941 - accuracy: 0.8296 - val_loss: 0.3851 - val_accuracy: 0.8332\n",
            "Epoch 575/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3935 - accuracy: 0.8303 - val_loss: 0.3853 - val_accuracy: 0.8335\n",
            "Epoch 576/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3946 - accuracy: 0.8275 - val_loss: 0.3851 - val_accuracy: 0.8334\n",
            "Epoch 577/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3949 - accuracy: 0.8291 - val_loss: 0.3847 - val_accuracy: 0.8339\n",
            "Epoch 578/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3936 - accuracy: 0.8280 - val_loss: 0.3849 - val_accuracy: 0.8335\n",
            "Epoch 579/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3893 - accuracy: 0.8310 - val_loss: 0.3846 - val_accuracy: 0.8342\n",
            "Epoch 580/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3931 - accuracy: 0.8284 - val_loss: 0.3857 - val_accuracy: 0.8322\n",
            "Epoch 581/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3916 - accuracy: 0.8300 - val_loss: 0.3850 - val_accuracy: 0.8335\n",
            "Epoch 582/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3912 - accuracy: 0.8293 - val_loss: 0.3843 - val_accuracy: 0.8345\n",
            "Epoch 583/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3918 - accuracy: 0.8299 - val_loss: 0.3853 - val_accuracy: 0.8336\n",
            "Epoch 584/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3910 - accuracy: 0.8285 - val_loss: 0.3864 - val_accuracy: 0.8326\n",
            "Epoch 585/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3947 - accuracy: 0.8297 - val_loss: 0.3843 - val_accuracy: 0.8338\n",
            "Epoch 586/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3904 - accuracy: 0.8319 - val_loss: 0.3861 - val_accuracy: 0.8324\n",
            "Epoch 587/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3914 - accuracy: 0.8293 - val_loss: 0.3862 - val_accuracy: 0.8326\n",
            "Epoch 588/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3928 - accuracy: 0.8303 - val_loss: 0.3857 - val_accuracy: 0.8327\n",
            "Epoch 589/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3940 - accuracy: 0.8279 - val_loss: 0.3845 - val_accuracy: 0.8344\n",
            "Epoch 590/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3909 - accuracy: 0.8311 - val_loss: 0.3838 - val_accuracy: 0.8343\n",
            "Epoch 591/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3916 - accuracy: 0.8308 - val_loss: 0.3847 - val_accuracy: 0.8349\n",
            "Epoch 592/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3918 - accuracy: 0.8287 - val_loss: 0.3849 - val_accuracy: 0.8333\n",
            "Epoch 593/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3909 - accuracy: 0.8289 - val_loss: 0.3849 - val_accuracy: 0.8336\n",
            "Epoch 594/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3924 - accuracy: 0.8300 - val_loss: 0.3834 - val_accuracy: 0.8344\n",
            "Epoch 595/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3967 - accuracy: 0.8276 - val_loss: 0.3845 - val_accuracy: 0.8347\n",
            "Epoch 596/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3896 - accuracy: 0.8318 - val_loss: 0.3839 - val_accuracy: 0.8343\n",
            "Epoch 597/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3898 - accuracy: 0.8315 - val_loss: 0.3838 - val_accuracy: 0.8346\n",
            "Epoch 598/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3896 - accuracy: 0.8318 - val_loss: 0.3860 - val_accuracy: 0.8339\n",
            "Epoch 599/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3916 - accuracy: 0.8299 - val_loss: 0.3840 - val_accuracy: 0.8343\n",
            "Epoch 600/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3924 - accuracy: 0.8285 - val_loss: 0.3846 - val_accuracy: 0.8335\n",
            "Epoch 601/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3908 - accuracy: 0.8295 - val_loss: 0.3848 - val_accuracy: 0.8328\n",
            "Epoch 602/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3860 - accuracy: 0.8314 - val_loss: 0.3840 - val_accuracy: 0.8334\n",
            "Epoch 603/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3909 - accuracy: 0.8301 - val_loss: 0.3839 - val_accuracy: 0.8337\n",
            "Epoch 604/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3930 - accuracy: 0.8305 - val_loss: 0.3839 - val_accuracy: 0.8348\n",
            "Epoch 605/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3914 - accuracy: 0.8303 - val_loss: 0.3844 - val_accuracy: 0.8336\n",
            "Epoch 606/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3927 - accuracy: 0.8304 - val_loss: 0.3829 - val_accuracy: 0.8350\n",
            "Epoch 607/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3885 - accuracy: 0.8339 - val_loss: 0.3830 - val_accuracy: 0.8343\n",
            "Epoch 608/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3919 - accuracy: 0.8295 - val_loss: 0.3832 - val_accuracy: 0.8345\n",
            "Epoch 609/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3906 - accuracy: 0.8319 - val_loss: 0.3838 - val_accuracy: 0.8341\n",
            "Epoch 610/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3871 - accuracy: 0.8330 - val_loss: 0.3838 - val_accuracy: 0.8343\n",
            "Epoch 611/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3895 - accuracy: 0.8310 - val_loss: 0.3835 - val_accuracy: 0.8344\n",
            "Epoch 612/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3921 - accuracy: 0.8303 - val_loss: 0.3844 - val_accuracy: 0.8328\n",
            "Epoch 613/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3894 - accuracy: 0.8308 - val_loss: 0.3833 - val_accuracy: 0.8341\n",
            "Epoch 614/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3924 - accuracy: 0.8281 - val_loss: 0.3831 - val_accuracy: 0.8338\n",
            "Epoch 615/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3909 - accuracy: 0.8305 - val_loss: 0.3841 - val_accuracy: 0.8331\n",
            "Epoch 616/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3898 - accuracy: 0.8301 - val_loss: 0.3828 - val_accuracy: 0.8346\n",
            "Epoch 617/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3913 - accuracy: 0.8303 - val_loss: 0.3825 - val_accuracy: 0.8350\n",
            "Epoch 618/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3937 - accuracy: 0.8292 - val_loss: 0.3837 - val_accuracy: 0.8334\n",
            "Epoch 619/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3891 - accuracy: 0.8302 - val_loss: 0.3829 - val_accuracy: 0.8348\n",
            "Epoch 620/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3900 - accuracy: 0.8310 - val_loss: 0.3819 - val_accuracy: 0.8345\n",
            "Epoch 621/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3891 - accuracy: 0.8327 - val_loss: 0.3829 - val_accuracy: 0.8346\n",
            "Epoch 622/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3870 - accuracy: 0.8351 - val_loss: 0.3831 - val_accuracy: 0.8347\n",
            "Epoch 623/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3920 - accuracy: 0.8293 - val_loss: 0.3827 - val_accuracy: 0.8355\n",
            "Epoch 624/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3911 - accuracy: 0.8299 - val_loss: 0.3833 - val_accuracy: 0.8351\n",
            "Epoch 625/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3893 - accuracy: 0.8308 - val_loss: 0.3825 - val_accuracy: 0.8349\n",
            "Epoch 626/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3878 - accuracy: 0.8318 - val_loss: 0.3835 - val_accuracy: 0.8347\n",
            "Epoch 627/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3894 - accuracy: 0.8317 - val_loss: 0.3833 - val_accuracy: 0.8353\n",
            "Epoch 628/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3866 - accuracy: 0.8332 - val_loss: 0.3824 - val_accuracy: 0.8351\n",
            "Epoch 629/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3915 - accuracy: 0.8310 - val_loss: 0.3812 - val_accuracy: 0.8351\n",
            "Epoch 630/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3863 - accuracy: 0.8333 - val_loss: 0.3830 - val_accuracy: 0.8340\n",
            "Epoch 631/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3910 - accuracy: 0.8314 - val_loss: 0.3826 - val_accuracy: 0.8342\n",
            "Epoch 632/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3895 - accuracy: 0.8315 - val_loss: 0.3825 - val_accuracy: 0.8348\n",
            "Epoch 633/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3881 - accuracy: 0.8318 - val_loss: 0.3823 - val_accuracy: 0.8357\n",
            "Epoch 634/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3876 - accuracy: 0.8330 - val_loss: 0.3832 - val_accuracy: 0.8346\n",
            "Epoch 635/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3893 - accuracy: 0.8302 - val_loss: 0.3815 - val_accuracy: 0.8357\n",
            "Epoch 636/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3928 - accuracy: 0.8277 - val_loss: 0.3828 - val_accuracy: 0.8344\n",
            "Epoch 637/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3881 - accuracy: 0.8312 - val_loss: 0.3831 - val_accuracy: 0.8354\n",
            "Epoch 638/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3938 - accuracy: 0.8294 - val_loss: 0.3823 - val_accuracy: 0.8354\n",
            "Epoch 639/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3905 - accuracy: 0.8331 - val_loss: 0.3834 - val_accuracy: 0.8350\n",
            "Epoch 640/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3868 - accuracy: 0.8325 - val_loss: 0.3817 - val_accuracy: 0.8349\n",
            "Epoch 641/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3910 - accuracy: 0.8309 - val_loss: 0.3832 - val_accuracy: 0.8353\n",
            "Epoch 642/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3888 - accuracy: 0.8321 - val_loss: 0.3820 - val_accuracy: 0.8352\n",
            "Epoch 643/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3905 - accuracy: 0.8316 - val_loss: 0.3819 - val_accuracy: 0.8345\n",
            "Epoch 644/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3927 - accuracy: 0.8304 - val_loss: 0.3822 - val_accuracy: 0.8352\n",
            "Epoch 645/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3860 - accuracy: 0.8332 - val_loss: 0.3833 - val_accuracy: 0.8342\n",
            "Epoch 646/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3886 - accuracy: 0.8304 - val_loss: 0.3815 - val_accuracy: 0.8346\n",
            "Epoch 647/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3856 - accuracy: 0.8324 - val_loss: 0.3818 - val_accuracy: 0.8346\n",
            "Epoch 648/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3863 - accuracy: 0.8336 - val_loss: 0.3825 - val_accuracy: 0.8336\n",
            "Epoch 649/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3893 - accuracy: 0.8299 - val_loss: 0.3818 - val_accuracy: 0.8344\n",
            "Epoch 650/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3931 - accuracy: 0.8274 - val_loss: 0.3815 - val_accuracy: 0.8362\n",
            "Epoch 651/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3935 - accuracy: 0.8298 - val_loss: 0.3821 - val_accuracy: 0.8345\n",
            "Epoch 652/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3869 - accuracy: 0.8330 - val_loss: 0.3811 - val_accuracy: 0.8357\n",
            "Epoch 653/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3882 - accuracy: 0.8316 - val_loss: 0.3817 - val_accuracy: 0.8349\n",
            "Epoch 654/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3913 - accuracy: 0.8303 - val_loss: 0.3810 - val_accuracy: 0.8348\n",
            "Epoch 655/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3913 - accuracy: 0.8311 - val_loss: 0.3817 - val_accuracy: 0.8342\n",
            "Epoch 656/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3904 - accuracy: 0.8311 - val_loss: 0.3811 - val_accuracy: 0.8363\n",
            "Epoch 657/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3907 - accuracy: 0.8318 - val_loss: 0.3811 - val_accuracy: 0.8354\n",
            "Epoch 658/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3892 - accuracy: 0.8317 - val_loss: 0.3815 - val_accuracy: 0.8353\n",
            "Epoch 659/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3900 - accuracy: 0.8320 - val_loss: 0.3814 - val_accuracy: 0.8353\n",
            "Epoch 660/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3927 - accuracy: 0.8300 - val_loss: 0.3812 - val_accuracy: 0.8362\n",
            "Epoch 661/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3889 - accuracy: 0.8319 - val_loss: 0.3820 - val_accuracy: 0.8345\n",
            "Epoch 662/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3876 - accuracy: 0.8322 - val_loss: 0.3808 - val_accuracy: 0.8356\n",
            "Epoch 663/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3893 - accuracy: 0.8309 - val_loss: 0.3812 - val_accuracy: 0.8358\n",
            "Epoch 664/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3910 - accuracy: 0.8320 - val_loss: 0.3808 - val_accuracy: 0.8349\n",
            "Epoch 665/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3840 - accuracy: 0.8346 - val_loss: 0.3817 - val_accuracy: 0.8361\n",
            "Epoch 666/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3875 - accuracy: 0.8320 - val_loss: 0.3827 - val_accuracy: 0.8342\n",
            "Epoch 667/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3882 - accuracy: 0.8309 - val_loss: 0.3808 - val_accuracy: 0.8361\n",
            "Epoch 668/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3905 - accuracy: 0.8306 - val_loss: 0.3802 - val_accuracy: 0.8356\n",
            "Epoch 669/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3902 - accuracy: 0.8318 - val_loss: 0.3800 - val_accuracy: 0.8357\n",
            "Epoch 670/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3843 - accuracy: 0.8336 - val_loss: 0.3815 - val_accuracy: 0.8349\n",
            "Epoch 671/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3895 - accuracy: 0.8310 - val_loss: 0.3810 - val_accuracy: 0.8359\n",
            "Epoch 672/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3896 - accuracy: 0.8288 - val_loss: 0.3826 - val_accuracy: 0.8356\n",
            "Epoch 673/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3860 - accuracy: 0.8317 - val_loss: 0.3807 - val_accuracy: 0.8364\n",
            "Epoch 674/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3884 - accuracy: 0.8310 - val_loss: 0.3802 - val_accuracy: 0.8354\n",
            "Epoch 675/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3865 - accuracy: 0.8317 - val_loss: 0.3807 - val_accuracy: 0.8356\n",
            "Epoch 676/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3891 - accuracy: 0.8283 - val_loss: 0.3809 - val_accuracy: 0.8369\n",
            "Epoch 677/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3870 - accuracy: 0.8308 - val_loss: 0.3814 - val_accuracy: 0.8353\n",
            "Epoch 678/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3870 - accuracy: 0.8318 - val_loss: 0.3801 - val_accuracy: 0.8357\n",
            "Epoch 679/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3890 - accuracy: 0.8289 - val_loss: 0.3803 - val_accuracy: 0.8360\n",
            "Epoch 680/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3872 - accuracy: 0.8333 - val_loss: 0.3807 - val_accuracy: 0.8364\n",
            "Epoch 681/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3836 - accuracy: 0.8329 - val_loss: 0.3808 - val_accuracy: 0.8349\n",
            "Epoch 682/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3849 - accuracy: 0.8350 - val_loss: 0.3804 - val_accuracy: 0.8357\n",
            "Epoch 683/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3868 - accuracy: 0.8320 - val_loss: 0.3812 - val_accuracy: 0.8347\n",
            "Epoch 684/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3859 - accuracy: 0.8332 - val_loss: 0.3795 - val_accuracy: 0.8360\n",
            "Epoch 685/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3837 - accuracy: 0.8315 - val_loss: 0.3817 - val_accuracy: 0.8355\n",
            "Epoch 686/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3848 - accuracy: 0.8345 - val_loss: 0.3812 - val_accuracy: 0.8355\n",
            "Epoch 687/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3896 - accuracy: 0.8322 - val_loss: 0.3803 - val_accuracy: 0.8359\n",
            "Epoch 688/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3879 - accuracy: 0.8330 - val_loss: 0.3798 - val_accuracy: 0.8354\n",
            "Epoch 689/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3853 - accuracy: 0.8326 - val_loss: 0.3810 - val_accuracy: 0.8355\n",
            "Epoch 690/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3881 - accuracy: 0.8311 - val_loss: 0.3819 - val_accuracy: 0.8346\n",
            "Epoch 691/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3891 - accuracy: 0.8313 - val_loss: 0.3802 - val_accuracy: 0.8354\n",
            "Epoch 692/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3845 - accuracy: 0.8314 - val_loss: 0.3795 - val_accuracy: 0.8356\n",
            "Epoch 693/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3854 - accuracy: 0.8323 - val_loss: 0.3802 - val_accuracy: 0.8347\n",
            "Epoch 694/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3890 - accuracy: 0.8321 - val_loss: 0.3794 - val_accuracy: 0.8358\n",
            "Epoch 695/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3909 - accuracy: 0.8321 - val_loss: 0.3802 - val_accuracy: 0.8357\n",
            "Epoch 696/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3899 - accuracy: 0.8310 - val_loss: 0.3797 - val_accuracy: 0.8358\n",
            "Epoch 697/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3873 - accuracy: 0.8322 - val_loss: 0.3795 - val_accuracy: 0.8354\n",
            "Epoch 698/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3885 - accuracy: 0.8329 - val_loss: 0.3800 - val_accuracy: 0.8360\n",
            "Epoch 699/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3889 - accuracy: 0.8325 - val_loss: 0.3807 - val_accuracy: 0.8346\n",
            "Epoch 700/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3871 - accuracy: 0.8333 - val_loss: 0.3809 - val_accuracy: 0.8355\n",
            "Epoch 701/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3905 - accuracy: 0.8305 - val_loss: 0.3796 - val_accuracy: 0.8365\n",
            "Epoch 702/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3915 - accuracy: 0.8303 - val_loss: 0.3796 - val_accuracy: 0.8354\n",
            "Epoch 703/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3878 - accuracy: 0.8343 - val_loss: 0.3807 - val_accuracy: 0.8355\n",
            "Epoch 704/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3854 - accuracy: 0.8329 - val_loss: 0.3786 - val_accuracy: 0.8367\n",
            "Epoch 705/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3894 - accuracy: 0.8312 - val_loss: 0.3786 - val_accuracy: 0.8357\n",
            "Epoch 706/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3845 - accuracy: 0.8353 - val_loss: 0.3798 - val_accuracy: 0.8365\n",
            "Epoch 707/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3879 - accuracy: 0.8316 - val_loss: 0.3793 - val_accuracy: 0.8362\n",
            "Epoch 708/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3862 - accuracy: 0.8317 - val_loss: 0.3784 - val_accuracy: 0.8362\n",
            "Epoch 709/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3905 - accuracy: 0.8317 - val_loss: 0.3789 - val_accuracy: 0.8366\n",
            "Epoch 710/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3850 - accuracy: 0.8337 - val_loss: 0.3813 - val_accuracy: 0.8351\n",
            "Epoch 711/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3885 - accuracy: 0.8318 - val_loss: 0.3785 - val_accuracy: 0.8362\n",
            "Epoch 712/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3896 - accuracy: 0.8312 - val_loss: 0.3782 - val_accuracy: 0.8366\n",
            "Epoch 713/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3874 - accuracy: 0.8323 - val_loss: 0.3785 - val_accuracy: 0.8361\n",
            "Epoch 714/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3871 - accuracy: 0.8338 - val_loss: 0.3802 - val_accuracy: 0.8361\n",
            "Epoch 715/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3853 - accuracy: 0.8343 - val_loss: 0.3798 - val_accuracy: 0.8362\n",
            "Epoch 716/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3846 - accuracy: 0.8346 - val_loss: 0.3788 - val_accuracy: 0.8365\n",
            "Epoch 717/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3884 - accuracy: 0.8313 - val_loss: 0.3772 - val_accuracy: 0.8370\n",
            "Epoch 718/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3856 - accuracy: 0.8343 - val_loss: 0.3781 - val_accuracy: 0.8364\n",
            "Epoch 719/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3854 - accuracy: 0.8336 - val_loss: 0.3790 - val_accuracy: 0.8359\n",
            "Epoch 720/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3873 - accuracy: 0.8336 - val_loss: 0.3791 - val_accuracy: 0.8366\n",
            "Epoch 721/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3873 - accuracy: 0.8323 - val_loss: 0.3782 - val_accuracy: 0.8356\n",
            "Epoch 722/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3851 - accuracy: 0.8332 - val_loss: 0.3793 - val_accuracy: 0.8358\n",
            "Epoch 723/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3861 - accuracy: 0.8327 - val_loss: 0.3792 - val_accuracy: 0.8350\n",
            "Epoch 724/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3857 - accuracy: 0.8345 - val_loss: 0.3787 - val_accuracy: 0.8364\n",
            "Epoch 725/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3882 - accuracy: 0.8320 - val_loss: 0.3780 - val_accuracy: 0.8364\n",
            "Epoch 726/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3836 - accuracy: 0.8341 - val_loss: 0.3803 - val_accuracy: 0.8356\n",
            "Epoch 727/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3870 - accuracy: 0.8316 - val_loss: 0.3789 - val_accuracy: 0.8363\n",
            "Epoch 728/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3845 - accuracy: 0.8341 - val_loss: 0.3789 - val_accuracy: 0.8367\n",
            "Epoch 729/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3876 - accuracy: 0.8308 - val_loss: 0.3789 - val_accuracy: 0.8363\n",
            "Epoch 730/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3877 - accuracy: 0.8318 - val_loss: 0.3808 - val_accuracy: 0.8354\n",
            "Epoch 731/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3863 - accuracy: 0.8351 - val_loss: 0.3799 - val_accuracy: 0.8350\n",
            "Epoch 732/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3898 - accuracy: 0.8316 - val_loss: 0.3779 - val_accuracy: 0.8368\n",
            "Epoch 733/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3841 - accuracy: 0.8341 - val_loss: 0.3778 - val_accuracy: 0.8364\n",
            "Epoch 734/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3844 - accuracy: 0.8332 - val_loss: 0.3789 - val_accuracy: 0.8366\n",
            "Epoch 735/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3850 - accuracy: 0.8338 - val_loss: 0.3785 - val_accuracy: 0.8362\n",
            "Epoch 736/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3819 - accuracy: 0.8343 - val_loss: 0.3780 - val_accuracy: 0.8365\n",
            "Epoch 737/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3852 - accuracy: 0.8336 - val_loss: 0.3786 - val_accuracy: 0.8357\n",
            "Epoch 738/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3840 - accuracy: 0.8339 - val_loss: 0.3778 - val_accuracy: 0.8367\n",
            "Epoch 739/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3863 - accuracy: 0.8344 - val_loss: 0.3785 - val_accuracy: 0.8366\n",
            "Epoch 740/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3871 - accuracy: 0.8334 - val_loss: 0.3784 - val_accuracy: 0.8370\n",
            "Epoch 741/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3854 - accuracy: 0.8346 - val_loss: 0.3787 - val_accuracy: 0.8353\n",
            "Epoch 742/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3878 - accuracy: 0.8324 - val_loss: 0.3777 - val_accuracy: 0.8364\n",
            "Epoch 743/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3834 - accuracy: 0.8351 - val_loss: 0.3783 - val_accuracy: 0.8366\n",
            "Epoch 744/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3854 - accuracy: 0.8335 - val_loss: 0.3781 - val_accuracy: 0.8365\n",
            "Epoch 745/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3874 - accuracy: 0.8330 - val_loss: 0.3781 - val_accuracy: 0.8366\n",
            "Epoch 746/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3866 - accuracy: 0.8334 - val_loss: 0.3779 - val_accuracy: 0.8370\n",
            "Epoch 747/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3839 - accuracy: 0.8353 - val_loss: 0.3786 - val_accuracy: 0.8355\n",
            "Epoch 748/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3884 - accuracy: 0.8326 - val_loss: 0.3776 - val_accuracy: 0.8358\n",
            "Epoch 749/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3847 - accuracy: 0.8357 - val_loss: 0.3782 - val_accuracy: 0.8358\n",
            "Epoch 750/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3823 - accuracy: 0.8347 - val_loss: 0.3786 - val_accuracy: 0.8361\n",
            "Epoch 751/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3862 - accuracy: 0.8327 - val_loss: 0.3769 - val_accuracy: 0.8371\n",
            "Epoch 752/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3789 - accuracy: 0.8379 - val_loss: 0.3783 - val_accuracy: 0.8363\n",
            "Epoch 753/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3888 - accuracy: 0.8315 - val_loss: 0.3782 - val_accuracy: 0.8373\n",
            "Epoch 754/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3883 - accuracy: 0.8333 - val_loss: 0.3774 - val_accuracy: 0.8370\n",
            "Epoch 755/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3888 - accuracy: 0.8329 - val_loss: 0.3775 - val_accuracy: 0.8370\n",
            "Epoch 756/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3823 - accuracy: 0.8347 - val_loss: 0.3782 - val_accuracy: 0.8363\n",
            "Epoch 757/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3826 - accuracy: 0.8354 - val_loss: 0.3774 - val_accuracy: 0.8369\n",
            "Epoch 758/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3866 - accuracy: 0.8329 - val_loss: 0.3779 - val_accuracy: 0.8365\n",
            "Epoch 759/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3904 - accuracy: 0.8303 - val_loss: 0.3778 - val_accuracy: 0.8361\n",
            "Epoch 760/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3862 - accuracy: 0.8340 - val_loss: 0.3776 - val_accuracy: 0.8363\n",
            "Epoch 761/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3847 - accuracy: 0.8358 - val_loss: 0.3770 - val_accuracy: 0.8373\n",
            "Epoch 762/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3884 - accuracy: 0.8329 - val_loss: 0.3766 - val_accuracy: 0.8361\n",
            "Epoch 763/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3857 - accuracy: 0.8333 - val_loss: 0.3778 - val_accuracy: 0.8365\n",
            "Epoch 764/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3830 - accuracy: 0.8350 - val_loss: 0.3777 - val_accuracy: 0.8360\n",
            "Epoch 765/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3851 - accuracy: 0.8337 - val_loss: 0.3776 - val_accuracy: 0.8366\n",
            "Epoch 766/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3848 - accuracy: 0.8336 - val_loss: 0.3777 - val_accuracy: 0.8365\n",
            "Epoch 767/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3877 - accuracy: 0.8327 - val_loss: 0.3777 - val_accuracy: 0.8371\n",
            "Epoch 768/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3854 - accuracy: 0.8347 - val_loss: 0.3767 - val_accuracy: 0.8362\n",
            "Epoch 769/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3849 - accuracy: 0.8342 - val_loss: 0.3771 - val_accuracy: 0.8364\n",
            "Epoch 770/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3859 - accuracy: 0.8331 - val_loss: 0.3774 - val_accuracy: 0.8361\n",
            "Epoch 771/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3875 - accuracy: 0.8325 - val_loss: 0.3762 - val_accuracy: 0.8379\n",
            "Epoch 772/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3836 - accuracy: 0.8346 - val_loss: 0.3768 - val_accuracy: 0.8372\n",
            "Epoch 773/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3891 - accuracy: 0.8324 - val_loss: 0.3765 - val_accuracy: 0.8372\n",
            "Epoch 774/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3874 - accuracy: 0.8320 - val_loss: 0.3775 - val_accuracy: 0.8369\n",
            "Epoch 775/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3840 - accuracy: 0.8347 - val_loss: 0.3768 - val_accuracy: 0.8367\n",
            "Epoch 776/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3849 - accuracy: 0.8343 - val_loss: 0.3764 - val_accuracy: 0.8370\n",
            "Epoch 777/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3847 - accuracy: 0.8338 - val_loss: 0.3764 - val_accuracy: 0.8376\n",
            "Epoch 778/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3805 - accuracy: 0.8363 - val_loss: 0.3776 - val_accuracy: 0.8369\n",
            "Epoch 779/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3861 - accuracy: 0.8348 - val_loss: 0.3766 - val_accuracy: 0.8367\n",
            "Epoch 780/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3865 - accuracy: 0.8327 - val_loss: 0.3772 - val_accuracy: 0.8379\n",
            "Epoch 781/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3844 - accuracy: 0.8350 - val_loss: 0.3770 - val_accuracy: 0.8375\n",
            "Epoch 782/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3826 - accuracy: 0.8335 - val_loss: 0.3770 - val_accuracy: 0.8379\n",
            "Epoch 783/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3832 - accuracy: 0.8352 - val_loss: 0.3767 - val_accuracy: 0.8373\n",
            "Epoch 784/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3821 - accuracy: 0.8366 - val_loss: 0.3767 - val_accuracy: 0.8373\n",
            "Epoch 785/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3861 - accuracy: 0.8330 - val_loss: 0.3770 - val_accuracy: 0.8373\n",
            "Epoch 786/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3844 - accuracy: 0.8334 - val_loss: 0.3762 - val_accuracy: 0.8369\n",
            "Epoch 787/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3843 - accuracy: 0.8329 - val_loss: 0.3766 - val_accuracy: 0.8371\n",
            "Epoch 788/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3838 - accuracy: 0.8357 - val_loss: 0.3767 - val_accuracy: 0.8371\n",
            "Epoch 789/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3849 - accuracy: 0.8329 - val_loss: 0.3767 - val_accuracy: 0.8372\n",
            "Epoch 790/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3820 - accuracy: 0.8365 - val_loss: 0.3766 - val_accuracy: 0.8375\n",
            "Epoch 791/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3823 - accuracy: 0.8362 - val_loss: 0.3769 - val_accuracy: 0.8369\n",
            "Epoch 792/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3810 - accuracy: 0.8352 - val_loss: 0.3770 - val_accuracy: 0.8385\n",
            "Epoch 793/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3825 - accuracy: 0.8351 - val_loss: 0.3758 - val_accuracy: 0.8379\n",
            "Epoch 794/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3778 - accuracy: 0.8368 - val_loss: 0.3775 - val_accuracy: 0.8366\n",
            "Epoch 795/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3820 - accuracy: 0.8357 - val_loss: 0.3775 - val_accuracy: 0.8371\n",
            "Epoch 796/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3846 - accuracy: 0.8351 - val_loss: 0.3760 - val_accuracy: 0.8365\n",
            "Epoch 797/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3847 - accuracy: 0.8340 - val_loss: 0.3758 - val_accuracy: 0.8372\n",
            "Epoch 798/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3850 - accuracy: 0.8330 - val_loss: 0.3767 - val_accuracy: 0.8378\n",
            "Epoch 799/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3842 - accuracy: 0.8351 - val_loss: 0.3774 - val_accuracy: 0.8367\n",
            "Epoch 800/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3820 - accuracy: 0.8362 - val_loss: 0.3765 - val_accuracy: 0.8376\n",
            "Epoch 801/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3821 - accuracy: 0.8341 - val_loss: 0.3764 - val_accuracy: 0.8379\n",
            "Epoch 802/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3846 - accuracy: 0.8337 - val_loss: 0.3758 - val_accuracy: 0.8378\n",
            "Epoch 803/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3876 - accuracy: 0.8301 - val_loss: 0.3766 - val_accuracy: 0.8366\n",
            "Epoch 804/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3825 - accuracy: 0.8359 - val_loss: 0.3764 - val_accuracy: 0.8374\n",
            "Epoch 805/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3860 - accuracy: 0.8341 - val_loss: 0.3759 - val_accuracy: 0.8367\n",
            "Epoch 806/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3851 - accuracy: 0.8348 - val_loss: 0.3765 - val_accuracy: 0.8372\n",
            "Epoch 807/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3851 - accuracy: 0.8335 - val_loss: 0.3764 - val_accuracy: 0.8380\n",
            "Epoch 808/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3842 - accuracy: 0.8334 - val_loss: 0.3754 - val_accuracy: 0.8382\n",
            "Epoch 809/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3853 - accuracy: 0.8350 - val_loss: 0.3768 - val_accuracy: 0.8377\n",
            "Epoch 810/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3855 - accuracy: 0.8333 - val_loss: 0.3760 - val_accuracy: 0.8374\n",
            "Epoch 811/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3853 - accuracy: 0.8339 - val_loss: 0.3770 - val_accuracy: 0.8380\n",
            "Epoch 812/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3822 - accuracy: 0.8345 - val_loss: 0.3764 - val_accuracy: 0.8385\n",
            "Epoch 813/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3842 - accuracy: 0.8331 - val_loss: 0.3760 - val_accuracy: 0.8376\n",
            "Epoch 814/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3797 - accuracy: 0.8374 - val_loss: 0.3767 - val_accuracy: 0.8381\n",
            "Epoch 815/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3847 - accuracy: 0.8344 - val_loss: 0.3759 - val_accuracy: 0.8376\n",
            "Epoch 816/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3805 - accuracy: 0.8359 - val_loss: 0.3775 - val_accuracy: 0.8359\n",
            "Epoch 817/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3820 - accuracy: 0.8367 - val_loss: 0.3772 - val_accuracy: 0.8376\n",
            "Epoch 818/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3839 - accuracy: 0.8350 - val_loss: 0.3750 - val_accuracy: 0.8376\n",
            "Epoch 819/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3842 - accuracy: 0.8347 - val_loss: 0.3750 - val_accuracy: 0.8375\n",
            "Epoch 820/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3871 - accuracy: 0.8314 - val_loss: 0.3756 - val_accuracy: 0.8373\n",
            "Epoch 821/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3847 - accuracy: 0.8334 - val_loss: 0.3761 - val_accuracy: 0.8367\n",
            "Epoch 822/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3852 - accuracy: 0.8338 - val_loss: 0.3752 - val_accuracy: 0.8380\n",
            "Epoch 823/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3826 - accuracy: 0.8352 - val_loss: 0.3751 - val_accuracy: 0.8389\n",
            "Epoch 824/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3834 - accuracy: 0.8339 - val_loss: 0.3765 - val_accuracy: 0.8379\n",
            "Epoch 825/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3834 - accuracy: 0.8341 - val_loss: 0.3750 - val_accuracy: 0.8379\n",
            "Epoch 826/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3847 - accuracy: 0.8349 - val_loss: 0.3752 - val_accuracy: 0.8379\n",
            "Epoch 827/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3837 - accuracy: 0.8352 - val_loss: 0.3781 - val_accuracy: 0.8360\n",
            "Epoch 828/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3844 - accuracy: 0.8336 - val_loss: 0.3749 - val_accuracy: 0.8375\n",
            "Epoch 829/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3836 - accuracy: 0.8346 - val_loss: 0.3748 - val_accuracy: 0.8374\n",
            "Epoch 830/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3859 - accuracy: 0.8336 - val_loss: 0.3759 - val_accuracy: 0.8366\n",
            "Epoch 831/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3806 - accuracy: 0.8359 - val_loss: 0.3752 - val_accuracy: 0.8387\n",
            "Epoch 832/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3837 - accuracy: 0.8356 - val_loss: 0.3747 - val_accuracy: 0.8377\n",
            "Epoch 833/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3787 - accuracy: 0.8376 - val_loss: 0.3751 - val_accuracy: 0.8376\n",
            "Epoch 834/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3862 - accuracy: 0.8329 - val_loss: 0.3743 - val_accuracy: 0.8375\n",
            "Epoch 835/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3805 - accuracy: 0.8375 - val_loss: 0.3750 - val_accuracy: 0.8380\n",
            "Epoch 836/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3842 - accuracy: 0.8342 - val_loss: 0.3740 - val_accuracy: 0.8392\n",
            "Epoch 837/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3833 - accuracy: 0.8334 - val_loss: 0.3755 - val_accuracy: 0.8377\n",
            "Epoch 838/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3806 - accuracy: 0.8360 - val_loss: 0.3744 - val_accuracy: 0.8385\n",
            "Epoch 839/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3829 - accuracy: 0.8351 - val_loss: 0.3751 - val_accuracy: 0.8376\n",
            "Epoch 840/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3831 - accuracy: 0.8342 - val_loss: 0.3751 - val_accuracy: 0.8387\n",
            "Epoch 841/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3819 - accuracy: 0.8361 - val_loss: 0.3737 - val_accuracy: 0.8385\n",
            "Epoch 842/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3813 - accuracy: 0.8361 - val_loss: 0.3749 - val_accuracy: 0.8377\n",
            "Epoch 843/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3806 - accuracy: 0.8377 - val_loss: 0.3750 - val_accuracy: 0.8380\n",
            "Epoch 844/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3830 - accuracy: 0.8352 - val_loss: 0.3756 - val_accuracy: 0.8376\n",
            "Epoch 845/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3825 - accuracy: 0.8376 - val_loss: 0.3743 - val_accuracy: 0.8379\n",
            "Epoch 846/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3782 - accuracy: 0.8387 - val_loss: 0.3756 - val_accuracy: 0.8387\n",
            "Epoch 847/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3807 - accuracy: 0.8360 - val_loss: 0.3735 - val_accuracy: 0.8386\n",
            "Epoch 848/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3820 - accuracy: 0.8356 - val_loss: 0.3744 - val_accuracy: 0.8380\n",
            "Epoch 849/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3784 - accuracy: 0.8372 - val_loss: 0.3747 - val_accuracy: 0.8375\n",
            "Epoch 850/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3838 - accuracy: 0.8331 - val_loss: 0.3752 - val_accuracy: 0.8378\n",
            "Epoch 851/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3830 - accuracy: 0.8332 - val_loss: 0.3758 - val_accuracy: 0.8371\n",
            "Epoch 852/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3853 - accuracy: 0.8337 - val_loss: 0.3753 - val_accuracy: 0.8369\n",
            "Epoch 853/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3834 - accuracy: 0.8347 - val_loss: 0.3745 - val_accuracy: 0.8375\n",
            "Epoch 854/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3841 - accuracy: 0.8351 - val_loss: 0.3750 - val_accuracy: 0.8376\n",
            "Epoch 855/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3805 - accuracy: 0.8352 - val_loss: 0.3740 - val_accuracy: 0.8377\n",
            "Epoch 856/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3829 - accuracy: 0.8328 - val_loss: 0.3742 - val_accuracy: 0.8380\n",
            "Epoch 857/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3818 - accuracy: 0.8360 - val_loss: 0.3735 - val_accuracy: 0.8387\n",
            "Epoch 858/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3780 - accuracy: 0.8382 - val_loss: 0.3740 - val_accuracy: 0.8396\n",
            "Epoch 859/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3846 - accuracy: 0.8344 - val_loss: 0.3744 - val_accuracy: 0.8377\n",
            "Epoch 860/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3819 - accuracy: 0.8350 - val_loss: 0.3743 - val_accuracy: 0.8382\n",
            "Epoch 861/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3829 - accuracy: 0.8348 - val_loss: 0.3745 - val_accuracy: 0.8387\n",
            "Epoch 862/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3820 - accuracy: 0.8348 - val_loss: 0.3743 - val_accuracy: 0.8389\n",
            "Epoch 863/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3811 - accuracy: 0.8363 - val_loss: 0.3750 - val_accuracy: 0.8388\n",
            "Epoch 864/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3801 - accuracy: 0.8367 - val_loss: 0.3748 - val_accuracy: 0.8393\n",
            "Epoch 865/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3854 - accuracy: 0.8327 - val_loss: 0.3762 - val_accuracy: 0.8375\n",
            "Epoch 866/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3820 - accuracy: 0.8345 - val_loss: 0.3743 - val_accuracy: 0.8382\n",
            "Epoch 867/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3815 - accuracy: 0.8372 - val_loss: 0.3741 - val_accuracy: 0.8378\n",
            "Epoch 868/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3810 - accuracy: 0.8360 - val_loss: 0.3749 - val_accuracy: 0.8383\n",
            "Epoch 869/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3834 - accuracy: 0.8347 - val_loss: 0.3743 - val_accuracy: 0.8379\n",
            "Epoch 870/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3839 - accuracy: 0.8355 - val_loss: 0.3740 - val_accuracy: 0.8402\n",
            "Epoch 871/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3779 - accuracy: 0.8374 - val_loss: 0.3746 - val_accuracy: 0.8380\n",
            "Epoch 872/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3795 - accuracy: 0.8367 - val_loss: 0.3746 - val_accuracy: 0.8379\n",
            "Epoch 873/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3829 - accuracy: 0.8351 - val_loss: 0.3739 - val_accuracy: 0.8379\n",
            "Epoch 874/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3847 - accuracy: 0.8344 - val_loss: 0.3740 - val_accuracy: 0.8391\n",
            "Epoch 875/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3854 - accuracy: 0.8351 - val_loss: 0.3753 - val_accuracy: 0.8373\n",
            "Epoch 876/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3849 - accuracy: 0.8325 - val_loss: 0.3740 - val_accuracy: 0.8387\n",
            "Epoch 877/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3832 - accuracy: 0.8343 - val_loss: 0.3734 - val_accuracy: 0.8390\n",
            "Epoch 878/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3811 - accuracy: 0.8364 - val_loss: 0.3740 - val_accuracy: 0.8371\n",
            "Epoch 879/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3781 - accuracy: 0.8364 - val_loss: 0.3758 - val_accuracy: 0.8387\n",
            "Epoch 880/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3848 - accuracy: 0.8330 - val_loss: 0.3747 - val_accuracy: 0.8380\n",
            "Epoch 881/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3785 - accuracy: 0.8367 - val_loss: 0.3747 - val_accuracy: 0.8381\n",
            "Epoch 882/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3823 - accuracy: 0.8374 - val_loss: 0.3732 - val_accuracy: 0.8398\n",
            "Epoch 883/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3829 - accuracy: 0.8361 - val_loss: 0.3736 - val_accuracy: 0.8393\n",
            "Epoch 884/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3794 - accuracy: 0.8376 - val_loss: 0.3746 - val_accuracy: 0.8382\n",
            "Epoch 885/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3864 - accuracy: 0.8336 - val_loss: 0.3735 - val_accuracy: 0.8383\n",
            "Epoch 886/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3793 - accuracy: 0.8359 - val_loss: 0.3730 - val_accuracy: 0.8381\n",
            "Epoch 887/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3832 - accuracy: 0.8336 - val_loss: 0.3744 - val_accuracy: 0.8385\n",
            "Epoch 888/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3809 - accuracy: 0.8354 - val_loss: 0.3749 - val_accuracy: 0.8384\n",
            "Epoch 889/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3814 - accuracy: 0.8355 - val_loss: 0.3751 - val_accuracy: 0.8380\n",
            "Epoch 890/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3809 - accuracy: 0.8357 - val_loss: 0.3743 - val_accuracy: 0.8388\n",
            "Epoch 891/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3780 - accuracy: 0.8356 - val_loss: 0.3735 - val_accuracy: 0.8397\n",
            "Epoch 892/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3829 - accuracy: 0.8348 - val_loss: 0.3724 - val_accuracy: 0.8386\n",
            "Epoch 893/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3814 - accuracy: 0.8336 - val_loss: 0.3740 - val_accuracy: 0.8384\n",
            "Epoch 894/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3797 - accuracy: 0.8358 - val_loss: 0.3742 - val_accuracy: 0.8384\n",
            "Epoch 895/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3779 - accuracy: 0.8374 - val_loss: 0.3733 - val_accuracy: 0.8392\n",
            "Epoch 896/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3801 - accuracy: 0.8353 - val_loss: 0.3738 - val_accuracy: 0.8385\n",
            "Epoch 897/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3802 - accuracy: 0.8368 - val_loss: 0.3724 - val_accuracy: 0.8396\n",
            "Epoch 898/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3786 - accuracy: 0.8367 - val_loss: 0.3727 - val_accuracy: 0.8392\n",
            "Epoch 899/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3782 - accuracy: 0.8375 - val_loss: 0.3741 - val_accuracy: 0.8371\n",
            "Epoch 900/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3805 - accuracy: 0.8372 - val_loss: 0.3738 - val_accuracy: 0.8382\n",
            "Epoch 901/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3831 - accuracy: 0.8353 - val_loss: 0.3733 - val_accuracy: 0.8392\n",
            "Epoch 902/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3809 - accuracy: 0.8357 - val_loss: 0.3739 - val_accuracy: 0.8389\n",
            "Epoch 903/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3773 - accuracy: 0.8377 - val_loss: 0.3731 - val_accuracy: 0.8380\n",
            "Epoch 904/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3768 - accuracy: 0.8381 - val_loss: 0.3738 - val_accuracy: 0.8398\n",
            "Epoch 905/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3803 - accuracy: 0.8372 - val_loss: 0.3724 - val_accuracy: 0.8406\n",
            "Epoch 906/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3849 - accuracy: 0.8352 - val_loss: 0.3728 - val_accuracy: 0.8389\n",
            "Epoch 907/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3842 - accuracy: 0.8344 - val_loss: 0.3751 - val_accuracy: 0.8383\n",
            "Epoch 908/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3821 - accuracy: 0.8365 - val_loss: 0.3731 - val_accuracy: 0.8387\n",
            "Epoch 909/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3848 - accuracy: 0.8330 - val_loss: 0.3737 - val_accuracy: 0.8370\n",
            "Epoch 910/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3800 - accuracy: 0.8368 - val_loss: 0.3740 - val_accuracy: 0.8373\n",
            "Epoch 911/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3813 - accuracy: 0.8351 - val_loss: 0.3728 - val_accuracy: 0.8382\n",
            "Epoch 912/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3801 - accuracy: 0.8355 - val_loss: 0.3744 - val_accuracy: 0.8380\n",
            "Epoch 913/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3791 - accuracy: 0.8376 - val_loss: 0.3723 - val_accuracy: 0.8397\n",
            "Epoch 914/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3794 - accuracy: 0.8361 - val_loss: 0.3731 - val_accuracy: 0.8401\n",
            "Epoch 915/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3800 - accuracy: 0.8361 - val_loss: 0.3736 - val_accuracy: 0.8391\n",
            "Epoch 916/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3819 - accuracy: 0.8357 - val_loss: 0.3730 - val_accuracy: 0.8389\n",
            "Epoch 917/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3805 - accuracy: 0.8352 - val_loss: 0.3729 - val_accuracy: 0.8394\n",
            "Epoch 918/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3816 - accuracy: 0.8363 - val_loss: 0.3734 - val_accuracy: 0.8386\n",
            "Epoch 919/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3763 - accuracy: 0.8382 - val_loss: 0.3719 - val_accuracy: 0.8397\n",
            "Epoch 920/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3775 - accuracy: 0.8384 - val_loss: 0.3725 - val_accuracy: 0.8389\n",
            "Epoch 921/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3806 - accuracy: 0.8356 - val_loss: 0.3726 - val_accuracy: 0.8385\n",
            "Epoch 922/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3784 - accuracy: 0.8374 - val_loss: 0.3737 - val_accuracy: 0.8377\n",
            "Epoch 923/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3794 - accuracy: 0.8359 - val_loss: 0.3730 - val_accuracy: 0.8389\n",
            "Epoch 924/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3824 - accuracy: 0.8353 - val_loss: 0.3730 - val_accuracy: 0.8381\n",
            "Epoch 925/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3828 - accuracy: 0.8354 - val_loss: 0.3730 - val_accuracy: 0.8390\n",
            "Epoch 926/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3788 - accuracy: 0.8359 - val_loss: 0.3727 - val_accuracy: 0.8393\n",
            "Epoch 927/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3804 - accuracy: 0.8368 - val_loss: 0.3729 - val_accuracy: 0.8392\n",
            "Epoch 928/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3769 - accuracy: 0.8380 - val_loss: 0.3740 - val_accuracy: 0.8388\n",
            "Epoch 929/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3822 - accuracy: 0.8366 - val_loss: 0.3726 - val_accuracy: 0.8384\n",
            "Epoch 930/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3801 - accuracy: 0.8359 - val_loss: 0.3733 - val_accuracy: 0.8381\n",
            "Epoch 931/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3779 - accuracy: 0.8373 - val_loss: 0.3712 - val_accuracy: 0.8390\n",
            "Epoch 932/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3837 - accuracy: 0.8347 - val_loss: 0.3726 - val_accuracy: 0.8391\n",
            "Epoch 933/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3774 - accuracy: 0.8402 - val_loss: 0.3727 - val_accuracy: 0.8394\n",
            "Epoch 934/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3827 - accuracy: 0.8344 - val_loss: 0.3720 - val_accuracy: 0.8383\n",
            "Epoch 935/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3796 - accuracy: 0.8363 - val_loss: 0.3720 - val_accuracy: 0.8397\n",
            "Epoch 936/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3800 - accuracy: 0.8363 - val_loss: 0.3733 - val_accuracy: 0.8388\n",
            "Epoch 937/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3787 - accuracy: 0.8376 - val_loss: 0.3718 - val_accuracy: 0.8400\n",
            "Epoch 938/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3794 - accuracy: 0.8346 - val_loss: 0.3728 - val_accuracy: 0.8400\n",
            "Epoch 939/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3779 - accuracy: 0.8371 - val_loss: 0.3722 - val_accuracy: 0.8396\n",
            "Epoch 940/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3765 - accuracy: 0.8384 - val_loss: 0.3727 - val_accuracy: 0.8394\n",
            "Epoch 941/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3821 - accuracy: 0.8374 - val_loss: 0.3712 - val_accuracy: 0.8397\n",
            "Epoch 942/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3773 - accuracy: 0.8385 - val_loss: 0.3730 - val_accuracy: 0.8389\n",
            "Epoch 943/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3791 - accuracy: 0.8371 - val_loss: 0.3714 - val_accuracy: 0.8392\n",
            "Epoch 944/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3792 - accuracy: 0.8368 - val_loss: 0.3716 - val_accuracy: 0.8394\n",
            "Epoch 945/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3790 - accuracy: 0.8374 - val_loss: 0.3732 - val_accuracy: 0.8383\n",
            "Epoch 946/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3753 - accuracy: 0.8378 - val_loss: 0.3732 - val_accuracy: 0.8387\n",
            "Epoch 947/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3793 - accuracy: 0.8375 - val_loss: 0.3721 - val_accuracy: 0.8385\n",
            "Epoch 948/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3807 - accuracy: 0.8350 - val_loss: 0.3715 - val_accuracy: 0.8396\n",
            "Epoch 949/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3760 - accuracy: 0.8392 - val_loss: 0.3725 - val_accuracy: 0.8389\n",
            "Epoch 950/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3748 - accuracy: 0.8406 - val_loss: 0.3723 - val_accuracy: 0.8399\n",
            "Epoch 951/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3798 - accuracy: 0.8371 - val_loss: 0.3726 - val_accuracy: 0.8398\n",
            "Epoch 952/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3786 - accuracy: 0.8376 - val_loss: 0.3717 - val_accuracy: 0.8402\n",
            "Epoch 953/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3776 - accuracy: 0.8371 - val_loss: 0.3718 - val_accuracy: 0.8387\n",
            "Epoch 954/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3795 - accuracy: 0.8360 - val_loss: 0.3725 - val_accuracy: 0.8387\n",
            "Epoch 955/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3772 - accuracy: 0.8372 - val_loss: 0.3717 - val_accuracy: 0.8398\n",
            "Epoch 956/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3801 - accuracy: 0.8365 - val_loss: 0.3721 - val_accuracy: 0.8396\n",
            "Epoch 957/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3789 - accuracy: 0.8369 - val_loss: 0.3727 - val_accuracy: 0.8385\n",
            "Epoch 958/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3807 - accuracy: 0.8358 - val_loss: 0.3717 - val_accuracy: 0.8389\n",
            "Epoch 959/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3853 - accuracy: 0.8330 - val_loss: 0.3713 - val_accuracy: 0.8401\n",
            "Epoch 960/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3810 - accuracy: 0.8362 - val_loss: 0.3714 - val_accuracy: 0.8398\n",
            "Epoch 961/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3760 - accuracy: 0.8394 - val_loss: 0.3722 - val_accuracy: 0.8397\n",
            "Epoch 962/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3796 - accuracy: 0.8381 - val_loss: 0.3709 - val_accuracy: 0.8402\n",
            "Epoch 963/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3770 - accuracy: 0.8393 - val_loss: 0.3707 - val_accuracy: 0.8397\n",
            "Epoch 964/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3789 - accuracy: 0.8351 - val_loss: 0.3719 - val_accuracy: 0.8392\n",
            "Epoch 965/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3795 - accuracy: 0.8363 - val_loss: 0.3721 - val_accuracy: 0.8388\n",
            "Epoch 966/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3800 - accuracy: 0.8349 - val_loss: 0.3707 - val_accuracy: 0.8408\n",
            "Epoch 967/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3756 - accuracy: 0.8402 - val_loss: 0.3708 - val_accuracy: 0.8398\n",
            "Epoch 968/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3803 - accuracy: 0.8373 - val_loss: 0.3718 - val_accuracy: 0.8386\n",
            "Epoch 969/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3767 - accuracy: 0.8396 - val_loss: 0.3716 - val_accuracy: 0.8397\n",
            "Epoch 970/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3780 - accuracy: 0.8371 - val_loss: 0.3713 - val_accuracy: 0.8404\n",
            "Epoch 971/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3758 - accuracy: 0.8394 - val_loss: 0.3724 - val_accuracy: 0.8393\n",
            "Epoch 972/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3810 - accuracy: 0.8366 - val_loss: 0.3723 - val_accuracy: 0.8398\n",
            "Epoch 973/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3778 - accuracy: 0.8392 - val_loss: 0.3716 - val_accuracy: 0.8407\n",
            "Epoch 974/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3781 - accuracy: 0.8376 - val_loss: 0.3726 - val_accuracy: 0.8395\n",
            "Epoch 975/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3818 - accuracy: 0.8344 - val_loss: 0.3720 - val_accuracy: 0.8387\n",
            "Epoch 976/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3819 - accuracy: 0.8356 - val_loss: 0.3727 - val_accuracy: 0.8401\n",
            "Epoch 977/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3824 - accuracy: 0.8362 - val_loss: 0.3718 - val_accuracy: 0.8399\n",
            "Epoch 978/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3803 - accuracy: 0.8372 - val_loss: 0.3721 - val_accuracy: 0.8400\n",
            "Epoch 979/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3805 - accuracy: 0.8366 - val_loss: 0.3724 - val_accuracy: 0.8397\n",
            "Epoch 980/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3800 - accuracy: 0.8373 - val_loss: 0.3708 - val_accuracy: 0.8396\n",
            "Epoch 981/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3795 - accuracy: 0.8374 - val_loss: 0.3724 - val_accuracy: 0.8386\n",
            "Epoch 982/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3760 - accuracy: 0.8388 - val_loss: 0.3711 - val_accuracy: 0.8404\n",
            "Epoch 983/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3801 - accuracy: 0.8370 - val_loss: 0.3718 - val_accuracy: 0.8389\n",
            "Epoch 984/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3760 - accuracy: 0.8382 - val_loss: 0.3714 - val_accuracy: 0.8405\n",
            "Epoch 985/1500\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3796 - accuracy: 0.8363 - val_loss: 0.3697 - val_accuracy: 0.8401\n",
            "Epoch 986/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3744 - accuracy: 0.8382 - val_loss: 0.3708 - val_accuracy: 0.8404\n",
            "Epoch 987/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3782 - accuracy: 0.8381 - val_loss: 0.3711 - val_accuracy: 0.8403\n",
            "Epoch 988/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3780 - accuracy: 0.8370 - val_loss: 0.3722 - val_accuracy: 0.8395\n",
            "Epoch 989/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3797 - accuracy: 0.8362 - val_loss: 0.3713 - val_accuracy: 0.8403\n",
            "Epoch 990/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3757 - accuracy: 0.8388 - val_loss: 0.3730 - val_accuracy: 0.8388\n",
            "Epoch 991/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3783 - accuracy: 0.8389 - val_loss: 0.3705 - val_accuracy: 0.8401\n",
            "Epoch 992/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3766 - accuracy: 0.8390 - val_loss: 0.3713 - val_accuracy: 0.8394\n",
            "Epoch 993/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3797 - accuracy: 0.8354 - val_loss: 0.3717 - val_accuracy: 0.8395\n",
            "Epoch 994/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3768 - accuracy: 0.8384 - val_loss: 0.3729 - val_accuracy: 0.8398\n",
            "Epoch 995/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3789 - accuracy: 0.8369 - val_loss: 0.3708 - val_accuracy: 0.8401\n",
            "Epoch 996/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3790 - accuracy: 0.8371 - val_loss: 0.3708 - val_accuracy: 0.8404\n",
            "Epoch 997/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3750 - accuracy: 0.8391 - val_loss: 0.3713 - val_accuracy: 0.8396\n",
            "Epoch 998/1500\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3787 - accuracy: 0.8359 - val_loss: 0.3714 - val_accuracy: 0.8398\n",
            "Epoch 999/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3739 - accuracy: 0.8386 - val_loss: 0.3700 - val_accuracy: 0.8407\n",
            "Epoch 1000/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3759 - accuracy: 0.8391 - val_loss: 0.3727 - val_accuracy: 0.8399\n",
            "Epoch 1001/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3774 - accuracy: 0.8373 - val_loss: 0.3718 - val_accuracy: 0.8393\n",
            "Epoch 1002/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3761 - accuracy: 0.8367 - val_loss: 0.3700 - val_accuracy: 0.8407\n",
            "Epoch 1003/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3804 - accuracy: 0.8377 - val_loss: 0.3711 - val_accuracy: 0.8408\n",
            "Epoch 1004/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3773 - accuracy: 0.8393 - val_loss: 0.3701 - val_accuracy: 0.8406\n",
            "Epoch 1005/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3812 - accuracy: 0.8364 - val_loss: 0.3702 - val_accuracy: 0.8399\n",
            "Epoch 1006/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3808 - accuracy: 0.8338 - val_loss: 0.3713 - val_accuracy: 0.8403\n",
            "Epoch 1007/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3782 - accuracy: 0.8367 - val_loss: 0.3703 - val_accuracy: 0.8406\n",
            "Epoch 1008/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3759 - accuracy: 0.8389 - val_loss: 0.3718 - val_accuracy: 0.8408\n",
            "Epoch 1009/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3758 - accuracy: 0.8374 - val_loss: 0.3704 - val_accuracy: 0.8411\n",
            "Epoch 1010/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3791 - accuracy: 0.8380 - val_loss: 0.3706 - val_accuracy: 0.8409\n",
            "Epoch 1011/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3743 - accuracy: 0.8381 - val_loss: 0.3701 - val_accuracy: 0.8413\n",
            "Epoch 1012/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3765 - accuracy: 0.8384 - val_loss: 0.3710 - val_accuracy: 0.8399\n",
            "Epoch 1013/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3757 - accuracy: 0.8408 - val_loss: 0.3702 - val_accuracy: 0.8412\n",
            "Epoch 1014/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3764 - accuracy: 0.8386 - val_loss: 0.3718 - val_accuracy: 0.8393\n",
            "Epoch 1015/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3791 - accuracy: 0.8370 - val_loss: 0.3705 - val_accuracy: 0.8406\n",
            "Epoch 1016/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3808 - accuracy: 0.8361 - val_loss: 0.3700 - val_accuracy: 0.8408\n",
            "Epoch 1017/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3730 - accuracy: 0.8412 - val_loss: 0.3710 - val_accuracy: 0.8403\n",
            "Epoch 1018/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3774 - accuracy: 0.8393 - val_loss: 0.3706 - val_accuracy: 0.8419\n",
            "Epoch 1019/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3765 - accuracy: 0.8387 - val_loss: 0.3718 - val_accuracy: 0.8406\n",
            "Epoch 1020/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3758 - accuracy: 0.8390 - val_loss: 0.3702 - val_accuracy: 0.8411\n",
            "Epoch 1021/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3807 - accuracy: 0.8358 - val_loss: 0.3716 - val_accuracy: 0.8401\n",
            "Epoch 1022/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3782 - accuracy: 0.8366 - val_loss: 0.3701 - val_accuracy: 0.8410\n",
            "Epoch 1023/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3716 - accuracy: 0.8421 - val_loss: 0.3708 - val_accuracy: 0.8410\n",
            "Epoch 1024/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3772 - accuracy: 0.8359 - val_loss: 0.3705 - val_accuracy: 0.8405\n",
            "Epoch 1025/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3817 - accuracy: 0.8367 - val_loss: 0.3706 - val_accuracy: 0.8399\n",
            "Epoch 1026/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3794 - accuracy: 0.8371 - val_loss: 0.3707 - val_accuracy: 0.8403\n",
            "Epoch 1027/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3759 - accuracy: 0.8390 - val_loss: 0.3699 - val_accuracy: 0.8414\n",
            "Epoch 1028/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3758 - accuracy: 0.8371 - val_loss: 0.3705 - val_accuracy: 0.8397\n",
            "Epoch 1029/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3766 - accuracy: 0.8391 - val_loss: 0.3710 - val_accuracy: 0.8398\n",
            "Epoch 1030/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3800 - accuracy: 0.8370 - val_loss: 0.3704 - val_accuracy: 0.8404\n",
            "Epoch 1031/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3755 - accuracy: 0.8380 - val_loss: 0.3698 - val_accuracy: 0.8399\n",
            "Epoch 1032/1500\n",
            "2532/2532 [==============================] - 8s 3ms/step - loss: 0.3766 - accuracy: 0.8386 - val_loss: 0.3686 - val_accuracy: 0.8412\n",
            "Epoch 1033/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3763 - accuracy: 0.8372 - val_loss: 0.3695 - val_accuracy: 0.8411\n",
            "Epoch 1034/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3764 - accuracy: 0.8379 - val_loss: 0.3697 - val_accuracy: 0.8410\n",
            "Epoch 1035/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3753 - accuracy: 0.8384 - val_loss: 0.3694 - val_accuracy: 0.8415\n",
            "Epoch 1036/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3769 - accuracy: 0.8383 - val_loss: 0.3705 - val_accuracy: 0.8404\n",
            "Epoch 1037/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3759 - accuracy: 0.8375 - val_loss: 0.3699 - val_accuracy: 0.8409\n",
            "Epoch 1038/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3782 - accuracy: 0.8371 - val_loss: 0.3696 - val_accuracy: 0.8413\n",
            "Epoch 1039/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3775 - accuracy: 0.8375 - val_loss: 0.3692 - val_accuracy: 0.8415\n",
            "Epoch 1040/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3730 - accuracy: 0.8391 - val_loss: 0.3694 - val_accuracy: 0.8415\n",
            "Epoch 1041/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3819 - accuracy: 0.8348 - val_loss: 0.3690 - val_accuracy: 0.8408\n",
            "Epoch 1042/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3748 - accuracy: 0.8391 - val_loss: 0.3704 - val_accuracy: 0.8408\n",
            "Epoch 1043/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3745 - accuracy: 0.8405 - val_loss: 0.3690 - val_accuracy: 0.8416\n",
            "Epoch 1044/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3757 - accuracy: 0.8384 - val_loss: 0.3695 - val_accuracy: 0.8398\n",
            "Epoch 1045/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3747 - accuracy: 0.8410 - val_loss: 0.3695 - val_accuracy: 0.8414\n",
            "Epoch 1046/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3753 - accuracy: 0.8379 - val_loss: 0.3704 - val_accuracy: 0.8407\n",
            "Epoch 1047/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3765 - accuracy: 0.8368 - val_loss: 0.3683 - val_accuracy: 0.8420\n",
            "Epoch 1048/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3774 - accuracy: 0.8379 - val_loss: 0.3685 - val_accuracy: 0.8414\n",
            "Epoch 1049/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3815 - accuracy: 0.8352 - val_loss: 0.3685 - val_accuracy: 0.8415\n",
            "Epoch 1050/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3789 - accuracy: 0.8360 - val_loss: 0.3703 - val_accuracy: 0.8416\n",
            "Epoch 1051/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3782 - accuracy: 0.8375 - val_loss: 0.3690 - val_accuracy: 0.8420\n",
            "Epoch 1052/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3742 - accuracy: 0.8404 - val_loss: 0.3700 - val_accuracy: 0.8413\n",
            "Epoch 1053/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3783 - accuracy: 0.8386 - val_loss: 0.3702 - val_accuracy: 0.8410\n",
            "Epoch 1054/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3737 - accuracy: 0.8383 - val_loss: 0.3698 - val_accuracy: 0.8415\n",
            "Epoch 1055/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3769 - accuracy: 0.8374 - val_loss: 0.3685 - val_accuracy: 0.8413\n",
            "Epoch 1056/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3763 - accuracy: 0.8374 - val_loss: 0.3699 - val_accuracy: 0.8410\n",
            "Epoch 1057/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3773 - accuracy: 0.8370 - val_loss: 0.3680 - val_accuracy: 0.8413\n",
            "Epoch 1058/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3754 - accuracy: 0.8383 - val_loss: 0.3684 - val_accuracy: 0.8415\n",
            "Epoch 1059/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3802 - accuracy: 0.8364 - val_loss: 0.3699 - val_accuracy: 0.8410\n",
            "Epoch 1060/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3726 - accuracy: 0.8414 - val_loss: 0.3687 - val_accuracy: 0.8412\n",
            "Epoch 1061/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3763 - accuracy: 0.8390 - val_loss: 0.3684 - val_accuracy: 0.8417\n",
            "Epoch 1062/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3779 - accuracy: 0.8363 - val_loss: 0.3703 - val_accuracy: 0.8403\n",
            "Epoch 1063/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3772 - accuracy: 0.8384 - val_loss: 0.3696 - val_accuracy: 0.8410\n",
            "Epoch 1064/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3760 - accuracy: 0.8382 - val_loss: 0.3701 - val_accuracy: 0.8415\n",
            "Epoch 1065/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3773 - accuracy: 0.8396 - val_loss: 0.3691 - val_accuracy: 0.8411\n",
            "Epoch 1066/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3801 - accuracy: 0.8348 - val_loss: 0.3699 - val_accuracy: 0.8401\n",
            "Epoch 1067/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3778 - accuracy: 0.8369 - val_loss: 0.3699 - val_accuracy: 0.8403\n",
            "Epoch 1068/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3766 - accuracy: 0.8372 - val_loss: 0.3691 - val_accuracy: 0.8410\n",
            "Epoch 1069/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3748 - accuracy: 0.8392 - val_loss: 0.3693 - val_accuracy: 0.8410\n",
            "Epoch 1070/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3752 - accuracy: 0.8387 - val_loss: 0.3695 - val_accuracy: 0.8419\n",
            "Epoch 1071/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3747 - accuracy: 0.8378 - val_loss: 0.3679 - val_accuracy: 0.8424\n",
            "Epoch 1072/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3744 - accuracy: 0.8388 - val_loss: 0.3696 - val_accuracy: 0.8420\n",
            "Epoch 1073/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3731 - accuracy: 0.8404 - val_loss: 0.3684 - val_accuracy: 0.8415\n",
            "Epoch 1074/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3737 - accuracy: 0.8404 - val_loss: 0.3686 - val_accuracy: 0.8416\n",
            "Epoch 1075/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3752 - accuracy: 0.8392 - val_loss: 0.3691 - val_accuracy: 0.8411\n",
            "Epoch 1076/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3732 - accuracy: 0.8407 - val_loss: 0.3686 - val_accuracy: 0.8419\n",
            "Epoch 1077/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3807 - accuracy: 0.8363 - val_loss: 0.3687 - val_accuracy: 0.8408\n",
            "Epoch 1078/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3765 - accuracy: 0.8388 - val_loss: 0.3703 - val_accuracy: 0.8412\n",
            "Epoch 1079/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3741 - accuracy: 0.8403 - val_loss: 0.3685 - val_accuracy: 0.8414\n",
            "Epoch 1080/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3711 - accuracy: 0.8409 - val_loss: 0.3684 - val_accuracy: 0.8417\n",
            "Epoch 1081/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3745 - accuracy: 0.8375 - val_loss: 0.3693 - val_accuracy: 0.8409\n",
            "Epoch 1082/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3791 - accuracy: 0.8368 - val_loss: 0.3692 - val_accuracy: 0.8409\n",
            "Epoch 1083/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3784 - accuracy: 0.8391 - val_loss: 0.3680 - val_accuracy: 0.8417\n",
            "Epoch 1084/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3749 - accuracy: 0.8401 - val_loss: 0.3685 - val_accuracy: 0.8424\n",
            "Epoch 1085/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3723 - accuracy: 0.8405 - val_loss: 0.3687 - val_accuracy: 0.8414\n",
            "Epoch 1086/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3703 - accuracy: 0.8419 - val_loss: 0.3685 - val_accuracy: 0.8411\n",
            "Epoch 1087/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3740 - accuracy: 0.8389 - val_loss: 0.3699 - val_accuracy: 0.8418\n",
            "Epoch 1088/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3732 - accuracy: 0.8405 - val_loss: 0.3700 - val_accuracy: 0.8412\n",
            "Epoch 1089/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3776 - accuracy: 0.8366 - val_loss: 0.3689 - val_accuracy: 0.8419\n",
            "Epoch 1090/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3752 - accuracy: 0.8392 - val_loss: 0.3684 - val_accuracy: 0.8423\n",
            "Epoch 1091/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3768 - accuracy: 0.8376 - val_loss: 0.3700 - val_accuracy: 0.8424\n",
            "Epoch 1092/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3767 - accuracy: 0.8392 - val_loss: 0.3693 - val_accuracy: 0.8418\n",
            "Epoch 1093/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3779 - accuracy: 0.8381 - val_loss: 0.3690 - val_accuracy: 0.8424\n",
            "Epoch 1094/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3776 - accuracy: 0.8384 - val_loss: 0.3705 - val_accuracy: 0.8416\n",
            "Epoch 1095/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3755 - accuracy: 0.8380 - val_loss: 0.3712 - val_accuracy: 0.8419\n",
            "Epoch 1096/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3734 - accuracy: 0.8420 - val_loss: 0.3680 - val_accuracy: 0.8415\n",
            "Epoch 1097/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3759 - accuracy: 0.8386 - val_loss: 0.3676 - val_accuracy: 0.8423\n",
            "Epoch 1098/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3730 - accuracy: 0.8403 - val_loss: 0.3683 - val_accuracy: 0.8422\n",
            "Epoch 1099/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3763 - accuracy: 0.8382 - val_loss: 0.3694 - val_accuracy: 0.8423\n",
            "Epoch 1100/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3742 - accuracy: 0.8400 - val_loss: 0.3682 - val_accuracy: 0.8422\n",
            "Epoch 1101/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3757 - accuracy: 0.8402 - val_loss: 0.3689 - val_accuracy: 0.8428\n",
            "Epoch 1102/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3772 - accuracy: 0.8374 - val_loss: 0.3674 - val_accuracy: 0.8427\n",
            "Epoch 1103/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3757 - accuracy: 0.8397 - val_loss: 0.3688 - val_accuracy: 0.8429\n",
            "Epoch 1104/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3756 - accuracy: 0.8382 - val_loss: 0.3684 - val_accuracy: 0.8429\n",
            "Epoch 1105/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3767 - accuracy: 0.8371 - val_loss: 0.3679 - val_accuracy: 0.8420\n",
            "Epoch 1106/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3758 - accuracy: 0.8393 - val_loss: 0.3694 - val_accuracy: 0.8414\n",
            "Epoch 1107/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3770 - accuracy: 0.8379 - val_loss: 0.3689 - val_accuracy: 0.8427\n",
            "Epoch 1108/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3797 - accuracy: 0.8359 - val_loss: 0.3675 - val_accuracy: 0.8423\n",
            "Epoch 1109/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3805 - accuracy: 0.8346 - val_loss: 0.3676 - val_accuracy: 0.8421\n",
            "Epoch 1110/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3754 - accuracy: 0.8378 - val_loss: 0.3681 - val_accuracy: 0.8425\n",
            "Epoch 1111/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3749 - accuracy: 0.8393 - val_loss: 0.3670 - val_accuracy: 0.8424\n",
            "Epoch 1112/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3755 - accuracy: 0.8377 - val_loss: 0.3686 - val_accuracy: 0.8418\n",
            "Epoch 1113/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3784 - accuracy: 0.8369 - val_loss: 0.3676 - val_accuracy: 0.8420\n",
            "Epoch 1114/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3775 - accuracy: 0.8384 - val_loss: 0.3695 - val_accuracy: 0.8416\n",
            "Epoch 1115/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3762 - accuracy: 0.8402 - val_loss: 0.3695 - val_accuracy: 0.8420\n",
            "Epoch 1116/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3724 - accuracy: 0.8417 - val_loss: 0.3686 - val_accuracy: 0.8416\n",
            "Epoch 1117/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3753 - accuracy: 0.8372 - val_loss: 0.3690 - val_accuracy: 0.8415\n",
            "Epoch 1118/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3790 - accuracy: 0.8370 - val_loss: 0.3677 - val_accuracy: 0.8427\n",
            "Epoch 1119/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3752 - accuracy: 0.8396 - val_loss: 0.3676 - val_accuracy: 0.8424\n",
            "Epoch 1120/1500\n",
            "2532/2532 [==============================] - 8s 3ms/step - loss: 0.3739 - accuracy: 0.8402 - val_loss: 0.3674 - val_accuracy: 0.8415\n",
            "Epoch 1121/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3744 - accuracy: 0.8406 - val_loss: 0.3677 - val_accuracy: 0.8420\n",
            "Epoch 1122/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3752 - accuracy: 0.8398 - val_loss: 0.3685 - val_accuracy: 0.8424\n",
            "Epoch 1123/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3759 - accuracy: 0.8385 - val_loss: 0.3688 - val_accuracy: 0.8424\n",
            "Epoch 1124/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3784 - accuracy: 0.8367 - val_loss: 0.3668 - val_accuracy: 0.8416\n",
            "Epoch 1125/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3733 - accuracy: 0.8400 - val_loss: 0.3676 - val_accuracy: 0.8425\n",
            "Epoch 1126/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3782 - accuracy: 0.8381 - val_loss: 0.3677 - val_accuracy: 0.8418\n",
            "Epoch 1127/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3761 - accuracy: 0.8382 - val_loss: 0.3673 - val_accuracy: 0.8423\n",
            "Epoch 1128/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3755 - accuracy: 0.8384 - val_loss: 0.3668 - val_accuracy: 0.8433\n",
            "Epoch 1129/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3779 - accuracy: 0.8365 - val_loss: 0.3672 - val_accuracy: 0.8422\n",
            "Epoch 1130/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3739 - accuracy: 0.8398 - val_loss: 0.3695 - val_accuracy: 0.8424\n",
            "Epoch 1131/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3763 - accuracy: 0.8384 - val_loss: 0.3684 - val_accuracy: 0.8416\n",
            "Epoch 1132/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3739 - accuracy: 0.8396 - val_loss: 0.3676 - val_accuracy: 0.8425\n",
            "Epoch 1133/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3761 - accuracy: 0.8391 - val_loss: 0.3676 - val_accuracy: 0.8430\n",
            "Epoch 1134/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3748 - accuracy: 0.8380 - val_loss: 0.3670 - val_accuracy: 0.8415\n",
            "Epoch 1135/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3729 - accuracy: 0.8410 - val_loss: 0.3672 - val_accuracy: 0.8421\n",
            "Epoch 1136/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3752 - accuracy: 0.8389 - val_loss: 0.3676 - val_accuracy: 0.8424\n",
            "Epoch 1137/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3714 - accuracy: 0.8413 - val_loss: 0.3675 - val_accuracy: 0.8425\n",
            "Epoch 1138/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3784 - accuracy: 0.8372 - val_loss: 0.3671 - val_accuracy: 0.8414\n",
            "Epoch 1139/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3723 - accuracy: 0.8405 - val_loss: 0.3687 - val_accuracy: 0.8413\n",
            "Epoch 1140/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3752 - accuracy: 0.8376 - val_loss: 0.3678 - val_accuracy: 0.8427\n",
            "Epoch 1141/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3715 - accuracy: 0.8414 - val_loss: 0.3672 - val_accuracy: 0.8425\n",
            "Epoch 1142/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3754 - accuracy: 0.8403 - val_loss: 0.3679 - val_accuracy: 0.8424\n",
            "Epoch 1143/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3762 - accuracy: 0.8382 - val_loss: 0.3688 - val_accuracy: 0.8420\n",
            "Epoch 1144/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3756 - accuracy: 0.8378 - val_loss: 0.3672 - val_accuracy: 0.8434\n",
            "Epoch 1145/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3757 - accuracy: 0.8387 - val_loss: 0.3677 - val_accuracy: 0.8426\n",
            "Epoch 1146/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3766 - accuracy: 0.8378 - val_loss: 0.3669 - val_accuracy: 0.8422\n",
            "Epoch 1147/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3728 - accuracy: 0.8401 - val_loss: 0.3684 - val_accuracy: 0.8415\n",
            "Epoch 1148/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3759 - accuracy: 0.8386 - val_loss: 0.3677 - val_accuracy: 0.8425\n",
            "Epoch 1149/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3755 - accuracy: 0.8407 - val_loss: 0.3681 - val_accuracy: 0.8434\n",
            "Epoch 1150/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3748 - accuracy: 0.8389 - val_loss: 0.3663 - val_accuracy: 0.8433\n",
            "Epoch 1151/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3752 - accuracy: 0.8382 - val_loss: 0.3674 - val_accuracy: 0.8431\n",
            "Epoch 1152/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3751 - accuracy: 0.8388 - val_loss: 0.3675 - val_accuracy: 0.8429\n",
            "Epoch 1153/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3759 - accuracy: 0.8380 - val_loss: 0.3666 - val_accuracy: 0.8427\n",
            "Epoch 1154/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3714 - accuracy: 0.8413 - val_loss: 0.3672 - val_accuracy: 0.8426\n",
            "Epoch 1155/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3734 - accuracy: 0.8394 - val_loss: 0.3676 - val_accuracy: 0.8436\n",
            "Epoch 1156/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3731 - accuracy: 0.8408 - val_loss: 0.3672 - val_accuracy: 0.8429\n",
            "Epoch 1157/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3741 - accuracy: 0.8394 - val_loss: 0.3677 - val_accuracy: 0.8422\n",
            "Epoch 1158/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3739 - accuracy: 0.8395 - val_loss: 0.3665 - val_accuracy: 0.8434\n",
            "Epoch 1159/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3752 - accuracy: 0.8392 - val_loss: 0.3684 - val_accuracy: 0.8423\n",
            "Epoch 1160/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3714 - accuracy: 0.8407 - val_loss: 0.3674 - val_accuracy: 0.8428\n",
            "Epoch 1161/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3758 - accuracy: 0.8385 - val_loss: 0.3667 - val_accuracy: 0.8428\n",
            "Epoch 1162/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3791 - accuracy: 0.8371 - val_loss: 0.3683 - val_accuracy: 0.8425\n",
            "Epoch 1163/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3747 - accuracy: 0.8394 - val_loss: 0.3672 - val_accuracy: 0.8433\n",
            "Epoch 1164/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3773 - accuracy: 0.8375 - val_loss: 0.3676 - val_accuracy: 0.8424\n",
            "Epoch 1165/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3741 - accuracy: 0.8398 - val_loss: 0.3672 - val_accuracy: 0.8430\n",
            "Epoch 1166/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3764 - accuracy: 0.8392 - val_loss: 0.3674 - val_accuracy: 0.8431\n",
            "Epoch 1167/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3739 - accuracy: 0.8386 - val_loss: 0.3663 - val_accuracy: 0.8425\n",
            "Epoch 1168/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3729 - accuracy: 0.8395 - val_loss: 0.3674 - val_accuracy: 0.8418\n",
            "Epoch 1169/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3724 - accuracy: 0.8413 - val_loss: 0.3670 - val_accuracy: 0.8429\n",
            "Epoch 1170/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3773 - accuracy: 0.8373 - val_loss: 0.3661 - val_accuracy: 0.8425\n",
            "Epoch 1171/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3771 - accuracy: 0.8397 - val_loss: 0.3668 - val_accuracy: 0.8431\n",
            "Epoch 1172/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3720 - accuracy: 0.8408 - val_loss: 0.3673 - val_accuracy: 0.8424\n",
            "Epoch 1173/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3731 - accuracy: 0.8396 - val_loss: 0.3675 - val_accuracy: 0.8435\n",
            "Epoch 1174/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3725 - accuracy: 0.8407 - val_loss: 0.3682 - val_accuracy: 0.8415\n",
            "Epoch 1175/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3743 - accuracy: 0.8378 - val_loss: 0.3663 - val_accuracy: 0.8443\n",
            "Epoch 1176/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3748 - accuracy: 0.8394 - val_loss: 0.3664 - val_accuracy: 0.8436\n",
            "Epoch 1177/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3752 - accuracy: 0.8395 - val_loss: 0.3673 - val_accuracy: 0.8429\n",
            "Epoch 1178/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3735 - accuracy: 0.8395 - val_loss: 0.3687 - val_accuracy: 0.8427\n",
            "Epoch 1179/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3721 - accuracy: 0.8393 - val_loss: 0.3687 - val_accuracy: 0.8428\n",
            "Epoch 1180/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3744 - accuracy: 0.8387 - val_loss: 0.3666 - val_accuracy: 0.8429\n",
            "Epoch 1181/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3739 - accuracy: 0.8408 - val_loss: 0.3659 - val_accuracy: 0.8434\n",
            "Epoch 1182/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3740 - accuracy: 0.8409 - val_loss: 0.3666 - val_accuracy: 0.8422\n",
            "Epoch 1183/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3754 - accuracy: 0.8401 - val_loss: 0.3661 - val_accuracy: 0.8431\n",
            "Epoch 1184/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3753 - accuracy: 0.8395 - val_loss: 0.3653 - val_accuracy: 0.8441\n",
            "Epoch 1185/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3749 - accuracy: 0.8399 - val_loss: 0.3678 - val_accuracy: 0.8425\n",
            "Epoch 1186/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3740 - accuracy: 0.8390 - val_loss: 0.3664 - val_accuracy: 0.8435\n",
            "Epoch 1187/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3739 - accuracy: 0.8404 - val_loss: 0.3663 - val_accuracy: 0.8429\n",
            "Epoch 1188/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3756 - accuracy: 0.8374 - val_loss: 0.3672 - val_accuracy: 0.8426\n",
            "Epoch 1189/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3722 - accuracy: 0.8406 - val_loss: 0.3667 - val_accuracy: 0.8442\n",
            "Epoch 1190/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3747 - accuracy: 0.8371 - val_loss: 0.3666 - val_accuracy: 0.8435\n",
            "Epoch 1191/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3728 - accuracy: 0.8404 - val_loss: 0.3656 - val_accuracy: 0.8432\n",
            "Epoch 1192/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3747 - accuracy: 0.8393 - val_loss: 0.3663 - val_accuracy: 0.8439\n",
            "Epoch 1193/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3788 - accuracy: 0.8370 - val_loss: 0.3666 - val_accuracy: 0.8428\n",
            "Epoch 1194/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3705 - accuracy: 0.8406 - val_loss: 0.3665 - val_accuracy: 0.8438\n",
            "Epoch 1195/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3722 - accuracy: 0.8394 - val_loss: 0.3665 - val_accuracy: 0.8426\n",
            "Epoch 1196/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3750 - accuracy: 0.8375 - val_loss: 0.3670 - val_accuracy: 0.8425\n",
            "Epoch 1197/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3760 - accuracy: 0.8394 - val_loss: 0.3651 - val_accuracy: 0.8432\n",
            "Epoch 1198/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3729 - accuracy: 0.8422 - val_loss: 0.3653 - val_accuracy: 0.8438\n",
            "Epoch 1199/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3736 - accuracy: 0.8394 - val_loss: 0.3663 - val_accuracy: 0.8432\n",
            "Epoch 1200/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3715 - accuracy: 0.8427 - val_loss: 0.3674 - val_accuracy: 0.8426\n",
            "Epoch 1201/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3691 - accuracy: 0.8427 - val_loss: 0.3665 - val_accuracy: 0.8440\n",
            "Epoch 1202/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3719 - accuracy: 0.8398 - val_loss: 0.3658 - val_accuracy: 0.8423\n",
            "Epoch 1203/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3728 - accuracy: 0.8402 - val_loss: 0.3669 - val_accuracy: 0.8428\n",
            "Epoch 1204/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3750 - accuracy: 0.8407 - val_loss: 0.3665 - val_accuracy: 0.8424\n",
            "Epoch 1205/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3742 - accuracy: 0.8395 - val_loss: 0.3656 - val_accuracy: 0.8429\n",
            "Epoch 1206/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3711 - accuracy: 0.8411 - val_loss: 0.3664 - val_accuracy: 0.8424\n",
            "Epoch 1207/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3721 - accuracy: 0.8411 - val_loss: 0.3658 - val_accuracy: 0.8418\n",
            "Epoch 1208/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3758 - accuracy: 0.8388 - val_loss: 0.3665 - val_accuracy: 0.8432\n",
            "Epoch 1209/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3705 - accuracy: 0.8419 - val_loss: 0.3671 - val_accuracy: 0.8421\n",
            "Epoch 1210/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3739 - accuracy: 0.8406 - val_loss: 0.3657 - val_accuracy: 0.8439\n",
            "Epoch 1211/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3727 - accuracy: 0.8399 - val_loss: 0.3652 - val_accuracy: 0.8429\n",
            "Epoch 1212/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3760 - accuracy: 0.8393 - val_loss: 0.3657 - val_accuracy: 0.8440\n",
            "Epoch 1213/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3778 - accuracy: 0.8376 - val_loss: 0.3666 - val_accuracy: 0.8434\n",
            "Epoch 1214/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3727 - accuracy: 0.8402 - val_loss: 0.3659 - val_accuracy: 0.8435\n",
            "Epoch 1215/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3762 - accuracy: 0.8378 - val_loss: 0.3648 - val_accuracy: 0.8445\n",
            "Epoch 1216/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3743 - accuracy: 0.8408 - val_loss: 0.3664 - val_accuracy: 0.8446\n",
            "Epoch 1217/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3737 - accuracy: 0.8393 - val_loss: 0.3652 - val_accuracy: 0.8447\n",
            "Epoch 1218/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3731 - accuracy: 0.8385 - val_loss: 0.3663 - val_accuracy: 0.8427\n",
            "Epoch 1219/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3779 - accuracy: 0.8377 - val_loss: 0.3665 - val_accuracy: 0.8433\n",
            "Epoch 1220/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3735 - accuracy: 0.8394 - val_loss: 0.3658 - val_accuracy: 0.8442\n",
            "Epoch 1221/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3728 - accuracy: 0.8408 - val_loss: 0.3671 - val_accuracy: 0.8424\n",
            "Epoch 1222/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3694 - accuracy: 0.8404 - val_loss: 0.3676 - val_accuracy: 0.8431\n",
            "Epoch 1223/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3734 - accuracy: 0.8400 - val_loss: 0.3672 - val_accuracy: 0.8434\n",
            "Epoch 1224/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3728 - accuracy: 0.8398 - val_loss: 0.3670 - val_accuracy: 0.8432\n",
            "Epoch 1225/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3727 - accuracy: 0.8413 - val_loss: 0.3648 - val_accuracy: 0.8434\n",
            "Epoch 1226/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3696 - accuracy: 0.8406 - val_loss: 0.3658 - val_accuracy: 0.8434\n",
            "Epoch 1227/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3762 - accuracy: 0.8378 - val_loss: 0.3654 - val_accuracy: 0.8436\n",
            "Epoch 1228/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3720 - accuracy: 0.8411 - val_loss: 0.3661 - val_accuracy: 0.8424\n",
            "Epoch 1229/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3727 - accuracy: 0.8414 - val_loss: 0.3647 - val_accuracy: 0.8438\n",
            "Epoch 1230/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3750 - accuracy: 0.8397 - val_loss: 0.3660 - val_accuracy: 0.8433\n",
            "Epoch 1231/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3733 - accuracy: 0.8402 - val_loss: 0.3667 - val_accuracy: 0.8428\n",
            "Epoch 1232/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3751 - accuracy: 0.8400 - val_loss: 0.3670 - val_accuracy: 0.8433\n",
            "Epoch 1233/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3732 - accuracy: 0.8397 - val_loss: 0.3665 - val_accuracy: 0.8427\n",
            "Epoch 1234/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3724 - accuracy: 0.8399 - val_loss: 0.3648 - val_accuracy: 0.8428\n",
            "Epoch 1235/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3701 - accuracy: 0.8410 - val_loss: 0.3650 - val_accuracy: 0.8443\n",
            "Epoch 1236/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3721 - accuracy: 0.8414 - val_loss: 0.3645 - val_accuracy: 0.8443\n",
            "Epoch 1237/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3740 - accuracy: 0.8388 - val_loss: 0.3658 - val_accuracy: 0.8431\n",
            "Epoch 1238/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3686 - accuracy: 0.8412 - val_loss: 0.3657 - val_accuracy: 0.8440\n",
            "Epoch 1239/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3720 - accuracy: 0.8420 - val_loss: 0.3662 - val_accuracy: 0.8440\n",
            "Epoch 1240/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3784 - accuracy: 0.8381 - val_loss: 0.3652 - val_accuracy: 0.8432\n",
            "Epoch 1241/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3726 - accuracy: 0.8388 - val_loss: 0.3640 - val_accuracy: 0.8436\n",
            "Epoch 1242/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3733 - accuracy: 0.8401 - val_loss: 0.3662 - val_accuracy: 0.8430\n",
            "Epoch 1243/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3738 - accuracy: 0.8410 - val_loss: 0.3660 - val_accuracy: 0.8425\n",
            "Epoch 1244/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3703 - accuracy: 0.8429 - val_loss: 0.3652 - val_accuracy: 0.8432\n",
            "Epoch 1245/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3725 - accuracy: 0.8420 - val_loss: 0.3660 - val_accuracy: 0.8442\n",
            "Epoch 1246/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3707 - accuracy: 0.8421 - val_loss: 0.3661 - val_accuracy: 0.8431\n",
            "Epoch 1247/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3723 - accuracy: 0.8388 - val_loss: 0.3651 - val_accuracy: 0.8438\n",
            "Epoch 1248/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3737 - accuracy: 0.8397 - val_loss: 0.3649 - val_accuracy: 0.8443\n",
            "Epoch 1249/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3734 - accuracy: 0.8414 - val_loss: 0.3655 - val_accuracy: 0.8433\n",
            "Epoch 1250/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3721 - accuracy: 0.8410 - val_loss: 0.3659 - val_accuracy: 0.8446\n",
            "Epoch 1251/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3717 - accuracy: 0.8404 - val_loss: 0.3654 - val_accuracy: 0.8434\n",
            "Epoch 1252/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3775 - accuracy: 0.8378 - val_loss: 0.3652 - val_accuracy: 0.8431\n",
            "Epoch 1253/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3718 - accuracy: 0.8415 - val_loss: 0.3647 - val_accuracy: 0.8446\n",
            "Epoch 1254/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3733 - accuracy: 0.8407 - val_loss: 0.3648 - val_accuracy: 0.8447\n",
            "Epoch 1255/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3734 - accuracy: 0.8383 - val_loss: 0.3646 - val_accuracy: 0.8443\n",
            "Epoch 1256/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3710 - accuracy: 0.8426 - val_loss: 0.3657 - val_accuracy: 0.8436\n",
            "Epoch 1257/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3739 - accuracy: 0.8384 - val_loss: 0.3642 - val_accuracy: 0.8448\n",
            "Epoch 1258/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3687 - accuracy: 0.8427 - val_loss: 0.3659 - val_accuracy: 0.8439\n",
            "Epoch 1259/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3696 - accuracy: 0.8422 - val_loss: 0.3650 - val_accuracy: 0.8452\n",
            "Epoch 1260/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3703 - accuracy: 0.8425 - val_loss: 0.3635 - val_accuracy: 0.8455\n",
            "Epoch 1261/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3754 - accuracy: 0.8385 - val_loss: 0.3647 - val_accuracy: 0.8441\n",
            "Epoch 1262/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3696 - accuracy: 0.8433 - val_loss: 0.3663 - val_accuracy: 0.8433\n",
            "Epoch 1263/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3704 - accuracy: 0.8396 - val_loss: 0.3663 - val_accuracy: 0.8433\n",
            "Epoch 1264/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3748 - accuracy: 0.8394 - val_loss: 0.3647 - val_accuracy: 0.8438\n",
            "Epoch 1265/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3796 - accuracy: 0.8371 - val_loss: 0.3652 - val_accuracy: 0.8428\n",
            "Epoch 1266/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3748 - accuracy: 0.8395 - val_loss: 0.3657 - val_accuracy: 0.8434\n",
            "Epoch 1267/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3738 - accuracy: 0.8406 - val_loss: 0.3653 - val_accuracy: 0.8439\n",
            "Epoch 1268/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3705 - accuracy: 0.8419 - val_loss: 0.3647 - val_accuracy: 0.8441\n",
            "Epoch 1269/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3716 - accuracy: 0.8409 - val_loss: 0.3652 - val_accuracy: 0.8443\n",
            "Epoch 1270/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3684 - accuracy: 0.8422 - val_loss: 0.3637 - val_accuracy: 0.8452\n",
            "Epoch 1271/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3712 - accuracy: 0.8413 - val_loss: 0.3643 - val_accuracy: 0.8444\n",
            "Epoch 1272/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3763 - accuracy: 0.8406 - val_loss: 0.3635 - val_accuracy: 0.8452\n",
            "Epoch 1273/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3685 - accuracy: 0.8438 - val_loss: 0.3649 - val_accuracy: 0.8441\n",
            "Epoch 1274/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3719 - accuracy: 0.8399 - val_loss: 0.3654 - val_accuracy: 0.8435\n",
            "Epoch 1275/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3767 - accuracy: 0.8401 - val_loss: 0.3647 - val_accuracy: 0.8443\n",
            "Epoch 1276/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3736 - accuracy: 0.8394 - val_loss: 0.3639 - val_accuracy: 0.8453\n",
            "Epoch 1277/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3713 - accuracy: 0.8415 - val_loss: 0.3648 - val_accuracy: 0.8443\n",
            "Epoch 1278/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3706 - accuracy: 0.8405 - val_loss: 0.3661 - val_accuracy: 0.8436\n",
            "Epoch 1279/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3733 - accuracy: 0.8405 - val_loss: 0.3651 - val_accuracy: 0.8442\n",
            "Epoch 1280/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3735 - accuracy: 0.8394 - val_loss: 0.3643 - val_accuracy: 0.8440\n",
            "Epoch 1281/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3717 - accuracy: 0.8419 - val_loss: 0.3648 - val_accuracy: 0.8443\n",
            "Epoch 1282/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3731 - accuracy: 0.8402 - val_loss: 0.3654 - val_accuracy: 0.8441\n",
            "Epoch 1283/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3746 - accuracy: 0.8382 - val_loss: 0.3660 - val_accuracy: 0.8439\n",
            "Epoch 1284/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3698 - accuracy: 0.8420 - val_loss: 0.3647 - val_accuracy: 0.8443\n",
            "Epoch 1285/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3698 - accuracy: 0.8429 - val_loss: 0.3661 - val_accuracy: 0.8429\n",
            "Epoch 1286/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3748 - accuracy: 0.8392 - val_loss: 0.3641 - val_accuracy: 0.8449\n",
            "Epoch 1287/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3714 - accuracy: 0.8419 - val_loss: 0.3644 - val_accuracy: 0.8439\n",
            "Epoch 1288/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3707 - accuracy: 0.8413 - val_loss: 0.3655 - val_accuracy: 0.8443\n",
            "Epoch 1289/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3740 - accuracy: 0.8400 - val_loss: 0.3648 - val_accuracy: 0.8439\n",
            "Epoch 1290/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3720 - accuracy: 0.8411 - val_loss: 0.3647 - val_accuracy: 0.8450\n",
            "Epoch 1291/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3732 - accuracy: 0.8400 - val_loss: 0.3630 - val_accuracy: 0.8449\n",
            "Epoch 1292/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3745 - accuracy: 0.8387 - val_loss: 0.3658 - val_accuracy: 0.8431\n",
            "Epoch 1293/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3735 - accuracy: 0.8405 - val_loss: 0.3640 - val_accuracy: 0.8444\n",
            "Epoch 1294/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3723 - accuracy: 0.8405 - val_loss: 0.3638 - val_accuracy: 0.8446\n",
            "Epoch 1295/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3711 - accuracy: 0.8410 - val_loss: 0.3637 - val_accuracy: 0.8444\n",
            "Epoch 1296/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3706 - accuracy: 0.8421 - val_loss: 0.3645 - val_accuracy: 0.8448\n",
            "Epoch 1297/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3718 - accuracy: 0.8409 - val_loss: 0.3639 - val_accuracy: 0.8446\n",
            "Epoch 1298/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3716 - accuracy: 0.8417 - val_loss: 0.3649 - val_accuracy: 0.8452\n",
            "Epoch 1299/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3699 - accuracy: 0.8429 - val_loss: 0.3651 - val_accuracy: 0.8444\n",
            "Epoch 1300/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3734 - accuracy: 0.8401 - val_loss: 0.3651 - val_accuracy: 0.8431\n",
            "Epoch 1301/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3681 - accuracy: 0.8432 - val_loss: 0.3649 - val_accuracy: 0.8432\n",
            "Epoch 1302/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3701 - accuracy: 0.8411 - val_loss: 0.3650 - val_accuracy: 0.8442\n",
            "Epoch 1303/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3723 - accuracy: 0.8417 - val_loss: 0.3641 - val_accuracy: 0.8443\n",
            "Epoch 1304/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3711 - accuracy: 0.8423 - val_loss: 0.3657 - val_accuracy: 0.8438\n",
            "Epoch 1305/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3694 - accuracy: 0.8428 - val_loss: 0.3646 - val_accuracy: 0.8447\n",
            "Epoch 1306/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3718 - accuracy: 0.8409 - val_loss: 0.3637 - val_accuracy: 0.8446\n",
            "Epoch 1307/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3724 - accuracy: 0.8407 - val_loss: 0.3646 - val_accuracy: 0.8439\n",
            "Epoch 1308/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3705 - accuracy: 0.8412 - val_loss: 0.3640 - val_accuracy: 0.8445\n",
            "Epoch 1309/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3714 - accuracy: 0.8417 - val_loss: 0.3659 - val_accuracy: 0.8430\n",
            "Epoch 1310/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3710 - accuracy: 0.8409 - val_loss: 0.3644 - val_accuracy: 0.8439\n",
            "Epoch 1311/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3717 - accuracy: 0.8434 - val_loss: 0.3632 - val_accuracy: 0.8442\n",
            "Epoch 1312/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3741 - accuracy: 0.8377 - val_loss: 0.3642 - val_accuracy: 0.8448\n",
            "Epoch 1313/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3701 - accuracy: 0.8413 - val_loss: 0.3647 - val_accuracy: 0.8445\n",
            "Epoch 1314/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3714 - accuracy: 0.8422 - val_loss: 0.3632 - val_accuracy: 0.8445\n",
            "Epoch 1315/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3700 - accuracy: 0.8416 - val_loss: 0.3636 - val_accuracy: 0.8450\n",
            "Epoch 1316/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3698 - accuracy: 0.8407 - val_loss: 0.3638 - val_accuracy: 0.8444\n",
            "Epoch 1317/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3789 - accuracy: 0.8393 - val_loss: 0.3643 - val_accuracy: 0.8439\n",
            "Epoch 1318/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3682 - accuracy: 0.8417 - val_loss: 0.3645 - val_accuracy: 0.8441\n",
            "Epoch 1319/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3690 - accuracy: 0.8436 - val_loss: 0.3665 - val_accuracy: 0.8437\n",
            "Epoch 1320/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3733 - accuracy: 0.8392 - val_loss: 0.3647 - val_accuracy: 0.8436\n",
            "Epoch 1321/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3726 - accuracy: 0.8374 - val_loss: 0.3643 - val_accuracy: 0.8438\n",
            "Epoch 1322/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3746 - accuracy: 0.8378 - val_loss: 0.3630 - val_accuracy: 0.8457\n",
            "Epoch 1323/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3705 - accuracy: 0.8436 - val_loss: 0.3653 - val_accuracy: 0.8443\n",
            "Epoch 1324/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3787 - accuracy: 0.8371 - val_loss: 0.3633 - val_accuracy: 0.8452\n",
            "Epoch 1325/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3728 - accuracy: 0.8392 - val_loss: 0.3650 - val_accuracy: 0.8442\n",
            "Epoch 1326/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3686 - accuracy: 0.8423 - val_loss: 0.3637 - val_accuracy: 0.8441\n",
            "Epoch 1327/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3737 - accuracy: 0.8409 - val_loss: 0.3636 - val_accuracy: 0.8445\n",
            "Epoch 1328/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3736 - accuracy: 0.8398 - val_loss: 0.3640 - val_accuracy: 0.8446\n",
            "Epoch 1329/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3747 - accuracy: 0.8387 - val_loss: 0.3629 - val_accuracy: 0.8445\n",
            "Epoch 1330/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3723 - accuracy: 0.8415 - val_loss: 0.3641 - val_accuracy: 0.8441\n",
            "Epoch 1331/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3700 - accuracy: 0.8434 - val_loss: 0.3629 - val_accuracy: 0.8445\n",
            "Epoch 1332/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3675 - accuracy: 0.8433 - val_loss: 0.3641 - val_accuracy: 0.8446\n",
            "Epoch 1333/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3708 - accuracy: 0.8420 - val_loss: 0.3634 - val_accuracy: 0.8444\n",
            "Epoch 1334/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3674 - accuracy: 0.8425 - val_loss: 0.3634 - val_accuracy: 0.8449\n",
            "Epoch 1335/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3700 - accuracy: 0.8424 - val_loss: 0.3646 - val_accuracy: 0.8446\n",
            "Epoch 1336/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3716 - accuracy: 0.8424 - val_loss: 0.3639 - val_accuracy: 0.8454\n",
            "Epoch 1337/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3707 - accuracy: 0.8420 - val_loss: 0.3639 - val_accuracy: 0.8445\n",
            "Epoch 1338/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3728 - accuracy: 0.8399 - val_loss: 0.3646 - val_accuracy: 0.8449\n",
            "Epoch 1339/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3684 - accuracy: 0.8428 - val_loss: 0.3651 - val_accuracy: 0.8436\n",
            "Epoch 1340/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3700 - accuracy: 0.8417 - val_loss: 0.3630 - val_accuracy: 0.8446\n",
            "Epoch 1341/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3735 - accuracy: 0.8391 - val_loss: 0.3646 - val_accuracy: 0.8441\n",
            "Epoch 1342/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3734 - accuracy: 0.8403 - val_loss: 0.3631 - val_accuracy: 0.8448\n",
            "Epoch 1343/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3676 - accuracy: 0.8428 - val_loss: 0.3640 - val_accuracy: 0.8451\n",
            "Epoch 1344/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3678 - accuracy: 0.8440 - val_loss: 0.3636 - val_accuracy: 0.8453\n",
            "Epoch 1345/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3673 - accuracy: 0.8427 - val_loss: 0.3654 - val_accuracy: 0.8438\n",
            "Epoch 1346/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3705 - accuracy: 0.8405 - val_loss: 0.3641 - val_accuracy: 0.8441\n",
            "Epoch 1347/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3708 - accuracy: 0.8399 - val_loss: 0.3630 - val_accuracy: 0.8448\n",
            "Epoch 1348/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3692 - accuracy: 0.8421 - val_loss: 0.3627 - val_accuracy: 0.8454\n",
            "Epoch 1349/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3747 - accuracy: 0.8381 - val_loss: 0.3644 - val_accuracy: 0.8453\n",
            "Epoch 1350/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3716 - accuracy: 0.8390 - val_loss: 0.3630 - val_accuracy: 0.8440\n",
            "Epoch 1351/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3719 - accuracy: 0.8391 - val_loss: 0.3633 - val_accuracy: 0.8442\n",
            "Epoch 1352/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3694 - accuracy: 0.8430 - val_loss: 0.3643 - val_accuracy: 0.8448\n",
            "Epoch 1353/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3715 - accuracy: 0.8401 - val_loss: 0.3641 - val_accuracy: 0.8447\n",
            "Epoch 1354/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3734 - accuracy: 0.8405 - val_loss: 0.3644 - val_accuracy: 0.8436\n",
            "Epoch 1355/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3740 - accuracy: 0.8394 - val_loss: 0.3631 - val_accuracy: 0.8451\n",
            "Epoch 1356/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3667 - accuracy: 0.8425 - val_loss: 0.3638 - val_accuracy: 0.8452\n",
            "Epoch 1357/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3681 - accuracy: 0.8413 - val_loss: 0.3648 - val_accuracy: 0.8449\n",
            "Epoch 1358/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3669 - accuracy: 0.8440 - val_loss: 0.3639 - val_accuracy: 0.8453\n",
            "Epoch 1359/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3692 - accuracy: 0.8416 - val_loss: 0.3631 - val_accuracy: 0.8447\n",
            "Epoch 1360/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3679 - accuracy: 0.8443 - val_loss: 0.3629 - val_accuracy: 0.8450\n",
            "Epoch 1361/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3697 - accuracy: 0.8414 - val_loss: 0.3626 - val_accuracy: 0.8447\n",
            "Epoch 1362/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3654 - accuracy: 0.8423 - val_loss: 0.3642 - val_accuracy: 0.8446\n",
            "Epoch 1363/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3760 - accuracy: 0.8394 - val_loss: 0.3630 - val_accuracy: 0.8453\n",
            "Epoch 1364/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3734 - accuracy: 0.8402 - val_loss: 0.3625 - val_accuracy: 0.8452\n",
            "Epoch 1365/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3725 - accuracy: 0.8402 - val_loss: 0.3617 - val_accuracy: 0.8453\n",
            "Epoch 1366/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3731 - accuracy: 0.8418 - val_loss: 0.3628 - val_accuracy: 0.8449\n",
            "Epoch 1367/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3702 - accuracy: 0.8417 - val_loss: 0.3637 - val_accuracy: 0.8444\n",
            "Epoch 1368/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3686 - accuracy: 0.8421 - val_loss: 0.3634 - val_accuracy: 0.8452\n",
            "Epoch 1369/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3753 - accuracy: 0.8403 - val_loss: 0.3623 - val_accuracy: 0.8445\n",
            "Epoch 1370/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3719 - accuracy: 0.8398 - val_loss: 0.3631 - val_accuracy: 0.8443\n",
            "Epoch 1371/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3734 - accuracy: 0.8408 - val_loss: 0.3634 - val_accuracy: 0.8442\n",
            "Epoch 1372/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3683 - accuracy: 0.8416 - val_loss: 0.3638 - val_accuracy: 0.8443\n",
            "Epoch 1373/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3712 - accuracy: 0.8388 - val_loss: 0.3625 - val_accuracy: 0.8446\n",
            "Epoch 1374/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3729 - accuracy: 0.8384 - val_loss: 0.3617 - val_accuracy: 0.8449\n",
            "Epoch 1375/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3707 - accuracy: 0.8408 - val_loss: 0.3644 - val_accuracy: 0.8444\n",
            "Epoch 1376/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3663 - accuracy: 0.8423 - val_loss: 0.3636 - val_accuracy: 0.8456\n",
            "Epoch 1377/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3729 - accuracy: 0.8400 - val_loss: 0.3637 - val_accuracy: 0.8445\n",
            "Epoch 1378/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3705 - accuracy: 0.8405 - val_loss: 0.3631 - val_accuracy: 0.8450\n",
            "Epoch 1379/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3714 - accuracy: 0.8412 - val_loss: 0.3646 - val_accuracy: 0.8444\n",
            "Epoch 1380/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3708 - accuracy: 0.8423 - val_loss: 0.3629 - val_accuracy: 0.8452\n",
            "Epoch 1381/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3755 - accuracy: 0.8395 - val_loss: 0.3629 - val_accuracy: 0.8443\n",
            "Epoch 1382/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3671 - accuracy: 0.8431 - val_loss: 0.3631 - val_accuracy: 0.8448\n",
            "Epoch 1383/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3699 - accuracy: 0.8420 - val_loss: 0.3628 - val_accuracy: 0.8448\n",
            "Epoch 1384/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3663 - accuracy: 0.8429 - val_loss: 0.3636 - val_accuracy: 0.8447\n",
            "Epoch 1385/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3685 - accuracy: 0.8430 - val_loss: 0.3633 - val_accuracy: 0.8451\n",
            "Epoch 1386/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3724 - accuracy: 0.8387 - val_loss: 0.3631 - val_accuracy: 0.8447\n",
            "Epoch 1387/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3703 - accuracy: 0.8411 - val_loss: 0.3639 - val_accuracy: 0.8452\n",
            "Epoch 1388/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3704 - accuracy: 0.8414 - val_loss: 0.3629 - val_accuracy: 0.8437\n",
            "Epoch 1389/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3702 - accuracy: 0.8412 - val_loss: 0.3632 - val_accuracy: 0.8443\n",
            "Epoch 1390/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3712 - accuracy: 0.8399 - val_loss: 0.3634 - val_accuracy: 0.8450\n",
            "Epoch 1391/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3679 - accuracy: 0.8433 - val_loss: 0.3620 - val_accuracy: 0.8449\n",
            "Epoch 1392/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3671 - accuracy: 0.8424 - val_loss: 0.3631 - val_accuracy: 0.8451\n",
            "Epoch 1393/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3718 - accuracy: 0.8416 - val_loss: 0.3632 - val_accuracy: 0.8436\n",
            "Epoch 1394/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3654 - accuracy: 0.8443 - val_loss: 0.3631 - val_accuracy: 0.8450\n",
            "Epoch 1395/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3681 - accuracy: 0.8404 - val_loss: 0.3632 - val_accuracy: 0.8447\n",
            "Epoch 1396/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3720 - accuracy: 0.8422 - val_loss: 0.3626 - val_accuracy: 0.8451\n",
            "Epoch 1397/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3692 - accuracy: 0.8399 - val_loss: 0.3624 - val_accuracy: 0.8450\n",
            "Epoch 1398/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3697 - accuracy: 0.8423 - val_loss: 0.3627 - val_accuracy: 0.8448\n",
            "Epoch 1399/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3702 - accuracy: 0.8424 - val_loss: 0.3627 - val_accuracy: 0.8450\n",
            "Epoch 1400/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3648 - accuracy: 0.8418 - val_loss: 0.3628 - val_accuracy: 0.8455\n",
            "Epoch 1401/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3720 - accuracy: 0.8402 - val_loss: 0.3629 - val_accuracy: 0.8447\n",
            "Epoch 1402/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3693 - accuracy: 0.8400 - val_loss: 0.3625 - val_accuracy: 0.8448\n",
            "Epoch 1403/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3702 - accuracy: 0.8401 - val_loss: 0.3619 - val_accuracy: 0.8453\n",
            "Epoch 1404/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3703 - accuracy: 0.8412 - val_loss: 0.3633 - val_accuracy: 0.8453\n",
            "Epoch 1405/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3688 - accuracy: 0.8423 - val_loss: 0.3621 - val_accuracy: 0.8457\n",
            "Epoch 1406/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3722 - accuracy: 0.8395 - val_loss: 0.3621 - val_accuracy: 0.8448\n",
            "Epoch 1407/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3680 - accuracy: 0.8410 - val_loss: 0.3646 - val_accuracy: 0.8433\n",
            "Epoch 1408/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3675 - accuracy: 0.8429 - val_loss: 0.3620 - val_accuracy: 0.8447\n",
            "Epoch 1409/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3703 - accuracy: 0.8394 - val_loss: 0.3625 - val_accuracy: 0.8452\n",
            "Epoch 1410/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3689 - accuracy: 0.8415 - val_loss: 0.3642 - val_accuracy: 0.8435\n",
            "Epoch 1411/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3701 - accuracy: 0.8405 - val_loss: 0.3626 - val_accuracy: 0.8445\n",
            "Epoch 1412/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3677 - accuracy: 0.8432 - val_loss: 0.3637 - val_accuracy: 0.8456\n",
            "Epoch 1413/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3665 - accuracy: 0.8422 - val_loss: 0.3641 - val_accuracy: 0.8456\n",
            "Epoch 1414/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3712 - accuracy: 0.8418 - val_loss: 0.3624 - val_accuracy: 0.8452\n",
            "Epoch 1415/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3671 - accuracy: 0.8424 - val_loss: 0.3630 - val_accuracy: 0.8450\n",
            "Epoch 1416/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3692 - accuracy: 0.8417 - val_loss: 0.3634 - val_accuracy: 0.8449\n",
            "Epoch 1417/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3678 - accuracy: 0.8439 - val_loss: 0.3629 - val_accuracy: 0.8454\n",
            "Epoch 1418/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3688 - accuracy: 0.8432 - val_loss: 0.3632 - val_accuracy: 0.8443\n",
            "Epoch 1419/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3734 - accuracy: 0.8412 - val_loss: 0.3636 - val_accuracy: 0.8448\n",
            "Epoch 1420/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3697 - accuracy: 0.8405 - val_loss: 0.3620 - val_accuracy: 0.8446\n",
            "Epoch 1421/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3723 - accuracy: 0.8404 - val_loss: 0.3629 - val_accuracy: 0.8434\n",
            "Epoch 1422/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3689 - accuracy: 0.8415 - val_loss: 0.3625 - val_accuracy: 0.8451\n",
            "Epoch 1423/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3678 - accuracy: 0.8423 - val_loss: 0.3628 - val_accuracy: 0.8449\n",
            "Epoch 1424/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3688 - accuracy: 0.8418 - val_loss: 0.3638 - val_accuracy: 0.8456\n",
            "Epoch 1425/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3751 - accuracy: 0.8390 - val_loss: 0.3623 - val_accuracy: 0.8449\n",
            "Epoch 1426/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3685 - accuracy: 0.8428 - val_loss: 0.3622 - val_accuracy: 0.8440\n",
            "Epoch 1427/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3681 - accuracy: 0.8424 - val_loss: 0.3630 - val_accuracy: 0.8446\n",
            "Epoch 1428/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3714 - accuracy: 0.8398 - val_loss: 0.3631 - val_accuracy: 0.8448\n",
            "Epoch 1429/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3660 - accuracy: 0.8436 - val_loss: 0.3637 - val_accuracy: 0.8446\n",
            "Epoch 1430/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3690 - accuracy: 0.8430 - val_loss: 0.3620 - val_accuracy: 0.8441\n",
            "Epoch 1431/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3751 - accuracy: 0.8391 - val_loss: 0.3621 - val_accuracy: 0.8452\n",
            "Epoch 1432/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3714 - accuracy: 0.8408 - val_loss: 0.3616 - val_accuracy: 0.8460\n",
            "Epoch 1433/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3692 - accuracy: 0.8423 - val_loss: 0.3623 - val_accuracy: 0.8449\n",
            "Epoch 1434/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3718 - accuracy: 0.8406 - val_loss: 0.3631 - val_accuracy: 0.8444\n",
            "Epoch 1435/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3727 - accuracy: 0.8399 - val_loss: 0.3625 - val_accuracy: 0.8463\n",
            "Epoch 1436/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3630 - accuracy: 0.8460 - val_loss: 0.3627 - val_accuracy: 0.8445\n",
            "Epoch 1437/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3701 - accuracy: 0.8414 - val_loss: 0.3626 - val_accuracy: 0.8448\n",
            "Epoch 1438/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3700 - accuracy: 0.8393 - val_loss: 0.3616 - val_accuracy: 0.8454\n",
            "Epoch 1439/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3725 - accuracy: 0.8400 - val_loss: 0.3638 - val_accuracy: 0.8440\n",
            "Epoch 1440/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3703 - accuracy: 0.8407 - val_loss: 0.3611 - val_accuracy: 0.8457\n",
            "Epoch 1441/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3692 - accuracy: 0.8429 - val_loss: 0.3624 - val_accuracy: 0.8441\n",
            "Epoch 1442/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3678 - accuracy: 0.8405 - val_loss: 0.3613 - val_accuracy: 0.8450\n",
            "Epoch 1443/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3715 - accuracy: 0.8405 - val_loss: 0.3617 - val_accuracy: 0.8460\n",
            "Epoch 1444/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3710 - accuracy: 0.8405 - val_loss: 0.3621 - val_accuracy: 0.8455\n",
            "Epoch 1445/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3719 - accuracy: 0.8401 - val_loss: 0.3616 - val_accuracy: 0.8454\n",
            "Epoch 1446/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3698 - accuracy: 0.8411 - val_loss: 0.3620 - val_accuracy: 0.8447\n",
            "Epoch 1447/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3673 - accuracy: 0.8425 - val_loss: 0.3624 - val_accuracy: 0.8454\n",
            "Epoch 1448/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3696 - accuracy: 0.8413 - val_loss: 0.3610 - val_accuracy: 0.8460\n",
            "Epoch 1449/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3706 - accuracy: 0.8431 - val_loss: 0.3609 - val_accuracy: 0.8454\n",
            "Epoch 1450/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3702 - accuracy: 0.8416 - val_loss: 0.3620 - val_accuracy: 0.8451\n",
            "Epoch 1451/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3703 - accuracy: 0.8401 - val_loss: 0.3622 - val_accuracy: 0.8454\n",
            "Epoch 1452/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3734 - accuracy: 0.8388 - val_loss: 0.3613 - val_accuracy: 0.8451\n",
            "Epoch 1453/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3696 - accuracy: 0.8422 - val_loss: 0.3631 - val_accuracy: 0.8447\n",
            "Epoch 1454/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3707 - accuracy: 0.8413 - val_loss: 0.3646 - val_accuracy: 0.8465\n",
            "Epoch 1455/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3688 - accuracy: 0.8430 - val_loss: 0.3612 - val_accuracy: 0.8461\n",
            "Epoch 1456/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3680 - accuracy: 0.8416 - val_loss: 0.3627 - val_accuracy: 0.8442\n",
            "Epoch 1457/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3694 - accuracy: 0.8421 - val_loss: 0.3619 - val_accuracy: 0.8452\n",
            "Epoch 1458/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3652 - accuracy: 0.8432 - val_loss: 0.3623 - val_accuracy: 0.8437\n",
            "Epoch 1459/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3676 - accuracy: 0.8426 - val_loss: 0.3624 - val_accuracy: 0.8454\n",
            "Epoch 1460/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3693 - accuracy: 0.8432 - val_loss: 0.3626 - val_accuracy: 0.8443\n",
            "Epoch 1461/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3697 - accuracy: 0.8421 - val_loss: 0.3612 - val_accuracy: 0.8445\n",
            "Epoch 1462/1500\n",
            "2532/2532 [==============================] - 8s 3ms/step - loss: 0.3704 - accuracy: 0.8405 - val_loss: 0.3610 - val_accuracy: 0.8464\n",
            "Epoch 1463/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3694 - accuracy: 0.8427 - val_loss: 0.3619 - val_accuracy: 0.8453\n",
            "Epoch 1464/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3682 - accuracy: 0.8440 - val_loss: 0.3624 - val_accuracy: 0.8450\n",
            "Epoch 1465/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3692 - accuracy: 0.8403 - val_loss: 0.3626 - val_accuracy: 0.8446\n",
            "Epoch 1466/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3665 - accuracy: 0.8437 - val_loss: 0.3626 - val_accuracy: 0.8457\n",
            "Epoch 1467/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3704 - accuracy: 0.8414 - val_loss: 0.3613 - val_accuracy: 0.8457\n",
            "Epoch 1468/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3696 - accuracy: 0.8422 - val_loss: 0.3623 - val_accuracy: 0.8460\n",
            "Epoch 1469/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3662 - accuracy: 0.8423 - val_loss: 0.3616 - val_accuracy: 0.8460\n",
            "Epoch 1470/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3687 - accuracy: 0.8425 - val_loss: 0.3605 - val_accuracy: 0.8464\n",
            "Epoch 1471/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3687 - accuracy: 0.8406 - val_loss: 0.3625 - val_accuracy: 0.8456\n",
            "Epoch 1472/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3696 - accuracy: 0.8414 - val_loss: 0.3617 - val_accuracy: 0.8457\n",
            "Epoch 1473/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3688 - accuracy: 0.8424 - val_loss: 0.3613 - val_accuracy: 0.8453\n",
            "Epoch 1474/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3720 - accuracy: 0.8410 - val_loss: 0.3626 - val_accuracy: 0.8446\n",
            "Epoch 1475/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3699 - accuracy: 0.8399 - val_loss: 0.3608 - val_accuracy: 0.8445\n",
            "Epoch 1476/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3696 - accuracy: 0.8425 - val_loss: 0.3609 - val_accuracy: 0.8453\n",
            "Epoch 1477/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3688 - accuracy: 0.8410 - val_loss: 0.3628 - val_accuracy: 0.8446\n",
            "Epoch 1478/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3664 - accuracy: 0.8421 - val_loss: 0.3613 - val_accuracy: 0.8455\n",
            "Epoch 1479/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3660 - accuracy: 0.8443 - val_loss: 0.3616 - val_accuracy: 0.8465\n",
            "Epoch 1480/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3685 - accuracy: 0.8416 - val_loss: 0.3621 - val_accuracy: 0.8453\n",
            "Epoch 1481/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3700 - accuracy: 0.8411 - val_loss: 0.3609 - val_accuracy: 0.8464\n",
            "Epoch 1482/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3706 - accuracy: 0.8402 - val_loss: 0.3641 - val_accuracy: 0.8442\n",
            "Epoch 1483/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3723 - accuracy: 0.8397 - val_loss: 0.3608 - val_accuracy: 0.8462\n",
            "Epoch 1484/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3677 - accuracy: 0.8433 - val_loss: 0.3609 - val_accuracy: 0.8456\n",
            "Epoch 1485/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3689 - accuracy: 0.8421 - val_loss: 0.3617 - val_accuracy: 0.8453\n",
            "Epoch 1486/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3667 - accuracy: 0.8434 - val_loss: 0.3639 - val_accuracy: 0.8440\n",
            "Epoch 1487/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3672 - accuracy: 0.8417 - val_loss: 0.3619 - val_accuracy: 0.8458\n",
            "Epoch 1488/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3674 - accuracy: 0.8429 - val_loss: 0.3611 - val_accuracy: 0.8459\n",
            "Epoch 1489/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3680 - accuracy: 0.8423 - val_loss: 0.3616 - val_accuracy: 0.8454\n",
            "Epoch 1490/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3699 - accuracy: 0.8407 - val_loss: 0.3603 - val_accuracy: 0.8463\n",
            "Epoch 1491/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3669 - accuracy: 0.8443 - val_loss: 0.3629 - val_accuracy: 0.8446\n",
            "Epoch 1492/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3701 - accuracy: 0.8405 - val_loss: 0.3609 - val_accuracy: 0.8457\n",
            "Epoch 1493/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3742 - accuracy: 0.8397 - val_loss: 0.3618 - val_accuracy: 0.8458\n",
            "Epoch 1494/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3667 - accuracy: 0.8445 - val_loss: 0.3624 - val_accuracy: 0.8451\n",
            "Epoch 1495/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3727 - accuracy: 0.8411 - val_loss: 0.3605 - val_accuracy: 0.8460\n",
            "Epoch 1496/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3696 - accuracy: 0.8417 - val_loss: 0.3610 - val_accuracy: 0.8458\n",
            "Epoch 1497/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3708 - accuracy: 0.8413 - val_loss: 0.3612 - val_accuracy: 0.8452\n",
            "Epoch 1498/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3681 - accuracy: 0.8421 - val_loss: 0.3619 - val_accuracy: 0.8447\n",
            "Epoch 1499/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3699 - accuracy: 0.8419 - val_loss: 0.3620 - val_accuracy: 0.8451\n",
            "Epoch 1500/1500\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3705 - accuracy: 0.8418 - val_loss: 0.3613 - val_accuracy: 0.8457\n",
            "Fold 1, 1500 epochs, 9397 sec\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Li3-YuuU8-gs"
      },
      "source": [
        "## Show Results of MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3HL6lwW9A8j"
      },
      "source": [
        "def show_test_AUC(model, title, X, y):\n",
        "    \"\"\"\n",
        "    From Miller's MLP_GenCode_1??.\n",
        "    \"\"\"\n",
        "    ns_probs = [0 for _ in range(len(y))]\n",
        "    bm_probs = model.predict(X)\n",
        "    ns_auc = roc_auc_score(y, ns_probs)\n",
        "    bm_auc = roc_auc_score(y, bm_probs)\n",
        "    ns_fpr, ns_tpr, _ = roc_curve(y, ns_probs)\n",
        "    bm_fpr, bm_tpr, _ = roc_curve(y, bm_probs)\n",
        "    plt.plot(ns_fpr, ns_tpr, linestyle='--', label='Guess, auc=%.4f'%ns_auc)\n",
        "    plt.plot(bm_fpr, bm_tpr, marker='.', label='Model, auc=%.4f'%bm_auc)\n",
        "    plt.title(title + ' ROC')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    print(\"%s: %.2f%%\" %('AUC',bm_auc*100.0))\n",
        "    \n",
        "def show_test_accuracy(model,X,y):\n",
        "    \"\"\"\n",
        "    From Miller's MLP_GenCode_1??.\n",
        "    \"\"\"\n",
        "    scores = model.evaluate(X, y, verbose=0)\n",
        "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "EeWFq22L9N6G",
        "outputId": "9e52332d-c2b2-4206-b8ba-4ac2b1e99642"
      },
      "source": [
        "print(\"Accuracy on training data.\")\n",
        "print(\"Prepare...\")\n",
        "X, y = prepare_x_and_y(pc_train, nc_train)\n",
        "print(\"Extract K-mer features...\")\n",
        "X = seqs_to_kmer_freqs(X, MAX_K)\n",
        "print(\"Plot...\")\n",
        "show_test_AUC(last_model, 'Train', X, y)\n",
        "show_test_accuracy(last_model, X, y)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training data.\n",
            "Prepare...\n",
            "Extract K-mer features...\n",
            "Plot...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "AUC: 92.38%\n",
            "accuracy: 85.15%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "LQY5Hze-9hl9",
        "outputId": "2565ac2b-3058-4bbf-bf35-6c70709047d3"
      },
      "source": [
        "print(\"Accuracy on test data.\")\n",
        "print(\"Prepare...\")\n",
        "X, y = prepare_x_and_y(pc_test, nc_test)\n",
        "print(\"Extract K-mer features...\")\n",
        "X = seqs_to_kmer_freqs(X, MAX_K)\n",
        "print(\"Plot...\")\n",
        "show_test_AUC(last_model, 'Test', X, y)\n",
        "show_test_accuracy(last_model, X, y)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on test data.\n",
            "Prepare...\n",
            "Extract K-mer features...\n",
            "Plot...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "AUC: 93.30%\n",
            "accuracy: 86.62%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}