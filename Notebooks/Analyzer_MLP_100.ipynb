{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QxjDXgzOuzm9"
   },
   "source": [
    "# Analyzer\n",
    "\n",
    "Statistically, visually, and through machine learning compare mRNA and lncRNA sequences from GENCODE v38.\n",
    "\n",
    "Assume the user downloaded files from GENCODE v38 [FTP](http://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_38/)\n",
    "to a subdirectory called data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CWH1hul6uKub"
   },
   "source": [
    "## Import Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cMB8T39CuJ2Y",
    "outputId": "55561bdb-5ed3-45b2-cd2a-5a467bbf1ea4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoLab not working. On my PC, use relative paths.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas as pd\n",
    "import gzip\n",
    "from scipy.stats import chisquare, kstest\n",
    "import sys\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Embedding,Dropout\n",
    "from keras.layers import Flatten,TimeDistributed\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    IN_COLAB = True\n",
    "    print(\"On Google CoLab, mount cloud-local file, get our code from GitHub.\")\n",
    "    PATH='/content/drive/'\n",
    "    #drive.mount(PATH,force_remount=True)  # hardly ever need this\n",
    "    drive.mount(PATH)    # Google will require login credentials\n",
    "    DATAPATH=PATH+'My Drive/data/'  # must end in \"/\"\n",
    "    import requests\n",
    "    s = requests.get('https://raw.githubusercontent.com/ShepherdCode/Soars2021/master/SimTools/RNA_describe.py')\n",
    "    with open('RNA_describe.py', 'w') as f:\n",
    "      f.write(s.text)  # writes to cloud local, delete the file later?\n",
    "    s = requests.get('https://raw.githubusercontent.com/ShepherdCode/Soars2021/master/SimTools/GenCodeTools.py')\n",
    "    with open ('GenCodeTools.py', 'w') as f:\n",
    "      f.write(s.text)\n",
    "    s = requests.get('https://raw.githubusercontent.com/ShepherdCode/Soars2021/master/SimTools/plot_generator.py')\n",
    "    with open('plot_generator.py', 'w') as f:\n",
    "      f.write(s.text)\n",
    "    s = requests.get('https://raw.githubusercontent.com/ShepherdCode/Soars2021/master/SimTools/KmerTools.py')\n",
    "    with open('KmerTools.py', 'w') as f:\n",
    "      f.write(s.text)  \n",
    "    from KmerTools import KmerTools\n",
    "    from RNA_describe import *\n",
    "    from GenCodeTools import *\n",
    "    from plot_generator import *\n",
    "except:\n",
    "    print(\"CoLab not working. On my PC, use relative paths.\")\n",
    "    IN_COLAB = False\n",
    "    DATAPATH='data/'  # must end in \"/\"\n",
    "    sys.path.append(\"..\") # append parent dir in order to use sibling dirs\n",
    "    from SimTools.RNA_describe import *\n",
    "    from SimTools.GenCodeTools import *\n",
    "    from SimTools.plot_generator import *\n",
    "    from SimTools.KmerTools import KmerTools\n",
    "\n",
    "MODELPATH=\"BestModel\"  # saved on cloud instance and lost after logout\n",
    "#MODELPATH=DATAPATH+MODELPATH  # saved on Google Drive but requires login\n",
    "\n",
    "if not assert_imported_RNA_describe():\n",
    "    print(\"ERROR: Cannot use RNA_describe.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T8RNNlZGsZN5"
   },
   "source": [
    "## Load GENCODE Data\n",
    "Loads GENCODE v38 data.\n",
    "\n",
    "Filters out mRNA sequences based on UTR check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "37JnfHgWt_-U",
    "outputId": "0f5e3a06-8f89-49aa-887b-394378e206cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PC seqs loaded: 70825\n",
      "NC seqs loaded: 48752\n"
     ]
    }
   ],
   "source": [
    "PC_FILENAME='gencode.v38.pc_transcripts.fa.gz'\n",
    "NC_FILENAME='gencode.v38.lncRNA_transcripts.fa.gz'\n",
    "PC_FULLPATH=DATAPATH+PC_FILENAME\n",
    "NC_FULLPATH=DATAPATH+NC_FILENAME\n",
    "loader=GenCodeLoader()\n",
    "loader.set_label(1)\n",
    "loader.set_check_list(None) \n",
    "loader.set_check_utr(True)\n",
    "pcdf=loader.load_file(PC_FULLPATH)\n",
    "print(\"PC seqs loaded:\",len(pcdf))\n",
    "loader.set_label(0)\n",
    "loader.set_check_list(None)\n",
    "loader.set_check_utr(False)\n",
    "ncdf=loader.load_file(NC_FULLPATH)\n",
    "print(\"NC seqs loaded:\",len(ncdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J0y1XAPLvr_G"
   },
   "source": [
    "## Process Sequences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "si3kGF7kTZ3M"
   },
   "source": [
    "Generate Sample of GENCODE Data Set\n",
    "\n",
    "Apply Length Constraints\n",
    "\n",
    "Validate Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "6V7WMCLN3l1q"
   },
   "outputs": [],
   "source": [
    "APPLY_SUBSET = True             #Option to subset the data\n",
    "MINIMUM_SEQUENCE_LENGTH = 200   #Minimum exclusive length to filter out sequences by\n",
    "MAXIMUM_SEQUENCE_LENGTH = 4000  #Maximum inclusive length to filter out sequences by\n",
    "SAMPLE_FRACTION = 1             #What fraction of the GenCode data set to take a sample of\n",
    "REPRODUCABILITY_SEED = 314159   #Use to reproduce random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ANtZknso53FT",
    "outputId": "6829fcbc-fd8a-4bce-9893-1f2ad73bd143"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PC sample size: 70825\n",
      "NC sample size: 48752\n"
     ]
    }
   ],
   "source": [
    "if APPLY_SUBSET:\n",
    "    pcdf = pcdf.sample(frac=SAMPLE_FRACTION, random_state=REPRODUCABILITY_SEED)\n",
    "    ncdf = ncdf.sample(frac=SAMPLE_FRACTION, random_state=REPRODUCABILITY_SEED)\n",
    "\n",
    "    print('PC sample size:', len(pcdf))\n",
    "    print('NC sample size:', len(ncdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xe5boK2NTWH1"
   },
   "source": [
    "Apply Length Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7ga4K3Aw4sJd"
   },
   "outputs": [],
   "source": [
    "def subset_list_by_len_bounds(input_list, min_len, max_len):\n",
    "  return list(filter(lambda x: len(x) > min_len and len(x) <= max_len, input_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D7pejW0g1lnR",
    "outputId": "f77ea024-2c15-49aa-d8bc-9801c768ce34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PC seqs in length range (200 - 4000): 55381\n",
      "NC seqs in length range (200 - 4000): 46912\n"
     ]
    }
   ],
   "source": [
    "pc_sequences = pcdf['sequence'].tolist()\n",
    "nc_sequences = ncdf['sequence'].tolist()\n",
    "\n",
    "if APPLY_SUBSET:\n",
    "    pc_sequences = subset_list_by_len_bounds(pc_sequences, MINIMUM_SEQUENCE_LENGTH, MAXIMUM_SEQUENCE_LENGTH)\n",
    "    nc_sequences = subset_list_by_len_bounds(nc_sequences, MINIMUM_SEQUENCE_LENGTH, MAXIMUM_SEQUENCE_LENGTH)\n",
    "\n",
    "    print('PC seqs in length range','('+str(MINIMUM_SEQUENCE_LENGTH),'-',str(MAXIMUM_SEQUENCE_LENGTH)+'):', len(pc_sequences))\n",
    "    print('NC seqs in length range','('+str(MINIMUM_SEQUENCE_LENGTH),'-',str(MAXIMUM_SEQUENCE_LENGTH)+'):', len(nc_sequences))\n",
    "\n",
    "#Garbage collection\n",
    "pcdf = None\n",
    "ncdf = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BlFZ2BHDS_kJ"
   },
   "source": [
    "Validate Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FYBUZyfxSRZs",
    "outputId": "bd72bca4-237d-4544-de17-cf7fca584d7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid PC seqs: 55381\n",
      "Valid NC seqs: 46911\n"
     ]
    }
   ],
   "source": [
    "def valid_sequence(seq):\n",
    "    \"\"\"\n",
    "    Checks if the given sequences if valid.\n",
    "    \"\"\"\n",
    "    for chr in seq:\n",
    "        if not (chr == 'A' or chr == 'C' or chr == 'G' or chr == 'T'):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def validate_sequences(sequences):\n",
    "    \"\"\"\n",
    "    Validate the given list of sequences\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    while i < len(sequences):\n",
    "        if valid_sequence(sequences[i]):\n",
    "            i += 1\n",
    "        else:\n",
    "            sequences.remove(sequences[i])\n",
    "\n",
    "validate_sequences(pc_sequences)\n",
    "validate_sequences(nc_sequences)\n",
    "\n",
    "print('Valid PC seqs:', len(pc_sequences))\n",
    "print('Valid NC seqs:', len(nc_sequences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IVWspW8e4v2b"
   },
   "source": [
    "## Set Up MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "rNxOORWM41Xi"
   },
   "outputs": [],
   "source": [
    "RATIO_TRAIN_TO_TEST = 0.99\n",
    "INPUT_SHAPE = (None, 4**3 + 4**2 + 4**1)\n",
    "MAX_K = 3\n",
    "NEURONS = 16\n",
    "DROP_RATE = 0.1\n",
    "EPOCHS = 5\n",
    "SPLITS = 5\n",
    "FOLDS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nf_MTH3a63ZA"
   },
   "source": [
    "Define what is training data and what is testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D2mKPv1B5oIR",
    "outputId": "105ceec0-fc18-4c9e-e90c-be9c21e20c4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PC TRAIN: 54827\n",
      "NC TRAIN 46441\n",
      "PC TEST: 554\n",
      "NC TEST: 470\n"
     ]
    }
   ],
   "source": [
    "NUM_PC = len(pc_sequences)\n",
    "NUM_PC_TRAIN = int(NUM_PC * RATIO_TRAIN_TO_TEST)\n",
    "NUM_NC = len(nc_sequences)\n",
    "NUM_NC_TRAIN = int(NUM_NC * RATIO_TRAIN_TO_TEST)\n",
    "\n",
    "pc_train = pc_sequences[:NUM_PC_TRAIN]\n",
    "pc_test = pc_sequences[NUM_PC_TRAIN:]\n",
    "nc_train = nc_sequences[:NUM_NC_TRAIN]\n",
    "nc_test = nc_sequences[NUM_NC_TRAIN:]\n",
    "\n",
    "print('PC TRAIN:', len(pc_train))\n",
    "print('NC TRAIN', len(nc_train))\n",
    "print('PC TEST:', len(pc_test))\n",
    "print('NC TEST:', len(nc_test))\n",
    "\n",
    "#Garbage Collection (this makes re-running the MLP a pain)\n",
    "#pc_sequences = None\n",
    "#nc_sequences = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5DOlou8Z7XU_"
   },
   "source": [
    "Prepare the Inputs and the Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "5MVxtNEc69NO"
   },
   "outputs": [],
   "source": [
    "def prepare_x_and_y(seqs1, seqs0):\n",
    "    \"\"\"\n",
    "    From Miller's MLP_GenCode_1??.\n",
    "    \"\"\"\n",
    "    len1=len(seqs1)\n",
    "    len0=len(seqs0)\n",
    "    total=len1+len0\n",
    "    L1=np.ones(len1,dtype=np.int8)\n",
    "    L0=np.zeros(len0,dtype=np.int8)\n",
    "    S1 = np.asarray(seqs1)\n",
    "    S0 = np.asarray(seqs0)\n",
    "    all_labels = np.concatenate((L1,L0))\n",
    "    all_seqs = np.concatenate((S1,S0))  \n",
    "    for i in range(0,len0):\n",
    "        all_labels[i*2] = L0[i]\n",
    "        all_seqs[i*2] = S0[i]\n",
    "        all_labels[i*2+1] = L1[i]\n",
    "        all_seqs[i*2+1] = S1[i]\n",
    "    return all_seqs,all_labels\n",
    "Xseq, y = prepare_x_and_y(pc_train, nc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g46xCFPZ7xqF"
   },
   "outputs": [],
   "source": [
    "def seqs_to_kmer_freqs(seqs, max_K):\n",
    "    \"\"\"\n",
    "    From Miller's MLP_GenCode_1??.\n",
    "    \"\"\"\n",
    "    tool = KmerTools()  # from SimTools\n",
    "    collection = []\n",
    "    for seq in seqs:\n",
    "        counts = tool.make_dict_upto_K(max_K)\n",
    "        # Last param should be True when using Harvester.\n",
    "        counts = tool.update_count_one_K(counts, max_K, seq, True)\n",
    "        # Given counts for K=3, Harvester fills in counts for K=1,2.\n",
    "        counts = tool.harvest_counts_from_K(counts, max_K)\n",
    "        fdict = tool.count_to_frequency(counts, max_K)\n",
    "        freqs = list(fdict.values())\n",
    "        collection.append(freqs)\n",
    "    return np.asarray(collection)\n",
    "\n",
    "Xfrq = seqs_to_kmer_freqs(Xseq, MAX_K)\n",
    "\n",
    "#Garbage Collection\n",
    "Xseq = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6TS9xAqP8ClN"
   },
   "source": [
    "## Make and Train MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SFI-Jwgc8Gv4",
    "outputId": "87d155f1-315f-4e88-8be7-b8ed5266fc72"
   },
   "outputs": [],
   "source": [
    "def make_DNN():\n",
    "    \"\"\"\n",
    "    From Miller's MLP_GenCode_1??.\n",
    "    \"\"\"\n",
    "    dt=np.float32\n",
    "    print(\"make_DNN\")\n",
    "    print(\"input shape:\",INPUT_SHAPE)\n",
    "    dnn = Sequential()\n",
    "\n",
    "    dnn.add(Dense(NEURONS, activation=\"sigmoid\", dtype=dt))  # relu doesn't work as well\n",
    "    dnn.add(Dropout(DROP_RATE))\n",
    "\n",
    "    dnn.add(Dense(NEURONS, activation=\"sigmoid\", dtype=dt)) \n",
    "    dnn.add(Dropout(DROP_RATE))\n",
    "\n",
    "    dnn.add(Dense(1, activation=\"sigmoid\", dtype=dt))  \n",
    "\n",
    "    dnn.compile(optimizer='adam',    # adadelta doesn't work as well\n",
    "        loss=BinaryCrossentropy(from_logits=False),\n",
    "        metrics=['accuracy'])   # add to default metrics=loss\n",
    "    dnn.build(input_shape=INPUT_SHAPE) \n",
    "    return dnn\n",
    "model = make_DNN()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qIEUYjE18dQT"
   },
   "outputs": [],
   "source": [
    "def do_cross_validation(X,y):\n",
    "    \"\"\"\n",
    "    From Miller's MLP_GenCode_1??.\n",
    "    \"\"\"\n",
    "    cv_scores = []\n",
    "    fold=0\n",
    "    mycallbacks = [ModelCheckpoint(\n",
    "        filepath=MODELPATH, save_best_only=True, \n",
    "        monitor='val_accuracy', mode='max')]   \n",
    "    # When shuffle=True, the valid indices are a random subset.\n",
    "    splitter = KFold(n_splits=SPLITS, shuffle=True) \n",
    "    model = None\n",
    "    for train_index, valid_index in splitter.split(X):\n",
    "        if fold < FOLDS:\n",
    "            fold += 1\n",
    "            X_train=X[train_index] # inputs for training\n",
    "            y_train=y[train_index] # labels for training\n",
    "            X_valid=X[valid_index] # inputs for validation\n",
    "            y_valid=y[valid_index] # labels for validation\n",
    "            print(\"MODEL\")\n",
    "            # Call constructor on each CV. Else, continually improves the same model.\n",
    "            model = model = make_DNN()\n",
    "            print(\"FIT\")  # model.fit() implements learning\n",
    "            start_time=time.time()\n",
    "            history=model.fit(X_train, y_train, \n",
    "                epochs=EPOCHS, \n",
    "                verbose=1,  # ascii art while learning\n",
    "                callbacks=mycallbacks,   # called at end of each epoch\n",
    "                validation_data=(X_valid,y_valid))\n",
    "            end_time=time.time()\n",
    "            elapsed_time=(end_time-start_time)                        \n",
    "            print(\"Fold %d, %d epochs, %d sec\"%(fold,EPOCHS,elapsed_time))\n",
    "            # print(history.history.keys())  # all these keys will be shown in figure\n",
    "            pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "            plt.grid(True)\n",
    "            plt.gca().set_ylim(0,1) # any losses > 1 will be off the scale\n",
    "            plt.show()\n",
    "    return model  # parameters at end of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "6on9fVhr8ux_",
    "outputId": "20f2aa12-f520-4fa3-d1c6-db5442a5c385"
   },
   "outputs": [],
   "source": [
    "last_model = do_cross_validation(Xfrq, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Li3-YuuU8-gs"
   },
   "source": [
    "## Show Results of MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s3HL6lwW9A8j"
   },
   "outputs": [],
   "source": [
    "def show_test_AUC(model, title, X, y):\n",
    "    \"\"\"\n",
    "    From Miller's MLP_GenCode_1??.\n",
    "    \"\"\"\n",
    "    ns_probs = [0 for _ in range(len(y))]\n",
    "    bm_probs = model.predict(X)\n",
    "    ns_auc = roc_auc_score(y, ns_probs)\n",
    "    bm_auc = roc_auc_score(y, bm_probs)\n",
    "    ns_fpr, ns_tpr, _ = roc_curve(y, ns_probs)\n",
    "    bm_fpr, bm_tpr, _ = roc_curve(y, bm_probs)\n",
    "    plt.plot(ns_fpr, ns_tpr, linestyle='--', label='Guess, auc=%.4f'%ns_auc)\n",
    "    plt.plot(bm_fpr, bm_tpr, marker='.', label='Model, auc=%.4f'%bm_auc)\n",
    "    plt.title(title + ' ROC')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print(\"%s: %.2f%%\" %('AUC',bm_auc*100.0))\n",
    "    \n",
    "def show_test_accuracy(model,X,y):\n",
    "    \"\"\"\n",
    "    From Miller's MLP_GenCode_1??.\n",
    "    \"\"\"\n",
    "    scores = model.evaluate(X, y, verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 405
    },
    "id": "EeWFq22L9N6G",
    "outputId": "9e52332d-c2b2-4206-b8ba-4ac2b1e99642"
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy on training data.\")\n",
    "print(\"Prepare...\")\n",
    "X, y = prepare_x_and_y(pc_train, nc_train)\n",
    "print(\"Extract K-mer features...\")\n",
    "X = seqs_to_kmer_freqs(X, MAX_K)\n",
    "print(\"Plot...\")\n",
    "show_test_AUC(last_model, 'Train', X, y)\n",
    "show_test_accuracy(last_model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 405
    },
    "id": "LQY5Hze-9hl9",
    "outputId": "2565ac2b-3058-4bbf-bf35-6c70709047d3"
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy on test data.\")\n",
    "print(\"Prepare...\")\n",
    "X, y = prepare_x_and_y(pc_test, nc_test)\n",
    "print(\"Extract K-mer features...\")\n",
    "X = seqs_to_kmer_freqs(X, MAX_K)\n",
    "print(\"Plot...\")\n",
    "show_test_AUC(last_model, 'Test', X, y)\n",
    "show_test_accuracy(last_model, X, y)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Analyzer_MLP_100.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
