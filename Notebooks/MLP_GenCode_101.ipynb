{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "MLP_GenCode_101.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojm_6E9f9Kcf"
      },
      "source": [
        "# MLP GenCode \n",
        "Wen et al 2019 used DNN to distinguish GenCode mRNA/lncRNA.\n",
        "Based on K-mer frequencies, K={1,2,3}, they reported 99% accuracy.\n",
        "Their CNN used 2 Conv2D layers of 32 filters of width 3x3, max pool 2x2, 25% drop, dense 128.\n",
        "Can we reproduce that with MLP layers instead of CNN?\n",
        "Extract features as list of K-mer frequencies for K={1,2,3}."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmPF4h_YI_sT",
        "outputId": "043eb63e-9bd6-4b55-f86f-5487c1d2dcc4"
      },
      "source": [
        "import time\n",
        "def show_time():\n",
        "    t = time.time()\n",
        "    print(time.strftime('%Y-%m-%d %H:%M:%S %Z', time.localtime(t)))\n",
        "show_time()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-10 17:30:17 UTC\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEbXt5N4I_sc"
      },
      "source": [
        "PC_TRAINS=10000\n",
        "NC_TRAINS=10000\n",
        "PC_TESTS=5000\n",
        "NC_TESTS=5000   # Wen et al 2019 used 8000 and 2000 of each class\n",
        "PC_LENS=(200,4000)\n",
        "NC_LENS=(200,4000)    # Wen et al 2019 used 250-3500 for lncRNA only\n",
        "MAX_K = 3\n",
        "INPUT_SHAPE=(None,84)  # 4^3 + 4^2 + 4^1\n",
        "NEURONS=128\n",
        "DROP_RATE=0.2\n",
        "EPOCHS=100\n",
        "SPLITS=5\n",
        "FOLDS=5   # make this 5 for serious testing"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQY7aTj29Kch"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Embedding,Dropout\n",
        "from keras.layers import Flatten,TimeDistributed\n",
        "from keras.losses import BinaryCrossentropy\n",
        "from keras.callbacks import ModelCheckpoint\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUxEB53HI_sk",
        "outputId": "5f3dbaaf-0079-4eca-9b7b-c94f0f9343f5"
      },
      "source": [
        "import sys\n",
        "IN_COLAB = False\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    pass\n",
        "if IN_COLAB:\n",
        "    print(\"On Google CoLab, mount cloud-local file, get our code from GitHub.\")\n",
        "    PATH='/content/drive/'\n",
        "    #drive.mount(PATH,force_remount=True)  # hardly ever need this\n",
        "    drive.mount(PATH)    # Google will require login credentials\n",
        "    DATAPATH=PATH+'My Drive/data/'  # must end in \"/\"\n",
        "    import requests\n",
        "    r = requests.get('https://raw.githubusercontent.com/ShepherdCode/Soars2021/master/SimTools/GenCodeTools.py')\n",
        "    with open('GenCodeTools.py', 'w') as f:\n",
        "        f.write(r.text)  \n",
        "    from GenCodeTools import GenCodeLoader\n",
        "    r = requests.get('https://raw.githubusercontent.com/ShepherdCode/Soars2021/master/SimTools/KmerTools.py')\n",
        "    with open('KmerTools.py', 'w') as f:\n",
        "        f.write(r.text)  \n",
        "    from KmerTools import KmerTools\n",
        "else:\n",
        "        print(\"CoLab not working. On my PC, use relative paths.\")\n",
        "        DATAPATH='data/'  # must end in \"/\"\n",
        "        sys.path.append(\"..\") # append parent dir in order to use sibling dirs\n",
        "        from SimTools.GenCodeTools import GenCodeLoader\n",
        "        from SimTools.KmerTools import KmerTools\n",
        "MODELPATH=\"BestModel\"  # saved on cloud instance and lost after logout\n",
        "#MODELPATH=DATAPATH+MODELPATH  # saved on Google Drive but requires login"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "On Google CoLab, mount cloud-local file, get our code from GitHub.\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8buAhZRfI_sp"
      },
      "source": [
        "## Data Load\n",
        "Restrict mRNA to those transcripts with a recognized ORF."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypn0lhiqI_sq"
      },
      "source": [
        "PC_FILENAME='gencode.v38.pc_transcripts.fa.gz'\n",
        "NC_FILENAME='gencode.v38.lncRNA_transcripts.fa.gz'\n",
        "PC_FULLPATH=DATAPATH+PC_FILENAME\n",
        "NC_FULLPATH=DATAPATH+NC_FILENAME"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTz0pkFlI_sr",
        "outputId": "a800f8f0-855d-4180-dc92-b3d7359d7caf"
      },
      "source": [
        "# Full GenCode ver 38 human is 106143 pc + 48752 nc and loads in 7 sec.\n",
        "# Expect fewer transcripts if special filtering is used.\n",
        "loader=GenCodeLoader()\n",
        "loader.set_label(1)\n",
        "loader.set_check_utr(True)\n",
        "pcdf=loader.load_file(PC_FULLPATH)\n",
        "print(\"PC seqs loaded:\",len(pcdf))\n",
        "loader.set_label(0)\n",
        "loader.set_check_utr(False)\n",
        "ncdf=loader.load_file(NC_FULLPATH)\n",
        "print(\"NC seqs loaded:\",len(ncdf))\n",
        "trivial=False\n",
        "if trivial:\n",
        "  print(\"Trivialize the data...\")\n",
        "  dummy='AAAA'*200\n",
        "  for i in range(0,len(pcdf)):\n",
        "    pcdf['sequence']=dummy\n",
        "  dummy='GGGG'*200\n",
        "  for i in range(0,len(ncdf)):\n",
        "    ncdf['sequence']=dummy\n",
        "show_time()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PC seqs loaded: 70825\n",
            "NC seqs loaded: 48752\n",
            "2021-07-10 17:30:50 UTC\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCNh_FZaI_sv"
      },
      "source": [
        "## Data Prep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkBXTJ__I_sx",
        "outputId": "87bd6d7d-915d-420b-f622-95a2de5aad7b"
      },
      "source": [
        "def dataframe_length_filter(df,low_high):\n",
        "    (low,high)=low_high\n",
        "    # The pandas query language is strange, \n",
        "    # but this is MUCH faster than loop & drop.\n",
        "    return df[ (df['seqlen']>=low) & (df['seqlen']<=high) ]\n",
        "def dataframe_shuffle(df):\n",
        "    # The ignore_index option is new in Pandas 1.3. \n",
        "    # The default (False) replicates the old behavior: shuffle the index too.\n",
        "    # The new option seems more logical th\n",
        "    # After shuffling, df.iloc[0] has index == 0.\n",
        "    # return df.sample(frac=1,ignore_index=True)\n",
        "    return df.sample(frac=1)  # Use this till CoLab upgrades Pandas\n",
        "def dataframe_extract_sequence(df):\n",
        "    return df['sequence'].tolist()\n",
        "\n",
        "pc_all = dataframe_extract_sequence(\n",
        "    dataframe_shuffle(\n",
        "    dataframe_length_filter(pcdf,PC_LENS)))\n",
        "nc_all = dataframe_extract_sequence(\n",
        "    dataframe_shuffle(\n",
        "    dataframe_length_filter(ncdf,NC_LENS)))\n",
        "\n",
        "show_time()\n",
        "print(\"PC seqs pass filter:\",len(pc_all))\n",
        "print(\"NC seqs pass filter:\",len(nc_all))\n",
        "# Garbage collection to reduce RAM footprint\n",
        "pcdf=None\n",
        "ncdf=None"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-10 17:30:50 UTC\n",
            "PC seqs pass filter: 55381\n",
            "NC seqs pass filter: 46919\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V91rP2osI_s1"
      },
      "source": [
        "# Any portion of a shuffled list is a random selection\n",
        "pc_train=pc_all[:PC_TRAINS] \n",
        "nc_train=nc_all[:NC_TRAINS]\n",
        "pc_test=pc_all[PC_TRAINS:PC_TESTS] \n",
        "nc_test=nc_all[NC_TRAINS:PC_TESTS]\n",
        "# Garbage collection\n",
        "pc_all=None\n",
        "nc_all=None"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfyPeInGI_s4",
        "outputId": "7d76cc1d-ce5c-47b7-81cc-26baf93f04ec"
      },
      "source": [
        "def prepare_x_and_y(seqs1,seqs0):\n",
        "    len1=len(seqs1)\n",
        "    len0=len(seqs0)\n",
        "    labels1=np.ones(len1,dtype=np.int8)\n",
        "    labels0=np.zeros(len0,dtype=np.int8)\n",
        "    all_labels = np.concatenate((labels1,labels0))\n",
        "    seqs1 = np.asarray(seqs1)\n",
        "    seqs0 = np.asarray(seqs0)\n",
        "    all_seqs = np.concatenate((seqs1,seqs0),axis=0)\n",
        "    #return all_seqs,all_labels  # test unshuffled\n",
        "    tandem = (all_seqs,all_labels)\n",
        "    X,y = shuffle(tandem) # sklearn.utils.shuffle\n",
        "    return X,y\n",
        "Xseq,y=prepare_x_and_y(pc_train,nc_train)\n",
        "show_time()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-10 17:30:50 UTC\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "LWLixZOfI_s7",
        "outputId": "c0e286b2-5451-4af7-9ba0-8ef28be90bf6"
      },
      "source": [
        "def seqs_to_kmer_freqs(seqs,max_K):\n",
        "    tool = KmerTools()  # from SimTools\n",
        "    empty = tool.make_dict_upto_K(max_K)\n",
        "    collection = []\n",
        "    for seq in seqs:\n",
        "        counts = empty\n",
        "        counts = tool.update_count_one_K(counts,max_K,seq,True)\n",
        "        counts = tool.harvest_counts_from_K(counts,max_K)\n",
        "        fdict = tool.count_to_frequency(counts,max_K)\n",
        "        freqs = list(fdict.values())\n",
        "        collection.append(freqs)\n",
        "    return np.asarray(collection)\n",
        "Xfrq=seqs_to_kmer_freqs(Xseq,MAX_K)\n",
        "show_time()\n",
        "print(\"X shape\",np.shape(Xfrq))\n",
        "print(type(Xfrq),\"of\",type(Xfrq[0]),\"of\",type(Xfrq[0][0]))\n",
        "print(\"y shape\",np.shape(y))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-003f014e6c16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mcollection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mXfrq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseqs_to_kmer_freqs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXseq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMAX_K\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mshow_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X shape\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXfrq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-003f014e6c16>\u001b[0m in \u001b[0;36mseqs_to_kmer_freqs\u001b[0;34m(seqs, max_K)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseqs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_count_one_K\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_K\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mharvest_counts_from_K\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_K\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mfdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_to_frequency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_K\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/KmerTools.py\u001b[0m in \u001b[0;36mupdate_count_one_K\u001b[0;34m(self, counts, K, rna, tail)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mSet\u001b[0m \u001b[0mtail\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m \u001b[0monly\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0musing\u001b[0m \u001b[0mHarvester\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         '''\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrna\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mpadded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrna\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'numpy.int8' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJ4XhrzGI_s-"
      },
      "source": [
        "## Neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5NPW7zKI_tC"
      },
      "source": [
        "def make_DNN():\n",
        "    dt=np.float32\n",
        "    print(\"make_DNN\")\n",
        "    print(\"input shape:\",INPUT_SHAPE)\n",
        "    dnn = Sequential()\n",
        "    dnn.add(Dense(NEURONS,activation=\"sigmoid\",dtype=dt))\n",
        "    dnn.add(Dense(NEURONS,activation=\"sigmoid\",dtype=dt)) \n",
        "    dnn.add(Dense(NEURONS,activation=\"sigmoid\",dtype=dt)) \n",
        "    dnn.add(Dropout(DROP_RATE))\n",
        "    dnn.add(Dense(1,activation=\"sigmoid\",dtype=dt))   \n",
        "    dnn.compile(optimizer='adam',\n",
        "                loss=BinaryCrossentropy(from_logits=False),\n",
        "                metrics=['accuracy'])   # add to default metrics=loss\n",
        "    dnn.build(input_shape=INPUT_SHAPE) \n",
        "    return dnn\n",
        "model = make_DNN()\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2Dr6L9lI_tE"
      },
      "source": [
        "def do_cross_validation(X,y):\n",
        "    cv_scores = []\n",
        "    fold=0\n",
        "    mycallbacks = [ModelCheckpoint(\n",
        "        filepath=MODELPATH, save_best_only=True, \n",
        "        monitor='val_accuracy', mode='max')]   \n",
        "    splitter = KFold(n_splits=SPLITS)  # this does not shuffle\n",
        "    for train_index,valid_index in splitter.split(X):\n",
        "        if fold < FOLDS:\n",
        "            fold += 1\n",
        "            X_train=X[train_index] # inputs for training\n",
        "            y_train=y[train_index] # labels for training\n",
        "            X_valid=X[valid_index] # inputs for validation\n",
        "            y_valid=y[valid_index] # labels for validation\n",
        "            print(\"MODEL\")\n",
        "            # Call constructor on each CV. Else, continually improves the same model.\n",
        "            model = model = make_DNN()\n",
        "            print(\"FIT\")  # model.fit() implements learning\n",
        "            start_time=time.time()\n",
        "            history=model.fit(X_train, y_train, \n",
        "                    epochs=EPOCHS, \n",
        "                    verbose=1,  # ascii art while learning\n",
        "                    callbacks=mycallbacks,   # called at end of each epoch\n",
        "                    validation_data=(X_valid,y_valid))\n",
        "            end_time=time.time()\n",
        "            elapsed_time=(end_time-start_time)                        \n",
        "            print(\"Fold %d, %d epochs, %d sec\"%(fold,EPOCHS,elapsed_time))\n",
        "            # print(history.history.keys())  # all these keys will be shown in figure\n",
        "            pd.DataFrame(history.history).plot(figsize=(8,5))\n",
        "            plt.grid(True)\n",
        "            plt.gca().set_ylim(0,1) # any losses > 1 will be off the scale\n",
        "            plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ey7Q-YWcI_tH"
      },
      "source": [
        "do_cross_validation(Xfrq,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVImN4_0I_tJ"
      },
      "source": [
        "# TO DO: run trained model on (pc_test,nc_test)\n",
        "# and draw the AUC.\n",
        "# Borrow code from other notebooks."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}