{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ConvRecur_109.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0asdcdunj2Tx"
      },
      "source": [
        "# ORF recognition by Convolutional/Recurrent\n",
        "\n",
        "Test CNN+LSTM 16 on simulated RNA of length 64. \n",
        "\n",
        "Use restructured codebase from notebook 105."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "QP1VTRNQj2UO",
        "outputId": "b02dae80-3f26-429a-9b09-5752a4c367cc"
      },
      "source": [
        "import time \n",
        "t = time.time()\n",
        "time.strftime('%Y-%m-%d %H:%M:%S %Z', time.localtime(t))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2021-06-21 18:36:25 UTC'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nhz4GKonj2T_"
      },
      "source": [
        "PC_SEQUENCES=32000   # how many protein-coding sequences\n",
        "NC_SEQUENCES=32000   # how many non-coding sequences\n",
        "PC_TESTS=1000\n",
        "NC_TESTS=1000\n",
        "RNA_LEN=64            # how long is each sequence\n",
        "CDS_LEN=32            # min CDS len to be coding\n",
        "ALPHABET=4          # how many different letters are possible\n",
        "INPUT_SHAPE_2D = (RNA_LEN,ALPHABET,1) # Conv2D needs 3D inputs\n",
        "INPUT_SHAPE = (RNA_LEN,ALPHABET) # Conv1D needs 2D inputs\n",
        "FILTERS = 16   # how many different patterns the model looks for\n",
        "CELLS = 16\n",
        "NEURONS = 16\n",
        "DROP_RATE = 0.4\n",
        "WIDTH = 3   # how wide each pattern is, in bases\n",
        "STRIDE_2D = (1,1)  # For Conv2D how far in each direction\n",
        "STRIDE = 1 # For Conv1D, how far between pattern matches, in bases\n",
        "EPOCHS=100  # how many times to train on all the data\n",
        "SPLITS=3  # SPLITS=3 means train on 2/3 and validate on 1/3 \n",
        "FOLDS=3  # train the model this many times (range 1 to SPLITS)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lr7q90rxj2UE",
        "outputId": "a1a28f0f-b491-47e7-9928-c48bc5f94d1e"
      },
      "source": [
        "import sys\n",
        "IN_COLAB = False\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    pass\n",
        "if IN_COLAB:\n",
        "    print(\"On Google CoLab, mount cloud-local file, get our code from GitHub.\")\n",
        "    PATH='/content/drive/'\n",
        "    #drive.mount(PATH,force_remount=True)  # hardly ever need this\n",
        "    #drive.mount(PATH)    # Google will require login credentials\n",
        "    DATAPATH=PATH+'My Drive/data/'  # must end in \"/\"\n",
        "    import requests\n",
        "    r = requests.get('https://raw.githubusercontent.com/ShepherdCode/Soars2021/master/SimTools/RNA_describe.py')\n",
        "    with open('RNA_describe.py', 'w') as f:\n",
        "        f.write(r.text)  \n",
        "    from RNA_describe import ORF_counter\n",
        "    from RNA_describe import Random_Base_Oracle\n",
        "    r = requests.get('https://raw.githubusercontent.com/ShepherdCode/Soars2021/master/SimTools/RNA_prep.py')\n",
        "    with open('RNA_prep.py', 'w') as f:\n",
        "        f.write(r.text)  \n",
        "    from RNA_prep import prepare_inputs_len_x_alphabet\n",
        "else:\n",
        "        print(\"CoLab not working. On my PC, use relative paths.\")\n",
        "        DATAPATH='data/'  # must end in \"/\"\n",
        "        sys.path.append(\"..\") # append parent dir in order to use sibling dirs\n",
        "        from SimTools.RNA_describe import ORF_counter,Random_Base_Oracle\n",
        "        from SimTools.RNA_prep import prepare_inputs_len_x_alphabet\n",
        "\n",
        "MODELPATH=\"BestModel\"  # saved on cloud instance and lost after logout\n",
        "#MODELPATH=DATAPATH+MODELPATH  # saved on Google Drive but requires login\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "On Google CoLab, mount cloud-local file, get our code from GitHub.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGDXH8Uwj2UM"
      },
      "source": [
        "from os import listdir\n",
        "import csv\n",
        "from zipfile import ZipFile\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats  # mode\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Embedding,Dropout\n",
        "from keras.layers import Conv1D,Conv2D\n",
        "from keras.layers import GRU,LSTM\n",
        "from keras.layers import Flatten,TimeDistributed\n",
        "from keras.layers import MaxPooling1D,MaxPooling2D\n",
        "from keras.losses import BinaryCrossentropy\n",
        "# tf.keras.losses.BinaryCrossentropy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import colors\n",
        "mycmap = colors.ListedColormap(['red','blue'])  # list color for label 0 then 1\n",
        "np.set_printoptions(precision=2)\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUOG_jEvGtOm",
        "outputId": "fd3b3ece-27a3-4978-9d5f-b3e455b7754e"
      },
      "source": [
        "rbo=Random_Base_Oracle(RNA_LEN,True)\n",
        "pc_all,nc_all = rbo.get_partitioned_sequences(CDS_LEN,10) # just testing\n",
        "pc_all,nc_all = rbo.get_partitioned_sequences(CDS_LEN,PC_SEQUENCES+PC_TESTS)\n",
        "print(\"Use\",len(pc_all),\"PC seqs\")\n",
        "print(\"Use\",len(nc_all),\"NC seqs\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "It took 57 trials to reach 10 per class.\n",
            "It took 102578 trials to reach 33000 per class.\n",
            "Use 33000 PC seqs\n",
            "Use 33000 NC seqs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-BmSXi2jUyl",
        "outputId": "f90c6695-fdb4-4b53-9cc3-20f4e99fa536"
      },
      "source": [
        "# Describe the sequences\n",
        "def describe_sequences(list_of_seq):\n",
        "    oc = ORF_counter()\n",
        "    num_seq = len(list_of_seq)\n",
        "    rna_lens = np.zeros(num_seq)\n",
        "    orf_lens = np.zeros(num_seq)\n",
        "    for i in range(0,num_seq):\n",
        "        rna_len = len(list_of_seq[i])\n",
        "        rna_lens[i] = rna_len\n",
        "        oc.set_sequence(list_of_seq[i])\n",
        "        orf_len = oc.get_max_orf_len()\n",
        "        orf_lens[i] = orf_len\n",
        "    print (\"Average RNA length:\",rna_lens.mean())\n",
        "    print (\"Average ORF length:\",orf_lens.mean())\n",
        "    \n",
        "print(\"Simulated sequences prior to adjustment:\")\n",
        "print(\"PC seqs\")\n",
        "describe_sequences(pc_all)\n",
        "print(\"NC seqs\")\n",
        "describe_sequences(nc_all)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Simulated sequences prior to adjustment:\n",
            "PC seqs\n",
            "Average RNA length: 64.0\n",
            "Average ORF length: 38.373636363636365\n",
            "NC seqs\n",
            "Average RNA length: 64.0\n",
            "Average ORF length: 8.183909090909092\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iP1y7-J3jUys"
      },
      "source": [
        "pc_train=pc_all[:PC_SEQUENCES]\n",
        "nc_train=nc_all[:NC_SEQUENCES]\n",
        "pc_test=pc_all[PC_SEQUENCES:]\n",
        "nc_test=nc_all[NC_SEQUENCES:]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIpTrnH6j2US",
        "outputId": "409db1c5-d0c9-4c60-9503-86f9a9b2dbab"
      },
      "source": [
        "# Use code from our SimTools library.\n",
        "X,y = prepare_inputs_len_x_alphabet(pc_train,nc_train,ALPHABET) # shuffles\n",
        "print(\"Data ready.\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data ready.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NvrVU8ij2UU",
        "outputId": "a2e08015-6b4e-4297-e000-fab2aea40cc6"
      },
      "source": [
        "def make_DNN():\n",
        "    print(\"make_DNN\")\n",
        "    print(\"input shape:\",INPUT_SHAPE)\n",
        "    dnn = Sequential()\n",
        "    #dnn.add(Embedding(input_dim=INPUT_SHAPE,output_dim=INPUT_SHAPE)) \n",
        "    dnn.add(Conv1D(filters=FILTERS,kernel_size=WIDTH,strides=STRIDE,padding=\"same\",\n",
        "            input_shape=INPUT_SHAPE))\n",
        "    dnn.add(Conv1D(filters=FILTERS,kernel_size=WIDTH,strides=STRIDE,padding=\"same\"))\n",
        "    dnn.add(MaxPooling1D())\n",
        "    #dnn.add(Conv1D(filters=FILTERS,kernel_size=WIDTH,strides=STRIDE,padding=\"same\"))\n",
        "    #dnn.add(Conv1D(filters=FILTERS,kernel_size=WIDTH,strides=STRIDE,padding=\"same\"))\n",
        "    #dnn.add(MaxPooling1D())\n",
        "    #dnn.add(TimeDistributed(Flatten()))\n",
        "    dnn.add(LSTM(CELLS,return_sequences=True))\n",
        "    dnn.add(LSTM(CELLS,return_sequences=False))\n",
        "    dnn.add(Dense(NEURONS,activation=\"sigmoid\",dtype=np.float32))   \n",
        "    dnn.add(Dropout(DROP_RATE))\n",
        "    dnn.add(Dense(1,activation=\"sigmoid\",dtype=np.float32))   \n",
        "    dnn.compile(optimizer='adam',\n",
        "                loss=BinaryCrossentropy(from_logits=False),\n",
        "                metrics=['accuracy'])   # add to default metrics=loss\n",
        "    dnn.build(input_shape=INPUT_SHAPE)\n",
        "    #ln_rate = tf.keras.optimizers.Adam(learning_rate = LN_RATE)\n",
        "    #bc=tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "    #model.compile(loss=bc, optimizer=ln_rate, metrics=[\"accuracy\"])\n",
        "    return dnn\n",
        "model = make_DNN()\n",
        "print(model.summary())"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "make_DNN\n",
            "input shape: (64, 4)\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_8 (Conv1D)            (None, 64, 16)            208       \n",
            "_________________________________________________________________\n",
            "conv1d_9 (Conv1D)            (None, 64, 16)            784       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1 (None, 32, 16)            0         \n",
            "_________________________________________________________________\n",
            "lstm_8 (LSTM)                (None, 32, 16)            2112      \n",
            "_________________________________________________________________\n",
            "lstm_9 (LSTM)                (None, 16)                2112      \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 5,505\n",
            "Trainable params: 5,505\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlVF0hR3j2UW"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "def do_cross_validation(X,y):\n",
        "    cv_scores = []\n",
        "    fold=0\n",
        "    mycallbacks = [ModelCheckpoint(\n",
        "        filepath=MODELPATH, save_best_only=True, \n",
        "        monitor='val_accuracy', mode='max')]   \n",
        "    splitter = KFold(n_splits=SPLITS)  # this does not shuffle\n",
        "    for train_index,valid_index in splitter.split(X):\n",
        "        if fold < FOLDS:\n",
        "            fold += 1\n",
        "            X_train=X[train_index] # inputs for training\n",
        "            y_train=y[train_index] # labels for training\n",
        "            X_valid=X[valid_index] # inputs for validation\n",
        "            y_valid=y[valid_index] # labels for validation\n",
        "            print(\"MODEL\")\n",
        "            # Call constructor on each CV. Else, continually improves the same model.\n",
        "            model = model = make_DNN()\n",
        "            print(\"FIT\")  # model.fit() implements learning\n",
        "            start_time=time.time()\n",
        "            history=model.fit(X_train, y_train, \n",
        "                    epochs=EPOCHS, \n",
        "                    verbose=1,  # ascii art while learning\n",
        "                    callbacks=mycallbacks,   # called at end of each epoch\n",
        "                    validation_data=(X_valid,y_valid))\n",
        "            end_time=time.time()\n",
        "            elapsed_time=(end_time-start_time)                        \n",
        "            print(\"Fold %d, %d epochs, %d sec\"%(fold,EPOCHS,elapsed_time))\n",
        "            # print(history.history.keys())  # all these keys will be shown in figure\n",
        "            pd.DataFrame(history.history).plot(figsize=(8,5))\n",
        "            plt.grid(True)\n",
        "            plt.gca().set_ylim(0,1) # any losses > 1 will be off the scale\n",
        "            plt.show()\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9Ggt4EsSj2UY",
        "outputId": "f712e775-62a5-4519-ff22-aa078da1daa9"
      },
      "source": [
        "do_cross_validation(X,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MODEL\n",
            "make_DNN\n",
            "input shape: (64, 4)\n",
            "FIT\n",
            "Epoch 1/100\n",
            "1334/1334 [==============================] - 15s 9ms/step - loss: 0.6990 - accuracy: 0.5100 - val_loss: 0.6678 - val_accuracy: 0.5935\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_12_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_12_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/100\n",
            "1334/1334 [==============================] - 11s 8ms/step - loss: 0.6578 - accuracy: 0.6119 - val_loss: 0.6167 - val_accuracy: 0.6492\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_12_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_12_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/100\n",
            "1334/1334 [==============================] - 11s 8ms/step - loss: 0.6148 - accuracy: 0.6585 - val_loss: 0.5884 - val_accuracy: 0.6727\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_12_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_12_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/100\n",
            "1334/1334 [==============================] - 11s 8ms/step - loss: 0.5904 - accuracy: 0.6804 - val_loss: 0.5758 - val_accuracy: 0.6836\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_12_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_12_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/100\n",
            "1334/1334 [==============================] - 11s 9ms/step - loss: 0.5768 - accuracy: 0.6883 - val_loss: 0.5697 - val_accuracy: 0.6853\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_12_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_12_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6/100\n",
            "1334/1334 [==============================] - 11s 9ms/step - loss: 0.5673 - accuracy: 0.6934 - val_loss: 0.5630 - val_accuracy: 0.6904\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_12_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_12_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7/100\n",
            "1334/1334 [==============================] - 11s 8ms/step - loss: 0.5655 - accuracy: 0.6946 - val_loss: 0.5565 - val_accuracy: 0.6946\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_12_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_12_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5586 - accuracy: 0.7008 - val_loss: 0.5558 - val_accuracy: 0.6910\n",
            "Epoch 9/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5580 - accuracy: 0.6989 - val_loss: 0.5598 - val_accuracy: 0.6887\n",
            "Epoch 10/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5508 - accuracy: 0.7034 - val_loss: 0.5544 - val_accuracy: 0.6952\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_12_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_12_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 11/100\n",
            "1334/1334 [==============================] - 11s 9ms/step - loss: 0.5462 - accuracy: 0.7058 - val_loss: 0.5496 - val_accuracy: 0.6977\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_12_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_12_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 12/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5447 - accuracy: 0.7051 - val_loss: 0.5485 - val_accuracy: 0.6960\n",
            "Epoch 13/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5423 - accuracy: 0.7058 - val_loss: 0.5497 - val_accuracy: 0.6977\n",
            "Epoch 14/100\n",
            "1334/1334 [==============================] - 11s 8ms/step - loss: 0.5390 - accuracy: 0.7107 - val_loss: 0.5554 - val_accuracy: 0.6911\n",
            "Epoch 15/100\n",
            "1334/1334 [==============================] - 11s 9ms/step - loss: 0.5348 - accuracy: 0.7124 - val_loss: 0.5449 - val_accuracy: 0.6990\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_12_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_12_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 16/100\n",
            "1334/1334 [==============================] - 11s 9ms/step - loss: 0.5342 - accuracy: 0.7137 - val_loss: 0.5507 - val_accuracy: 0.7011\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_12_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_12_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 17/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5361 - accuracy: 0.7140 - val_loss: 0.5412 - val_accuracy: 0.7024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_12_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_12_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 18/100\n",
            "1334/1334 [==============================] - 11s 8ms/step - loss: 0.5317 - accuracy: 0.7139 - val_loss: 0.5441 - val_accuracy: 0.7000\n",
            "Epoch 19/100\n",
            "1334/1334 [==============================] - 11s 9ms/step - loss: 0.5311 - accuracy: 0.7120 - val_loss: 0.5469 - val_accuracy: 0.7016\n",
            "Epoch 20/100\n",
            "1334/1334 [==============================] - 11s 9ms/step - loss: 0.5273 - accuracy: 0.7165 - val_loss: 0.5501 - val_accuracy: 0.6969\n",
            "Epoch 21/100\n",
            "1334/1334 [==============================] - 11s 9ms/step - loss: 0.5239 - accuracy: 0.7181 - val_loss: 0.5525 - val_accuracy: 0.6990\n",
            "Epoch 22/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5249 - accuracy: 0.7175 - val_loss: 0.5553 - val_accuracy: 0.7001\n",
            "Epoch 23/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5292 - accuracy: 0.7153 - val_loss: 0.5496 - val_accuracy: 0.6986\n",
            "Epoch 24/100\n",
            "1334/1334 [==============================] - 11s 8ms/step - loss: 0.5208 - accuracy: 0.7224 - val_loss: 0.5476 - val_accuracy: 0.7009\n",
            "Epoch 25/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5214 - accuracy: 0.7203 - val_loss: 0.5440 - val_accuracy: 0.7000\n",
            "Epoch 26/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5215 - accuracy: 0.7176 - val_loss: 0.5395 - val_accuracy: 0.7022\n",
            "Epoch 27/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5185 - accuracy: 0.7189 - val_loss: 0.5394 - val_accuracy: 0.7024\n",
            "Epoch 28/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5172 - accuracy: 0.7206 - val_loss: 0.5422 - val_accuracy: 0.6991\n",
            "Epoch 29/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5255 - accuracy: 0.7174 - val_loss: 0.5376 - val_accuracy: 0.7025\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_12_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_12_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 30/100\n",
            "1334/1334 [==============================] - 11s 9ms/step - loss: 0.5173 - accuracy: 0.7179 - val_loss: 0.5391 - val_accuracy: 0.7031\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_12_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_12_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 31/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5183 - accuracy: 0.7196 - val_loss: 0.5415 - val_accuracy: 0.7011\n",
            "Epoch 32/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5154 - accuracy: 0.7221 - val_loss: 0.5575 - val_accuracy: 0.6946\n",
            "Epoch 33/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5208 - accuracy: 0.7164 - val_loss: 0.5410 - val_accuracy: 0.7051\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_12_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_12_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 34/100\n",
            "1334/1334 [==============================] - 11s 9ms/step - loss: 0.5137 - accuracy: 0.7228 - val_loss: 0.5436 - val_accuracy: 0.7046\n",
            "Epoch 35/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5078 - accuracy: 0.7297 - val_loss: 0.5508 - val_accuracy: 0.6982\n",
            "Epoch 36/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5131 - accuracy: 0.7248 - val_loss: 0.5515 - val_accuracy: 0.7034\n",
            "Epoch 37/100\n",
            "1334/1334 [==============================] - 11s 9ms/step - loss: 0.5090 - accuracy: 0.7279 - val_loss: 0.5440 - val_accuracy: 0.7045\n",
            "Epoch 38/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5137 - accuracy: 0.7264 - val_loss: 0.5401 - val_accuracy: 0.7027\n",
            "Epoch 39/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5066 - accuracy: 0.7310 - val_loss: 0.5440 - val_accuracy: 0.7003\n",
            "Epoch 40/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5067 - accuracy: 0.7281 - val_loss: 0.5402 - val_accuracy: 0.7067\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_12_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_12_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 41/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5106 - accuracy: 0.7264 - val_loss: 0.5495 - val_accuracy: 0.7031\n",
            "Epoch 42/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5074 - accuracy: 0.7279 - val_loss: 0.5422 - val_accuracy: 0.7067\n",
            "Epoch 43/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5069 - accuracy: 0.7255 - val_loss: 0.5615 - val_accuracy: 0.6972\n",
            "Epoch 44/100\n",
            "1334/1334 [==============================] - 11s 9ms/step - loss: 0.5161 - accuracy: 0.7261 - val_loss: 0.5534 - val_accuracy: 0.7059\n",
            "Epoch 45/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.4988 - accuracy: 0.7332 - val_loss: 0.5388 - val_accuracy: 0.7063\n",
            "Epoch 46/100\n",
            "1334/1334 [==============================] - 11s 9ms/step - loss: 0.5053 - accuracy: 0.7296 - val_loss: 0.5386 - val_accuracy: 0.7059\n",
            "Epoch 47/100\n",
            "1334/1334 [==============================] - 11s 8ms/step - loss: 0.5007 - accuracy: 0.7367 - val_loss: 0.5542 - val_accuracy: 0.7051\n",
            "Epoch 48/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5043 - accuracy: 0.7325 - val_loss: 0.5438 - val_accuracy: 0.7062\n",
            "Epoch 49/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5009 - accuracy: 0.7319 - val_loss: 0.5447 - val_accuracy: 0.7038\n",
            "Epoch 50/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.4988 - accuracy: 0.7367 - val_loss: 0.5565 - val_accuracy: 0.7043\n",
            "Epoch 51/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.4982 - accuracy: 0.7369 - val_loss: 0.5440 - val_accuracy: 0.7084\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_12_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_12_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 52/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.4950 - accuracy: 0.7366 - val_loss: 0.5372 - val_accuracy: 0.7079\n",
            "Epoch 53/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5005 - accuracy: 0.7355 - val_loss: 0.5438 - val_accuracy: 0.7057\n",
            "Epoch 54/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.4989 - accuracy: 0.7357 - val_loss: 0.5407 - val_accuracy: 0.7077\n",
            "Epoch 55/100\n",
            "1334/1334 [==============================] - 11s 8ms/step - loss: 0.4982 - accuracy: 0.7361 - val_loss: 0.5484 - val_accuracy: 0.7108\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_12_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_12_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 56/100\n",
            "1334/1334 [==============================] - 11s 9ms/step - loss: 0.4918 - accuracy: 0.7368 - val_loss: 0.5502 - val_accuracy: 0.7082\n",
            "Epoch 57/100\n",
            "1334/1334 [==============================] - 11s 9ms/step - loss: 0.4970 - accuracy: 0.7371 - val_loss: 0.5406 - val_accuracy: 0.7085\n",
            "Epoch 58/100\n",
            "1334/1334 [==============================] - 11s 9ms/step - loss: 0.4875 - accuracy: 0.7411 - val_loss: 0.5647 - val_accuracy: 0.6951\n",
            "Epoch 59/100\n",
            "1334/1334 [==============================] - 11s 8ms/step - loss: 0.5094 - accuracy: 0.7301 - val_loss: 0.5406 - val_accuracy: 0.7027\n",
            "Epoch 60/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.4976 - accuracy: 0.7337 - val_loss: 0.5443 - val_accuracy: 0.7072\n",
            "Epoch 61/100\n",
            "1334/1334 [==============================] - 11s 8ms/step - loss: 0.4937 - accuracy: 0.7396 - val_loss: 0.5465 - val_accuracy: 0.7075\n",
            "Epoch 62/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.4878 - accuracy: 0.7410 - val_loss: 0.5446 - val_accuracy: 0.7098\n",
            "Epoch 63/100\n",
            "1334/1334 [==============================] - 11s 9ms/step - loss: 0.4902 - accuracy: 0.7395 - val_loss: 0.5470 - val_accuracy: 0.7106\n",
            "Epoch 64/100\n",
            "1334/1334 [==============================] - 11s 8ms/step - loss: 0.4903 - accuracy: 0.7407 - val_loss: 0.5414 - val_accuracy: 0.7093\n",
            "Epoch 65/100\n",
            "1334/1334 [==============================] - 11s 9ms/step - loss: 0.4864 - accuracy: 0.7427 - val_loss: 0.5623 - val_accuracy: 0.7098\n",
            "Epoch 66/100\n",
            "1334/1334 [==============================] - 11s 8ms/step - loss: 0.4856 - accuracy: 0.7410 - val_loss: 0.5455 - val_accuracy: 0.7080\n",
            "Epoch 67/100\n",
            "1334/1334 [==============================] - 11s 9ms/step - loss: 0.4860 - accuracy: 0.7403 - val_loss: 0.5975 - val_accuracy: 0.6833\n",
            "Epoch 68/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5172 - accuracy: 0.7261 - val_loss: 0.5446 - val_accuracy: 0.7053\n",
            "Epoch 69/100\n",
            "1334/1334 [==============================] - 11s 9ms/step - loss: 0.4872 - accuracy: 0.7419 - val_loss: 0.5548 - val_accuracy: 0.7095\n",
            "Epoch 70/100\n",
            "1334/1334 [==============================] - 11s 8ms/step - loss: 0.4824 - accuracy: 0.7437 - val_loss: 0.5481 - val_accuracy: 0.7051\n",
            "Epoch 71/100\n",
            "1334/1334 [==============================] - 11s 8ms/step - loss: 0.4829 - accuracy: 0.7407 - val_loss: 0.5507 - val_accuracy: 0.7061\n",
            "Epoch 72/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.4915 - accuracy: 0.7408 - val_loss: 0.5530 - val_accuracy: 0.7089\n",
            "Epoch 73/100\n",
            "1334/1334 [==============================] - 11s 9ms/step - loss: 0.4899 - accuracy: 0.7386 - val_loss: 0.5483 - val_accuracy: 0.7112\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_12_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_12_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 74/100\n",
            "1334/1334 [==============================] - 11s 8ms/step - loss: 0.4855 - accuracy: 0.7411 - val_loss: 0.5508 - val_accuracy: 0.7078\n",
            "Epoch 75/100\n",
            "1334/1334 [==============================] - 11s 8ms/step - loss: 0.4827 - accuracy: 0.7441 - val_loss: 0.5516 - val_accuracy: 0.7081\n",
            "Epoch 76/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.4825 - accuracy: 0.7437 - val_loss: 0.5626 - val_accuracy: 0.7077\n",
            "Epoch 77/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.4924 - accuracy: 0.7376 - val_loss: 0.5575 - val_accuracy: 0.7038\n",
            "Epoch 78/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.4914 - accuracy: 0.7368 - val_loss: 0.5569 - val_accuracy: 0.7094\n",
            "Epoch 79/100\n",
            "1334/1334 [==============================] - 11s 9ms/step - loss: 0.4805 - accuracy: 0.7443 - val_loss: 0.5520 - val_accuracy: 0.7116\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_12_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_12_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 80/100\n",
            "1334/1334 [==============================] - 11s 9ms/step - loss: 0.4807 - accuracy: 0.7463 - val_loss: 0.5543 - val_accuracy: 0.7115\n",
            "Epoch 81/100\n",
            "1334/1334 [==============================] - 11s 9ms/step - loss: 0.4779 - accuracy: 0.7465 - val_loss: 0.5527 - val_accuracy: 0.7087\n",
            "Epoch 82/100\n",
            "1334/1334 [==============================] - 11s 9ms/step - loss: 0.4826 - accuracy: 0.7430 - val_loss: 0.5537 - val_accuracy: 0.7066\n",
            "Epoch 83/100\n",
            "1334/1334 [==============================] - 11s 8ms/step - loss: 0.4851 - accuracy: 0.7392 - val_loss: 0.5557 - val_accuracy: 0.7106\n",
            "Epoch 84/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.4768 - accuracy: 0.7488 - val_loss: 0.5554 - val_accuracy: 0.7081\n",
            "Epoch 85/100\n",
            "1334/1334 [==============================] - 11s 9ms/step - loss: 0.4763 - accuracy: 0.7475 - val_loss: 0.5570 - val_accuracy: 0.7098\n",
            "Epoch 86/100\n",
            "1334/1334 [==============================] - 11s 9ms/step - loss: 0.4798 - accuracy: 0.7480 - val_loss: 0.5471 - val_accuracy: 0.7108\n",
            "Epoch 87/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.4773 - accuracy: 0.7426 - val_loss: 0.5486 - val_accuracy: 0.7102\n",
            "Epoch 88/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.4783 - accuracy: 0.7486 - val_loss: 0.5677 - val_accuracy: 0.7120\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_12_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_12_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 89/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.4828 - accuracy: 0.7445 - val_loss: 0.5539 - val_accuracy: 0.7110\n",
            "Epoch 90/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.4757 - accuracy: 0.7471 - val_loss: 0.5491 - val_accuracy: 0.7122\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_12_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_12_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 91/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.4688 - accuracy: 0.7538 - val_loss: 0.5608 - val_accuracy: 0.7137\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_12_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_12_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 92/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.4706 - accuracy: 0.7505 - val_loss: 0.5603 - val_accuracy: 0.7076\n",
            "Epoch 93/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.4735 - accuracy: 0.7457 - val_loss: 0.5597 - val_accuracy: 0.7132\n",
            "Epoch 94/100\n",
            "1334/1334 [==============================] - 11s 8ms/step - loss: 0.4745 - accuracy: 0.7499 - val_loss: 0.5600 - val_accuracy: 0.7106\n",
            "Epoch 95/100\n",
            "1334/1334 [==============================] - 11s 9ms/step - loss: 0.4733 - accuracy: 0.7496 - val_loss: 0.5635 - val_accuracy: 0.7096\n",
            "Epoch 96/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.4692 - accuracy: 0.7517 - val_loss: 0.5597 - val_accuracy: 0.7097\n",
            "Epoch 97/100\n",
            "1334/1334 [==============================] - 11s 9ms/step - loss: 0.4727 - accuracy: 0.7491 - val_loss: 0.5583 - val_accuracy: 0.7156\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_12_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_12_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 98/100\n",
            "1334/1334 [==============================] - 11s 9ms/step - loss: 0.4710 - accuracy: 0.7503 - val_loss: 0.5520 - val_accuracy: 0.7130\n",
            "Epoch 99/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.4734 - accuracy: 0.7456 - val_loss: 0.5486 - val_accuracy: 0.7105\n",
            "Epoch 100/100\n",
            "1334/1334 [==============================] - 11s 9ms/step - loss: 0.4723 - accuracy: 0.7480 - val_loss: 0.5620 - val_accuracy: 0.7137\n",
            "Fold 1, 100 epochs, 1355 sec\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "MODEL\n",
            "make_DNN\n",
            "input shape: (64, 4)\n",
            "FIT\n",
            "Epoch 1/100\n",
            "1334/1334 [==============================] - 16s 9ms/step - loss: 0.7166 - accuracy: 0.5016 - val_loss: 0.6732 - val_accuracy: 0.5884\n",
            "Epoch 2/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.6705 - accuracy: 0.5898 - val_loss: 0.6358 - val_accuracy: 0.6391\n",
            "Epoch 3/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.6374 - accuracy: 0.6365 - val_loss: 0.6103 - val_accuracy: 0.6688\n",
            "Epoch 4/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.6071 - accuracy: 0.6682 - val_loss: 0.5868 - val_accuracy: 0.6755\n",
            "Epoch 5/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5914 - accuracy: 0.6745 - val_loss: 0.5772 - val_accuracy: 0.6773\n",
            "Epoch 6/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5803 - accuracy: 0.6841 - val_loss: 0.5661 - val_accuracy: 0.6916\n",
            "Epoch 7/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5708 - accuracy: 0.6917 - val_loss: 0.5543 - val_accuracy: 0.6999\n",
            "Epoch 8/100\n",
            "1334/1334 [==============================] - 11s 9ms/step - loss: 0.5713 - accuracy: 0.6860 - val_loss: 0.5654 - val_accuracy: 0.6928\n",
            "Epoch 9/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5598 - accuracy: 0.6990 - val_loss: 0.5447 - val_accuracy: 0.7051\n",
            "Epoch 10/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5558 - accuracy: 0.6987 - val_loss: 0.5482 - val_accuracy: 0.6977\n",
            "Epoch 11/100\n",
            "1334/1334 [==============================] - 11s 9ms/step - loss: 0.5477 - accuracy: 0.7007 - val_loss: 0.5472 - val_accuracy: 0.6997\n",
            "Epoch 12/100\n",
            "1334/1334 [==============================] - 11s 9ms/step - loss: 0.5684 - accuracy: 0.6937 - val_loss: 0.5443 - val_accuracy: 0.7060\n",
            "Epoch 13/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5547 - accuracy: 0.6970 - val_loss: 0.5410 - val_accuracy: 0.7076\n",
            "Epoch 14/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5446 - accuracy: 0.7059 - val_loss: 0.5470 - val_accuracy: 0.7095\n",
            "Epoch 15/100\n",
            "1334/1334 [==============================] - 11s 9ms/step - loss: 0.5580 - accuracy: 0.6993 - val_loss: 0.5365 - val_accuracy: 0.7108\n",
            "Epoch 16/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5395 - accuracy: 0.7054 - val_loss: 0.5444 - val_accuracy: 0.7031\n",
            "Epoch 17/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5385 - accuracy: 0.7074 - val_loss: 0.5419 - val_accuracy: 0.7063\n",
            "Epoch 18/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5408 - accuracy: 0.7077 - val_loss: 0.5352 - val_accuracy: 0.7110\n",
            "Epoch 19/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5337 - accuracy: 0.7120 - val_loss: 0.5326 - val_accuracy: 0.7108\n",
            "Epoch 20/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5304 - accuracy: 0.7149 - val_loss: 0.5367 - val_accuracy: 0.7074\n",
            "Epoch 21/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5352 - accuracy: 0.7127 - val_loss: 0.5337 - val_accuracy: 0.7142\n",
            "Epoch 22/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5280 - accuracy: 0.7188 - val_loss: 0.5344 - val_accuracy: 0.7119\n",
            "Epoch 23/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5312 - accuracy: 0.7095 - val_loss: 0.5289 - val_accuracy: 0.7141\n",
            "Epoch 24/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5292 - accuracy: 0.7149 - val_loss: 0.5336 - val_accuracy: 0.7121\n",
            "Epoch 25/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5292 - accuracy: 0.7136 - val_loss: 0.5358 - val_accuracy: 0.7119\n",
            "Epoch 26/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5239 - accuracy: 0.7169 - val_loss: 0.5312 - val_accuracy: 0.7125\n",
            "Epoch 27/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5227 - accuracy: 0.7181 - val_loss: 0.5302 - val_accuracy: 0.7104\n",
            "Epoch 28/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5197 - accuracy: 0.7182 - val_loss: 0.5293 - val_accuracy: 0.7159\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_14_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn, lstm_cell_15_layer_call_and_return_conditional_losses, lstm_cell_15_layer_call_fn, lstm_cell_14_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 29/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5174 - accuracy: 0.7238 - val_loss: 0.5384 - val_accuracy: 0.7056\n",
            "Epoch 30/100\n",
            "1334/1334 [==============================] - 11s 9ms/step - loss: 0.5195 - accuracy: 0.7189 - val_loss: 0.5367 - val_accuracy: 0.7158\n",
            "Epoch 31/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5172 - accuracy: 0.7233 - val_loss: 0.5349 - val_accuracy: 0.7159\n",
            "Epoch 32/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5147 - accuracy: 0.7216 - val_loss: 0.5284 - val_accuracy: 0.7158\n",
            "Epoch 33/100\n",
            "1334/1334 [==============================] - 11s 8ms/step - loss: 0.5181 - accuracy: 0.7228 - val_loss: 0.5437 - val_accuracy: 0.7114\n",
            "Epoch 34/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5160 - accuracy: 0.7228 - val_loss: 0.5272 - val_accuracy: 0.7136\n",
            "Epoch 35/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5179 - accuracy: 0.7170 - val_loss: 0.5353 - val_accuracy: 0.7134\n",
            "Epoch 36/100\n",
            "1334/1334 [==============================] - 11s 9ms/step - loss: 0.5149 - accuracy: 0.7240 - val_loss: 0.5278 - val_accuracy: 0.7138\n",
            "Epoch 37/100\n",
            "1334/1334 [==============================] - 12s 9ms/step - loss: 0.5107 - accuracy: 0.7276 - val_loss: 0.5290 - val_accuracy: 0.7160\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_14_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn, lstm_cell_15_layer_call_and_return_conditional_losses, lstm_cell_15_layer_call_fn, lstm_cell_14_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 38/100\n",
            "1334/1334 [==============================] - 11s 9ms/step - loss: 0.5121 - accuracy: 0.7235 - val_loss: 0.5330 - val_accuracy: 0.7134\n",
            "Epoch 39/100\n",
            " 664/1334 [=============>................] - ETA: 4s - loss: 0.5029 - accuracy: 0.7359"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-jG1h5fj2Ua"
      },
      "source": [
        "from keras.models import load_model\n",
        "X,y = prepare_inputs_len_x_alphabet(pc_test,nc_test,ALPHABET)\n",
        "best_model=load_model(MODELPATH)\n",
        "scores = best_model.evaluate(X, y, verbose=0)\n",
        "print(\"The best model parameters were saved during cross-validation.\")\n",
        "print(\"Best was defined as maximum validation accuracy at end of any epoch.\")\n",
        "print(\"Now re-load the best model and test it on previously unseen data.\")\n",
        "print(\"Test on\",len(pc_test),\"PC seqs\")\n",
        "print(\"Test on\",len(nc_test),\"NC seqs\")\n",
        "print(\"%s: %.2f%%\" % (best_model.metrics_names[1], scores[1]*100))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VycUnmvUj2Ue"
      },
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "ns_probs = [0 for _ in range(len(y))]\n",
        "bm_probs = best_model.predict(X)\n",
        "ns_auc = roc_auc_score(y, ns_probs)\n",
        "bm_auc = roc_auc_score(y, bm_probs)\n",
        "ns_fpr, ns_tpr, _ = roc_curve(y, ns_probs)\n",
        "bm_fpr, bm_tpr, _ = roc_curve(y, bm_probs)\n",
        "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='Guess, auc=%.4f'%ns_auc)\n",
        "plt.plot(bm_fpr, bm_tpr, marker='.', label='Model, auc=%.4f'%bm_auc)\n",
        "plt.title('ROC')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "print(\"%s: %.2f%%\" %('AUC',bm_auc*100.0))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFMb6rGNj2Ug"
      },
      "source": [
        "t = time.time()\n",
        "time.strftime('%Y-%m-%d %H:%M:%S %Z', time.localtime(t))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-mEgDrQjUzF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}