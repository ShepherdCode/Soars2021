{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Simulator101.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0asdcdunj2Tx"
      },
      "source": [
        "# ORF recognition by CNN\n",
        "\n",
        "Use variable number of bases between START and STOP. Thus, ncRNA will have its STOP out-of-frame or too close to the START, and pcRNA will have its STOP in-frame and far from the START."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QP1VTRNQj2UO",
        "outputId": "09d1f0df-b9ef-4b15-e941-fad8f8ccda24"
      },
      "source": [
        "import time \n",
        "t = time.time()\n",
        "time.strftime('%Y-%m-%d %H:%M:%S %Z', time.localtime(t))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2021-07-07 19:21:29 UTC'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nhz4GKonj2T_"
      },
      "source": [
        "PC_SEQUENCES= 32000  # how many protein-coding sequences\n",
        "NC_SEQUENCES= 32000   # how many non-coding sequences\n",
        "PC_TESTS=1000\n",
        "NC_TESTS=1000\n",
        "RNA_LEN=36            # how long is each sequence\n",
        "CDS_LEN=18            # min CDS len to be coding\n",
        "ALPHABET=4          # how many different letters are possible\n",
        "INPUT_SHAPE_2D = (RNA_LEN,ALPHABET,1) # Conv2D needs 3D inputs\n",
        "INPUT_SHAPE = (RNA_LEN,ALPHABET) # Conv1D needs 2D inputs\n",
        "FILTERS = 16   # how many different patterns the model looks for\n",
        "NEURONS = 16\n",
        "DROP_RATE = 0.4\n",
        "WIDTH = 3   # how wide each pattern is, in bases\n",
        "STRIDE_2D = (1,1)  # For Conv2D how far in each direction\n",
        "STRIDE = 1 # For Conv1D, how far between pattern matches, in bases\n",
        "EPOCHS=400  # how many times to train on all the data\n",
        "SPLITS=3  # SPLITS=3 means train on 2/3 and validate on 1/3 \n",
        "FOLDS=3  # train the model this many times (range 1 to SPLITS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lr7q90rxj2UE",
        "outputId": "7ce655e4-6615-4641-9b48-250c4c89d65d"
      },
      "source": [
        "import sys\n",
        "IN_COLAB = False\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    pass\n",
        "if IN_COLAB:\n",
        "    print(\"On Google CoLab, mount cloud-local file, get our code from GitHub.\")\n",
        "    PATH='/content/drive/'\n",
        "    #drive.mount(PATH,force_remount=True)  # hardly ever need this\n",
        "    #drive.mount(PATH)    # Google will require login credentials\n",
        "    DATAPATH=PATH+'My Drive/data/'  # must end in \"/\"\n",
        "    import requests\n",
        "    r = requests.get('https://raw.githubusercontent.com/ShepherdCode/Soars2021/master/SimTools/RNA_describe.py')\n",
        "    with open('RNA_describe.py', 'w') as f:\n",
        "        f.write(r.text)  \n",
        "    from RNA_describe import ORF_counter\n",
        "    from RNA_describe import Random_Base_Oracle\n",
        "    r = requests.get('https://raw.githubusercontent.com/ShepherdCode/Soars2021/master/SimTools/RNA_prep.py')\n",
        "    with open('RNA_prep.py', 'w') as f:\n",
        "        f.write(r.text)  \n",
        "    from RNA_prep import prepare_inputs_len_x_alphabet\n",
        "    r = requests.get('https://raw.githubusercontent.com/ShepherdCode/Soars2021/master/SimTools/ORF_eliminator.py')\n",
        "    with open('ORF_eliminator.py', 'w') as f:\n",
        "        f.write(r.text)  \n",
        "    from ORF_eliminator import *\n",
        "else:\n",
        "        print(\"CoLab not working. On my PC, use relative paths.\")\n",
        "        DATAPATH='data/'  # must end in \"/\"\n",
        "        sys.path.append(\"..\") # append parent dir in order to use sibling dirs\n",
        "        from SimTools.RNA_describe import ORF_counter,Random_Base_Oracle\n",
        "        from SimTools.RNA_prep import prepare_inputs_len_x_alphabet\n",
        "\n",
        "MODELPATH=\"BestModel\"  # saved on cloud instance and lost after logout\n",
        "#MODELPATH=DATAPATH+MODELPATH  # saved on Google Drive but requires login"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "On Google CoLab, mount cloud-local file, get our code from GitHub.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGDXH8Uwj2UM"
      },
      "source": [
        "from os import listdir\n",
        "import csv\n",
        "from zipfile import ZipFile\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats  # mode\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Embedding,Dropout\n",
        "from keras.layers import Conv1D,Conv2D\n",
        "from keras.layers import Flatten,MaxPooling1D,MaxPooling2D\n",
        "from keras.losses import BinaryCrossentropy\n",
        "# tf.keras.losses.BinaryCrossentropy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import colors\n",
        "mycmap = colors.ListedColormap(['red','blue'])  # list color for label 0 then 1\n",
        "np.set_printoptions(precision=2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUOG_jEvGtOm"
      },
      "source": [
        "random = Random_Sequence()\n",
        "nc_all =[]\n",
        "pc_all = random.generate_sequence_withORF(RNA_LEN, PC_SEQUENCES, CDS_LEN)\n",
        "randomSequence = random.generate_sequence(RNA_LEN, NC_SEQUENCES)\n",
        "noncoding = ORF_eliminator()\n",
        "for sequence in randomSequence:\n",
        "  nc_all.append(noncoding.eliminate_ORF(sequence, CDS_LEN))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-BmSXi2jUyl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cafb68c1-02bc-421d-cd52-0a4ae969e46f"
      },
      "source": [
        "# Describe the sequences\n",
        "def describe_sequences(list_of_seq):\n",
        "    oc = ORF_counter()\n",
        "    num_seq = len(list_of_seq)\n",
        "    rna_lens = np.zeros(num_seq)\n",
        "    orf_lens = np.zeros(num_seq)\n",
        "    for i in range(0,num_seq):\n",
        "        rna_len = len(list_of_seq[i])\n",
        "        rna_lens[i] = rna_len\n",
        "        oc.set_sequence(list_of_seq[i])\n",
        "        orf_len = oc.get_max_orf_len()\n",
        "        orf_lens[i] = orf_len\n",
        "    print (\"Average RNA length:\",rna_lens.mean())\n",
        "    print (\"Average ORF length:\",orf_lens.mean())\n",
        "    \n",
        "print(\"Simulated sequences prior to adjustment:\")\n",
        "print(\"PC seqs\")\n",
        "describe_sequences(pc_all)\n",
        "print(\"NC seqs\")\n",
        "describe_sequences(nc_all)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Simulated sequences prior to adjustment:\n",
            "PC seqs\n",
            "Average RNA length: 36.0\n",
            "Average ORF length: 22.1761875\n",
            "NC seqs\n",
            "Average RNA length: 36.0\n",
            "Average ORF length: 0.80371875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iP1y7-J3jUys"
      },
      "source": [
        "pc_train=pc_all[:PC_SEQUENCES]\n",
        "nc_train=nc_all[:NC_SEQUENCES]\n",
        "pc_test=pc_all[PC_SEQUENCES:]\n",
        "nc_test=nc_all[NC_SEQUENCES:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIpTrnH6j2US",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "465b2790-28b0-456f-815d-f413b3a39143"
      },
      "source": [
        "# Use code from our SimTools library.\n",
        "X,y = prepare_inputs_len_x_alphabet(pc_train,nc_train,ALPHABET) # shuffles\n",
        "print(\"Data ready.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data ready.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NvrVU8ij2UU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9835e46d-5820-4af7-eed6-0919fd8e3634"
      },
      "source": [
        "def make_DNN():\n",
        "    print(\"make_DNN\")\n",
        "    print(\"input shape:\",INPUT_SHAPE)\n",
        "    dnn = Sequential()\n",
        "    #dnn.add(Embedding(input_dim=INPUT_SHAPE,output_dim=INPUT_SHAPE)) \n",
        "    dnn.add(Conv1D(filters=FILTERS,kernel_size=WIDTH,strides=STRIDE,padding=\"same\",\n",
        "            input_shape=INPUT_SHAPE))\n",
        "    dnn.add(Conv1D(filters=FILTERS,kernel_size=WIDTH,strides=STRIDE,padding=\"same\"))\n",
        "    dnn.add(MaxPooling1D())\n",
        "    #dnn.add(Conv1D(filters=FILTERS,kernel_size=WIDTH,strides=STRIDE,padding=\"same\"))\n",
        "    #dnn.add(Conv1D(filters=FILTERS,kernel_size=WIDTH,strides=STRIDE,padding=\"same\"))\n",
        "    #dnn.add(MaxPooling1D())\n",
        "    dnn.add(Flatten())\n",
        "    dnn.add(Dense(NEURONS,activation=\"sigmoid\",dtype=np.float32))   \n",
        "    dnn.add(Dropout(DROP_RATE))\n",
        "    dnn.add(Dense(1,activation=\"sigmoid\",dtype=np.float32))   \n",
        "    dnn.compile(optimizer='adam',\n",
        "                loss=BinaryCrossentropy(from_logits=False),\n",
        "                metrics=['accuracy'])   # add to default metrics=loss\n",
        "    dnn.build(input_shape=INPUT_SHAPE)\n",
        "    #ln_rate = tf.keras.optimizers.Adam(learning_rate = LN_RATE)\n",
        "    #bc=tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "    #model.compile(loss=bc, optimizer=ln_rate, metrics=[\"accuracy\"])\n",
        "    return dnn\n",
        "model = make_DNN()\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "make_DNN\n",
            "input shape: (36, 4)\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_4 (Conv1D)            (None, 36, 16)            208       \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 36, 16)            784       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 18, 16)            0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 288)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 16)                4624      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 5,633\n",
            "Trainable params: 5,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlVF0hR3j2UW"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "def do_cross_validation(X,y):\n",
        "    cv_scores = []\n",
        "    fold=0\n",
        "    mycallbacks = [ModelCheckpoint(\n",
        "        filepath=MODELPATH, save_best_only=True, \n",
        "        monitor='val_accuracy', mode='max')]   \n",
        "    splitter = KFold(n_splits=SPLITS)  # this does not shuffle\n",
        "    for train_index,valid_index in splitter.split(X):\n",
        "        if fold < FOLDS:\n",
        "            fold += 1\n",
        "            X_train=X[train_index] # inputs for training\n",
        "            y_train=y[train_index] # labels for training\n",
        "            X_valid=X[valid_index] # inputs for validation\n",
        "            y_valid=y[valid_index] # labels for validation\n",
        "            print(\"MODEL\")\n",
        "            # Call constructor on each CV. Else, continually improves the same model.\n",
        "            model = model = make_DNN()\n",
        "            print(\"FIT\")  # model.fit() implements learning\n",
        "            start_time=time.time()\n",
        "            history=model.fit(X_train, y_train, \n",
        "                    epochs=EPOCHS, \n",
        "                    verbose=1,  # ascii art while learning\n",
        "                    callbacks=mycallbacks,   # called at end of each epoch\n",
        "                    validation_data=(X_valid,y_valid))\n",
        "            end_time=time.time()\n",
        "            elapsed_time=(end_time-start_time)                        \n",
        "            print(\"Fold %d, %d epochs, %d sec\"%(fold,EPOCHS,elapsed_time))\n",
        "            # print(history.history.keys())  # all these keys will be shown in figure\n",
        "            pd.DataFrame(history.history).plot(figsize=(8,5))\n",
        "            plt.grid(True)\n",
        "            plt.gca().set_ylim(0,1) # any losses > 1 will be off the scale\n",
        "            plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ggt4EsSj2UY"
      },
      "source": [
        "do_cross_validation(X,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-jG1h5fj2Ua"
      },
      "source": [
        "from keras.models import load_model\n",
        "X,y = prepare_inputs_len_x_alphabet(pc_test,nc_test,ALPHABET)\n",
        "best_model=load_model(MODELPATH)\n",
        "scores = best_model.evaluate(X, y, verbose=0)\n",
        "print(\"The best model parameters were saved during cross-validation.\")\n",
        "print(\"Best was defined as maximum validation accuracy at end of any epoch.\")\n",
        "print(\"Now re-load the best model and test it on previously unseen data.\")\n",
        "print(\"Test on\",len(pc_test),\"PC seqs\")\n",
        "print(\"Test on\",len(nc_test),\"NC seqs\")\n",
        "print(\"%s: %.2f%%\" % (best_model.metrics_names[1], scores[1]*100))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VycUnmvUj2Ue"
      },
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "ns_probs = [0 for _ in range(len(y))]\n",
        "bm_probs = best_model.predict(X)\n",
        "ns_auc = roc_auc_score(y, ns_probs)\n",
        "bm_auc = roc_auc_score(y, bm_probs)\n",
        "ns_fpr, ns_tpr, _ = roc_curve(y, ns_probs)\n",
        "bm_fpr, bm_tpr, _ = roc_curve(y, bm_probs)\n",
        "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='Guess, auc=%.4f'%ns_auc)\n",
        "plt.plot(bm_fpr, bm_tpr, marker='.', label='Model, auc=%.4f'%bm_auc)\n",
        "plt.title('ROC')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "print(\"%s: %.2f%%\" %('AUC',bm_auc*100.0))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFMb6rGNj2Ug"
      },
      "source": [
        "t = time.time()\n",
        "time.strftime('%Y-%m-%d %H:%M:%S %Z', time.localtime(t))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-mEgDrQjUzF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}