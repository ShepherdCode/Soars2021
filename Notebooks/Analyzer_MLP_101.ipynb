{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Analyzer_MLP_101.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxjDXgzOuzm9"
      },
      "source": [
        "# Analyzer MLP\n",
        "\n",
        "RNA classification model using mRNA and lncRNA sequences from GENCODE v38.\n",
        "\n",
        "Assume the user downloaded files from GENCODE v38 [FTP](http://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_38/)\n",
        "to a subdirectory called data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWH1hul6uKub"
      },
      "source": [
        "## Import Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMB8T39CuJ2Y",
        "outputId": "6a4ee3eb-b046-43ec-b1f2-fcd4a3bb43da"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import pandas as pd\n",
        "import gzip\n",
        "from scipy.stats import chisquare, kstest\n",
        "import sys\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Embedding,Dropout\n",
        "from keras.layers import Flatten,TimeDistributed\n",
        "from keras.losses import BinaryCrossentropy\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    IN_COLAB = True\n",
        "    print(\"On Google CoLab, mount cloud-local file, get our code from GitHub.\")\n",
        "    PATH='/content/drive/'\n",
        "    #drive.mount(PATH,force_remount=True)  # hardly ever need this\n",
        "    drive.mount(PATH)    # Google will require login credentials\n",
        "    DATAPATH=PATH+'My Drive/data/'  # must end in \"/\"\n",
        "    import requests\n",
        "    s = requests.get('https://raw.githubusercontent.com/ShepherdCode/Soars2021/master/SimTools/RNA_describe.py')\n",
        "    with open('RNA_describe.py', 'w') as f:\n",
        "      f.write(s.text)  # writes to cloud local, delete the file later?\n",
        "    s = requests.get('https://raw.githubusercontent.com/ShepherdCode/Soars2021/master/SimTools/GenCodeTools.py')\n",
        "    with open ('GenCodeTools.py', 'w') as f:\n",
        "      f.write(s.text)\n",
        "    s = requests.get('https://raw.githubusercontent.com/ShepherdCode/Soars2021/master/SimTools/plot_generator.py')\n",
        "    with open('plot_generator.py', 'w') as f:\n",
        "      f.write(s.text)\n",
        "    s = requests.get('https://raw.githubusercontent.com/ShepherdCode/Soars2021/master/SimTools/KmerTools.py')\n",
        "    with open('KmerTools.py', 'w') as f:\n",
        "      f.write(s.text)  \n",
        "    from KmerTools import KmerTools\n",
        "    from RNA_describe import *\n",
        "    from GenCodeTools import *\n",
        "    from plot_generator import *\n",
        "except:\n",
        "    print(\"CoLab not working. On my PC, use relative paths.\")\n",
        "    IN_COLAB = False\n",
        "    DATAPATH='../data/'  # must end in \"/\"\n",
        "    sys.path.append(\"..\") # append parent dir in order to use sibling dirs\n",
        "    from SimTools.RNA_describe import *\n",
        "    from SimTools.GenCodeTools import *\n",
        "    from SimTools.plot_generator import *\n",
        "    from SimTools.KmerTools import KmerTools\n",
        "\n",
        "MODELPATH=\"BestModel\"  # saved on cloud instance and lost after logout\n",
        "#MODELPATH=DATAPATH+MODELPATH  # saved on Google Drive but requires login\n",
        "\n",
        "if not assert_imported_RNA_describe():\n",
        "    print(\"ERROR: Cannot use RNA_describe.\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "On Google CoLab, mount cloud-local file, get our code from GitHub.\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8RNNlZGsZN5"
      },
      "source": [
        "## Load GENCODE Data\n",
        "Loads GENCODE v38 data.\n",
        "\n",
        "Filters out mRNA sequences based on UTR check."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37JnfHgWt_-U",
        "outputId": "296d71cd-a46a-4244-cbd3-233bf34ef597"
      },
      "source": [
        "PC_FILENAME='gencode.v38.pc_transcripts.fa.gz'\n",
        "NC_FILENAME='gencode.v38.lncRNA_transcripts.fa.gz'\n",
        "PC_FULLPATH=DATAPATH+PC_FILENAME\n",
        "NC_FULLPATH=DATAPATH+NC_FILENAME\n",
        "loader=GenCodeLoader()\n",
        "loader.set_label(1)\n",
        "loader.set_check_list(None) \n",
        "loader.set_check_utr(True)\n",
        "pcdf=loader.load_file(PC_FULLPATH)\n",
        "print(\"PC seqs loaded:\",len(pcdf))\n",
        "loader.set_label(0)\n",
        "loader.set_check_list(None)\n",
        "loader.set_check_utr(False)\n",
        "ncdf=loader.load_file(NC_FULLPATH)\n",
        "print(\"NC seqs loaded:\",len(ncdf))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PC seqs loaded: 70825\n",
            "NC seqs loaded: 48752\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0y1XAPLvr_G"
      },
      "source": [
        "## Process Sequences\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "si3kGF7kTZ3M"
      },
      "source": [
        "Generate Sample of GENCODE Data Set\n",
        "\n",
        "Apply Length Constraints\n",
        "\n",
        "Validate Sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6V7WMCLN3l1q"
      },
      "source": [
        "APPLY_SUBSET = True             #Option to subset the data\n",
        "MINIMUM_SEQUENCE_LENGTH = 200   #Minimum exclusive length to filter out sequences by\n",
        "MAXIMUM_SEQUENCE_LENGTH = 4000  #Maximum inclusive length to filter out sequences by\n",
        "SAMPLE_FRACTION = 1             #What fraction of the GenCode data set to take a sample of\n",
        "REPRODUCABILITY_SEED = 314159   #Use to reproduce random sampling"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANtZknso53FT",
        "outputId": "1da6ca18-60b0-40ec-d93c-3a817021b8ab"
      },
      "source": [
        "if APPLY_SUBSET:\n",
        "    pcdf = pcdf.sample(frac=SAMPLE_FRACTION, random_state=REPRODUCABILITY_SEED)\n",
        "    ncdf = ncdf.sample(frac=SAMPLE_FRACTION, random_state=REPRODUCABILITY_SEED)\n",
        "\n",
        "    print('PC sample size:', len(pcdf))\n",
        "    print('NC sample size:', len(ncdf))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PC sample size: 70825\n",
            "NC sample size: 48752\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xe5boK2NTWH1"
      },
      "source": [
        "Apply Length Constraints"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ga4K3Aw4sJd"
      },
      "source": [
        "def subset_list_by_len_bounds(input_list, min_len, max_len):\n",
        "  return list(filter(lambda x: len(x) > min_len and len(x) <= max_len, input_list))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7pejW0g1lnR",
        "outputId": "65cd84e2-e624-490e-f48e-e7a1699f5305"
      },
      "source": [
        "pc_sequences = pcdf['sequence'].tolist()\n",
        "nc_sequences = ncdf['sequence'].tolist()\n",
        "\n",
        "if APPLY_SUBSET:\n",
        "    pc_sequences = subset_list_by_len_bounds(pc_sequences, MINIMUM_SEQUENCE_LENGTH, MAXIMUM_SEQUENCE_LENGTH)\n",
        "    nc_sequences = subset_list_by_len_bounds(nc_sequences, MINIMUM_SEQUENCE_LENGTH, MAXIMUM_SEQUENCE_LENGTH)\n",
        "\n",
        "    print('PC seqs in length range','('+str(MINIMUM_SEQUENCE_LENGTH),'-',str(MAXIMUM_SEQUENCE_LENGTH)+'):', len(pc_sequences))\n",
        "    print('NC seqs in length range','('+str(MINIMUM_SEQUENCE_LENGTH),'-',str(MAXIMUM_SEQUENCE_LENGTH)+'):', len(nc_sequences))\n",
        "\n",
        "#Garbage collection\n",
        "pcdf = None\n",
        "ncdf = None"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PC seqs in length range (200 - 4000): 55381\n",
            "NC seqs in length range (200 - 4000): 46912\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlFZ2BHDS_kJ"
      },
      "source": [
        "Validate Sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYBUZyfxSRZs",
        "outputId": "45b54e64-cc87-4449-b087-f1c52352ed8f"
      },
      "source": [
        "def valid_sequence(seq):\n",
        "    \"\"\"\n",
        "    Checks if the given sequences if valid.\n",
        "    \"\"\"\n",
        "    for chr in seq:\n",
        "        if not (chr == 'A' or chr == 'C' or chr == 'G' or chr == 'T'):\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "def validate_sequences(sequences):\n",
        "    \"\"\"\n",
        "    Validate the given list of sequences\n",
        "    \"\"\"\n",
        "    i = 0\n",
        "    while i < len(sequences):\n",
        "        if valid_sequence(sequences[i]):\n",
        "            i += 1\n",
        "        else:\n",
        "            sequences.remove(sequences[i])\n",
        "\n",
        "validate_sequences(pc_sequences)\n",
        "validate_sequences(nc_sequences)\n",
        "\n",
        "print('Valid PC seqs:', len(pc_sequences))\n",
        "print('Valid NC seqs:', len(nc_sequences))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Valid PC seqs: 55381\n",
            "Valid NC seqs: 46911\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVWspW8e4v2b"
      },
      "source": [
        "## Set Up MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNxOORWM41Xi"
      },
      "source": [
        "RATIO_TRAIN_TO_TEST = 0.99\n",
        "INPUT_SHAPE = (None, 4**3 + 4**2 + 4**1)\n",
        "MAX_K = 3\n",
        "NEURONS = 16\n",
        "DROP_RATE = 0.1\n",
        "EPOCHS = 1000\n",
        "SPLITS = 5\n",
        "FOLDS = 1"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nf_MTH3a63ZA"
      },
      "source": [
        "Define what is training data and what is testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2mKPv1B5oIR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbef14c9-64eb-4994-9bc3-569011ab4f33"
      },
      "source": [
        "NUM_PC = len(pc_sequences)\n",
        "NUM_PC_TRAIN = int(NUM_PC * RATIO_TRAIN_TO_TEST)\n",
        "NUM_NC = len(nc_sequences)\n",
        "NUM_NC_TRAIN = int(NUM_NC * RATIO_TRAIN_TO_TEST)\n",
        "\n",
        "pc_train = pc_sequences[:NUM_PC_TRAIN]\n",
        "pc_test = pc_sequences[NUM_PC_TRAIN:]\n",
        "nc_train = nc_sequences[:NUM_NC_TRAIN]\n",
        "nc_test = nc_sequences[NUM_NC_TRAIN:]\n",
        "\n",
        "print('PC TRAIN:', len(pc_train))\n",
        "print('NC TRAIN', len(nc_train))\n",
        "print('PC TEST:', len(pc_test))\n",
        "print('NC TEST:', len(nc_test))\n",
        "\n",
        "#Garbage Collection (this makes re-running the MLP a pain)\n",
        "#pc_sequences = None\n",
        "#nc_sequences = None"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PC TRAIN: 54827\n",
            "NC TRAIN 46441\n",
            "PC TEST: 554\n",
            "NC TEST: 470\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DOlou8Z7XU_"
      },
      "source": [
        "Prepare the Inputs and the Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MVxtNEc69NO"
      },
      "source": [
        "def prepare_x_and_y(seqs1, seqs0):\n",
        "    \"\"\"\n",
        "    From Miller's MLP_GenCode_1??.\n",
        "    \"\"\"\n",
        "    len1=len(seqs1)\n",
        "    len0=len(seqs0)\n",
        "    total=len1+len0\n",
        "    L1=np.ones(len1,dtype=np.int8)\n",
        "    L0=np.zeros(len0,dtype=np.int8)\n",
        "    S1 = np.asarray(seqs1)\n",
        "    S0 = np.asarray(seqs0)\n",
        "    all_labels = np.concatenate((L1,L0))\n",
        "    all_seqs = np.concatenate((S1,S0))  \n",
        "    for i in range(0,len0):\n",
        "        all_labels[i*2] = L0[i]\n",
        "        all_seqs[i*2] = S0[i]\n",
        "        all_labels[i*2+1] = L1[i]\n",
        "        all_seqs[i*2+1] = S1[i]\n",
        "    return all_seqs,all_labels\n",
        "Xseq, y = prepare_x_and_y(pc_train, nc_train)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g46xCFPZ7xqF"
      },
      "source": [
        "def seqs_to_kmer_freqs(seqs, max_K):\n",
        "    \"\"\"\n",
        "    From Miller's MLP_GenCode_1??.\n",
        "    \"\"\"\n",
        "    tool = KmerTools()  # from SimTools\n",
        "    collection = []\n",
        "    for seq in seqs:\n",
        "        counts = tool.make_dict_upto_K(max_K)\n",
        "        # Last param should be True when using Harvester.\n",
        "        counts = tool.update_count_one_K(counts, max_K, seq, True)\n",
        "        # Given counts for K=3, Harvester fills in counts for K=1,2.\n",
        "        counts = tool.harvest_counts_from_K(counts, max_K)\n",
        "        fdict = tool.count_to_frequency(counts, max_K)\n",
        "        freqs = list(fdict.values())\n",
        "        collection.append(freqs)\n",
        "    return np.asarray(collection)\n",
        "\n",
        "Xfrq = seqs_to_kmer_freqs(Xseq, MAX_K)\n",
        "\n",
        "#Garbage Collection\n",
        "Xseq = None"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TS9xAqP8ClN"
      },
      "source": [
        "## Make and Train MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFI-Jwgc8Gv4",
        "outputId": "823eba20-99fe-4e5d-9507-2c286c7e60cf"
      },
      "source": [
        "def make_DNN():\n",
        "    \"\"\"\n",
        "    From Miller's MLP_GenCode_1??.\n",
        "    \"\"\"\n",
        "    dt=np.float32\n",
        "    print(\"make_DNN\")\n",
        "    print(\"input shape:\",INPUT_SHAPE)\n",
        "    dnn = Sequential()\n",
        "\n",
        "    dnn.add(Dense(NEURONS, activation=\"sigmoid\", dtype=dt))  # relu doesn't work as well\n",
        "    dnn.add(Dropout(DROP_RATE))\n",
        "\n",
        "    dnn.add(Dense(NEURONS, activation=\"sigmoid\", dtype=dt)) \n",
        "    dnn.add(Dropout(DROP_RATE))\n",
        "\n",
        "    dnn.add(Dense(NEURONS, activation=\"sigmoid\", dtype=dt))  # relu doesn't work as well\n",
        "    dnn.add(Dropout(DROP_RATE))\n",
        "\n",
        "    dnn.add(Dense(NEURONS, activation=\"sigmoid\", dtype=dt)) \n",
        "    dnn.add(Dropout(DROP_RATE))\n",
        "\n",
        "    dnn.add(Dense(1, activation=\"sigmoid\", dtype=dt))  \n",
        "\n",
        "    dnn.compile(optimizer='adam',    # adadelta doesn't work as well\n",
        "        loss=BinaryCrossentropy(from_logits=False),\n",
        "        metrics=['accuracy'])   # add to default metrics=loss\n",
        "    dnn.build(input_shape=INPUT_SHAPE) \n",
        "    return dnn\n",
        "model = make_DNN()\n",
        "print(model.summary())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "make_DNN\n",
            "input shape: (None, 84)\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 16)                1360      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 2,193\n",
            "Trainable params: 2,193\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIEUYjE18dQT"
      },
      "source": [
        "def do_cross_validation(X,y):\n",
        "    \"\"\"\n",
        "    From Miller's MLP_GenCode_1??.\n",
        "    \"\"\"\n",
        "    cv_scores = []\n",
        "    fold=0\n",
        "    #mycallbacks = [ModelCheckpoint(\n",
        "    #    filepath=MODELPATH, save_best_only=True, \n",
        "    #    monitor='val_accuracy', mode='max')]   \n",
        "    # When shuffle=True, the valid indices are a random subset.\n",
        "    splitter = KFold(n_splits=SPLITS, shuffle=True) \n",
        "    model = None\n",
        "    for train_index, valid_index in splitter.split(X):\n",
        "        if fold < FOLDS:\n",
        "            fold += 1\n",
        "            X_train=X[train_index] # inputs for training\n",
        "            y_train=y[train_index] # labels for training\n",
        "            X_valid=X[valid_index] # inputs for validation\n",
        "            y_valid=y[valid_index] # labels for validation\n",
        "            print(\"MODEL\")\n",
        "            # Call constructor on each CV. Else, continually improves the same model.\n",
        "            model = model = make_DNN()\n",
        "            print(\"FIT\")  # model.fit() implements learning\n",
        "            start_time=time.time()\n",
        "            history=model.fit(X_train, y_train, \n",
        "                epochs=EPOCHS, \n",
        "                verbose=1,  # ascii art while learning\n",
        "                # callbacks=mycallbacks,   # called at end of each epoch\n",
        "                validation_data=(X_valid,y_valid))\n",
        "            end_time=time.time()\n",
        "            elapsed_time=(end_time-start_time)                        \n",
        "            print(\"Fold %d, %d epochs, %d sec\"%(fold,EPOCHS,elapsed_time))\n",
        "            # print(history.history.keys())  # all these keys will be shown in figure\n",
        "            pd.DataFrame(history.history).plot(figsize=(8,5))\n",
        "            plt.grid(True)\n",
        "            plt.gca().set_ylim(0,1) # any losses > 1 will be off the scale\n",
        "            plt.show()\n",
        "    return model  # parameters at end of training"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6on9fVhr8ux_",
        "outputId": "04cbeda7-4755-43d4-f617-cd31c515e046"
      },
      "source": [
        "last_model = do_cross_validation(Xfrq, y)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MODEL\n",
            "make_DNN\n",
            "input shape: (None, 84)\n",
            "FIT\n",
            "Epoch 1/1000\n",
            "2532/2532 [==============================] - 21s 2ms/step - loss: 0.7015 - accuracy: 0.5215 - val_loss: 0.6311 - val_accuracy: 0.6550\n",
            "Epoch 2/1000\n",
            "2532/2532 [==============================] - 4s 2ms/step - loss: 0.6334 - accuracy: 0.6543 - val_loss: 0.6197 - val_accuracy: 0.6698\n",
            "Epoch 3/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.6210 - accuracy: 0.6672 - val_loss: 0.6048 - val_accuracy: 0.6795\n",
            "Epoch 4/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.6117 - accuracy: 0.6758 - val_loss: 0.5778 - val_accuracy: 0.7051\n",
            "Epoch 5/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5901 - accuracy: 0.6945 - val_loss: 0.5516 - val_accuracy: 0.7282\n",
            "Epoch 6/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5792 - accuracy: 0.7042 - val_loss: 0.5418 - val_accuracy: 0.7374\n",
            "Epoch 7/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5655 - accuracy: 0.7167 - val_loss: 0.5364 - val_accuracy: 0.7400\n",
            "Epoch 8/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5608 - accuracy: 0.7199 - val_loss: 0.5306 - val_accuracy: 0.7443\n",
            "Epoch 9/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5569 - accuracy: 0.7213 - val_loss: 0.5275 - val_accuracy: 0.7467\n",
            "Epoch 10/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5511 - accuracy: 0.7265 - val_loss: 0.5241 - val_accuracy: 0.7477\n",
            "Epoch 11/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5471 - accuracy: 0.7314 - val_loss: 0.5199 - val_accuracy: 0.7532\n",
            "Epoch 12/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5436 - accuracy: 0.7322 - val_loss: 0.5159 - val_accuracy: 0.7560\n",
            "Epoch 13/1000\n",
            "2532/2532 [==============================] - 4s 2ms/step - loss: 0.5397 - accuracy: 0.7350 - val_loss: 0.5171 - val_accuracy: 0.7553\n",
            "Epoch 14/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5416 - accuracy: 0.7354 - val_loss: 0.5153 - val_accuracy: 0.7602\n",
            "Epoch 15/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5365 - accuracy: 0.7375 - val_loss: 0.5093 - val_accuracy: 0.7593\n",
            "Epoch 16/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5330 - accuracy: 0.7431 - val_loss: 0.5090 - val_accuracy: 0.7634\n",
            "Epoch 17/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5293 - accuracy: 0.7437 - val_loss: 0.5069 - val_accuracy: 0.7636\n",
            "Epoch 18/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5291 - accuracy: 0.7428 - val_loss: 0.5031 - val_accuracy: 0.7633\n",
            "Epoch 19/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5265 - accuracy: 0.7463 - val_loss: 0.5018 - val_accuracy: 0.7671\n",
            "Epoch 20/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5247 - accuracy: 0.7460 - val_loss: 0.4980 - val_accuracy: 0.7697\n",
            "Epoch 21/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5258 - accuracy: 0.7455 - val_loss: 0.4979 - val_accuracy: 0.7703\n",
            "Epoch 22/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5234 - accuracy: 0.7489 - val_loss: 0.4953 - val_accuracy: 0.7712\n",
            "Epoch 23/1000\n",
            "2532/2532 [==============================] - 4s 2ms/step - loss: 0.5181 - accuracy: 0.7526 - val_loss: 0.4942 - val_accuracy: 0.7700\n",
            "Epoch 24/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5165 - accuracy: 0.7518 - val_loss: 0.4930 - val_accuracy: 0.7709\n",
            "Epoch 25/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5179 - accuracy: 0.7512 - val_loss: 0.4925 - val_accuracy: 0.7732\n",
            "Epoch 26/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5161 - accuracy: 0.7543 - val_loss: 0.4908 - val_accuracy: 0.7715\n",
            "Epoch 27/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5121 - accuracy: 0.7570 - val_loss: 0.4918 - val_accuracy: 0.7724\n",
            "Epoch 28/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5165 - accuracy: 0.7535 - val_loss: 0.4890 - val_accuracy: 0.7752\n",
            "Epoch 29/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5140 - accuracy: 0.7556 - val_loss: 0.4891 - val_accuracy: 0.7755\n",
            "Epoch 30/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5150 - accuracy: 0.7519 - val_loss: 0.4866 - val_accuracy: 0.7755\n",
            "Epoch 31/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5111 - accuracy: 0.7569 - val_loss: 0.4831 - val_accuracy: 0.7774\n",
            "Epoch 32/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5090 - accuracy: 0.7587 - val_loss: 0.4813 - val_accuracy: 0.7783\n",
            "Epoch 33/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5086 - accuracy: 0.7584 - val_loss: 0.4839 - val_accuracy: 0.7772\n",
            "Epoch 34/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5065 - accuracy: 0.7597 - val_loss: 0.4816 - val_accuracy: 0.7795\n",
            "Epoch 35/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5039 - accuracy: 0.7615 - val_loss: 0.4789 - val_accuracy: 0.7796\n",
            "Epoch 36/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5024 - accuracy: 0.7626 - val_loss: 0.4783 - val_accuracy: 0.7798\n",
            "Epoch 37/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5076 - accuracy: 0.7603 - val_loss: 0.4776 - val_accuracy: 0.7817\n",
            "Epoch 38/1000\n",
            "2532/2532 [==============================] - 4s 2ms/step - loss: 0.5021 - accuracy: 0.7630 - val_loss: 0.4779 - val_accuracy: 0.7818\n",
            "Epoch 39/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5006 - accuracy: 0.7623 - val_loss: 0.4770 - val_accuracy: 0.7778\n",
            "Epoch 40/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5010 - accuracy: 0.7612 - val_loss: 0.4759 - val_accuracy: 0.7815\n",
            "Epoch 41/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5020 - accuracy: 0.7625 - val_loss: 0.4743 - val_accuracy: 0.7813\n",
            "Epoch 42/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4984 - accuracy: 0.7643 - val_loss: 0.4756 - val_accuracy: 0.7788\n",
            "Epoch 43/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4963 - accuracy: 0.7646 - val_loss: 0.4725 - val_accuracy: 0.7827\n",
            "Epoch 44/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4976 - accuracy: 0.7645 - val_loss: 0.4711 - val_accuracy: 0.7839\n",
            "Epoch 45/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4957 - accuracy: 0.7671 - val_loss: 0.4735 - val_accuracy: 0.7797\n",
            "Epoch 46/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4964 - accuracy: 0.7658 - val_loss: 0.4706 - val_accuracy: 0.7843\n",
            "Epoch 47/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4945 - accuracy: 0.7661 - val_loss: 0.4704 - val_accuracy: 0.7822\n",
            "Epoch 48/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4961 - accuracy: 0.7656 - val_loss: 0.4690 - val_accuracy: 0.7833\n",
            "Epoch 49/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4947 - accuracy: 0.7657 - val_loss: 0.4677 - val_accuracy: 0.7850\n",
            "Epoch 50/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4919 - accuracy: 0.7673 - val_loss: 0.4679 - val_accuracy: 0.7847\n",
            "Epoch 51/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4896 - accuracy: 0.7694 - val_loss: 0.4660 - val_accuracy: 0.7866\n",
            "Epoch 52/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4894 - accuracy: 0.7677 - val_loss: 0.4662 - val_accuracy: 0.7858\n",
            "Epoch 53/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4911 - accuracy: 0.7660 - val_loss: 0.4647 - val_accuracy: 0.7866\n",
            "Epoch 54/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4922 - accuracy: 0.7661 - val_loss: 0.4633 - val_accuracy: 0.7862\n",
            "Epoch 55/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4862 - accuracy: 0.7708 - val_loss: 0.4627 - val_accuracy: 0.7868\n",
            "Epoch 56/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4872 - accuracy: 0.7713 - val_loss: 0.4629 - val_accuracy: 0.7872\n",
            "Epoch 57/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4860 - accuracy: 0.7692 - val_loss: 0.4611 - val_accuracy: 0.7870\n",
            "Epoch 58/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4833 - accuracy: 0.7702 - val_loss: 0.4599 - val_accuracy: 0.7880\n",
            "Epoch 59/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4851 - accuracy: 0.7691 - val_loss: 0.4579 - val_accuracy: 0.7882\n",
            "Epoch 60/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4812 - accuracy: 0.7724 - val_loss: 0.4583 - val_accuracy: 0.7886\n",
            "Epoch 61/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4818 - accuracy: 0.7716 - val_loss: 0.4577 - val_accuracy: 0.7879\n",
            "Epoch 62/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4775 - accuracy: 0.7750 - val_loss: 0.4567 - val_accuracy: 0.7884\n",
            "Epoch 63/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4801 - accuracy: 0.7742 - val_loss: 0.4548 - val_accuracy: 0.7898\n",
            "Epoch 64/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4797 - accuracy: 0.7727 - val_loss: 0.4557 - val_accuracy: 0.7909\n",
            "Epoch 65/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4764 - accuracy: 0.7759 - val_loss: 0.4535 - val_accuracy: 0.7918\n",
            "Epoch 66/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4816 - accuracy: 0.7714 - val_loss: 0.4518 - val_accuracy: 0.7921\n",
            "Epoch 67/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4777 - accuracy: 0.7756 - val_loss: 0.4524 - val_accuracy: 0.7916\n",
            "Epoch 68/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4774 - accuracy: 0.7748 - val_loss: 0.4504 - val_accuracy: 0.7937\n",
            "Epoch 69/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4777 - accuracy: 0.7735 - val_loss: 0.4480 - val_accuracy: 0.7944\n",
            "Epoch 70/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4741 - accuracy: 0.7760 - val_loss: 0.4468 - val_accuracy: 0.7953\n",
            "Epoch 71/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4711 - accuracy: 0.7790 - val_loss: 0.4464 - val_accuracy: 0.7953\n",
            "Epoch 72/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4774 - accuracy: 0.7769 - val_loss: 0.4446 - val_accuracy: 0.7986\n",
            "Epoch 73/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4708 - accuracy: 0.7768 - val_loss: 0.4450 - val_accuracy: 0.7991\n",
            "Epoch 74/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4675 - accuracy: 0.7814 - val_loss: 0.4423 - val_accuracy: 0.8006\n",
            "Epoch 75/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4704 - accuracy: 0.7808 - val_loss: 0.4425 - val_accuracy: 0.7992\n",
            "Epoch 76/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4678 - accuracy: 0.7806 - val_loss: 0.4406 - val_accuracy: 0.8028\n",
            "Epoch 77/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4711 - accuracy: 0.7784 - val_loss: 0.4405 - val_accuracy: 0.8021\n",
            "Epoch 78/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4687 - accuracy: 0.7815 - val_loss: 0.4399 - val_accuracy: 0.8025\n",
            "Epoch 79/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4672 - accuracy: 0.7821 - val_loss: 0.4377 - val_accuracy: 0.8031\n",
            "Epoch 80/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4639 - accuracy: 0.7842 - val_loss: 0.4377 - val_accuracy: 0.8033\n",
            "Epoch 81/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4685 - accuracy: 0.7798 - val_loss: 0.4374 - val_accuracy: 0.8049\n",
            "Epoch 82/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4616 - accuracy: 0.7879 - val_loss: 0.4371 - val_accuracy: 0.8065\n",
            "Epoch 83/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4621 - accuracy: 0.7839 - val_loss: 0.4351 - val_accuracy: 0.8052\n",
            "Epoch 84/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4610 - accuracy: 0.7863 - val_loss: 0.4353 - val_accuracy: 0.8056\n",
            "Epoch 85/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4633 - accuracy: 0.7836 - val_loss: 0.4342 - val_accuracy: 0.8060\n",
            "Epoch 86/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4640 - accuracy: 0.7861 - val_loss: 0.4340 - val_accuracy: 0.8066\n",
            "Epoch 87/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4627 - accuracy: 0.7846 - val_loss: 0.4335 - val_accuracy: 0.8075\n",
            "Epoch 88/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4592 - accuracy: 0.7873 - val_loss: 0.4326 - val_accuracy: 0.8082\n",
            "Epoch 89/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4609 - accuracy: 0.7851 - val_loss: 0.4319 - val_accuracy: 0.8077\n",
            "Epoch 90/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4613 - accuracy: 0.7857 - val_loss: 0.4330 - val_accuracy: 0.8064\n",
            "Epoch 91/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4565 - accuracy: 0.7894 - val_loss: 0.4302 - val_accuracy: 0.8091\n",
            "Epoch 92/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4573 - accuracy: 0.7877 - val_loss: 0.4325 - val_accuracy: 0.8079\n",
            "Epoch 93/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4587 - accuracy: 0.7893 - val_loss: 0.4296 - val_accuracy: 0.8092\n",
            "Epoch 94/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4548 - accuracy: 0.7928 - val_loss: 0.4291 - val_accuracy: 0.8096\n",
            "Epoch 95/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4552 - accuracy: 0.7902 - val_loss: 0.4286 - val_accuracy: 0.8097\n",
            "Epoch 96/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4559 - accuracy: 0.7886 - val_loss: 0.4291 - val_accuracy: 0.8089\n",
            "Epoch 97/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4543 - accuracy: 0.7900 - val_loss: 0.4281 - val_accuracy: 0.8109\n",
            "Epoch 98/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4511 - accuracy: 0.7912 - val_loss: 0.4275 - val_accuracy: 0.8100\n",
            "Epoch 99/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4502 - accuracy: 0.7919 - val_loss: 0.4283 - val_accuracy: 0.8111\n",
            "Epoch 100/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4514 - accuracy: 0.7930 - val_loss: 0.4282 - val_accuracy: 0.8083\n",
            "Epoch 101/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4535 - accuracy: 0.7914 - val_loss: 0.4267 - val_accuracy: 0.8101\n",
            "Epoch 102/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4535 - accuracy: 0.7916 - val_loss: 0.4260 - val_accuracy: 0.8118\n",
            "Epoch 103/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4564 - accuracy: 0.7897 - val_loss: 0.4261 - val_accuracy: 0.8106\n",
            "Epoch 104/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4484 - accuracy: 0.7939 - val_loss: 0.4258 - val_accuracy: 0.8117\n",
            "Epoch 105/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4521 - accuracy: 0.7934 - val_loss: 0.4249 - val_accuracy: 0.8115\n",
            "Epoch 106/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4523 - accuracy: 0.7910 - val_loss: 0.4251 - val_accuracy: 0.8103\n",
            "Epoch 107/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4512 - accuracy: 0.7919 - val_loss: 0.4249 - val_accuracy: 0.8107\n",
            "Epoch 108/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4496 - accuracy: 0.7932 - val_loss: 0.4266 - val_accuracy: 0.8090\n",
            "Epoch 109/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4502 - accuracy: 0.7932 - val_loss: 0.4252 - val_accuracy: 0.8110\n",
            "Epoch 110/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4465 - accuracy: 0.7946 - val_loss: 0.4243 - val_accuracy: 0.8117\n",
            "Epoch 111/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4479 - accuracy: 0.7941 - val_loss: 0.4236 - val_accuracy: 0.8122\n",
            "Epoch 112/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4465 - accuracy: 0.7957 - val_loss: 0.4230 - val_accuracy: 0.8121\n",
            "Epoch 113/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4491 - accuracy: 0.7942 - val_loss: 0.4220 - val_accuracy: 0.8128\n",
            "Epoch 114/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4469 - accuracy: 0.7968 - val_loss: 0.4222 - val_accuracy: 0.8134\n",
            "Epoch 115/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4455 - accuracy: 0.7963 - val_loss: 0.4223 - val_accuracy: 0.8132\n",
            "Epoch 116/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4491 - accuracy: 0.7953 - val_loss: 0.4211 - val_accuracy: 0.8128\n",
            "Epoch 117/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4481 - accuracy: 0.7958 - val_loss: 0.4222 - val_accuracy: 0.8133\n",
            "Epoch 118/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4475 - accuracy: 0.7961 - val_loss: 0.4225 - val_accuracy: 0.8129\n",
            "Epoch 119/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4456 - accuracy: 0.7970 - val_loss: 0.4217 - val_accuracy: 0.8140\n",
            "Epoch 120/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4445 - accuracy: 0.7977 - val_loss: 0.4211 - val_accuracy: 0.8128\n",
            "Epoch 121/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4457 - accuracy: 0.7963 - val_loss: 0.4211 - val_accuracy: 0.8134\n",
            "Epoch 122/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4452 - accuracy: 0.7961 - val_loss: 0.4206 - val_accuracy: 0.8131\n",
            "Epoch 123/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4467 - accuracy: 0.7955 - val_loss: 0.4199 - val_accuracy: 0.8137\n",
            "Epoch 124/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4459 - accuracy: 0.7964 - val_loss: 0.4189 - val_accuracy: 0.8143\n",
            "Epoch 125/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4420 - accuracy: 0.7986 - val_loss: 0.4199 - val_accuracy: 0.8130\n",
            "Epoch 126/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4429 - accuracy: 0.7972 - val_loss: 0.4195 - val_accuracy: 0.8145\n",
            "Epoch 127/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4442 - accuracy: 0.7980 - val_loss: 0.4195 - val_accuracy: 0.8140\n",
            "Epoch 128/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4440 - accuracy: 0.7975 - val_loss: 0.4187 - val_accuracy: 0.8150\n",
            "Epoch 129/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4417 - accuracy: 0.7988 - val_loss: 0.4189 - val_accuracy: 0.8144\n",
            "Epoch 130/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4406 - accuracy: 0.7992 - val_loss: 0.4191 - val_accuracy: 0.8148\n",
            "Epoch 131/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4397 - accuracy: 0.8006 - val_loss: 0.4184 - val_accuracy: 0.8144\n",
            "Epoch 132/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4409 - accuracy: 0.7991 - val_loss: 0.4187 - val_accuracy: 0.8139\n",
            "Epoch 133/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4410 - accuracy: 0.7979 - val_loss: 0.4177 - val_accuracy: 0.8139\n",
            "Epoch 134/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4434 - accuracy: 0.7988 - val_loss: 0.4180 - val_accuracy: 0.8142\n",
            "Epoch 135/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4420 - accuracy: 0.7998 - val_loss: 0.4168 - val_accuracy: 0.8150\n",
            "Epoch 136/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4393 - accuracy: 0.7989 - val_loss: 0.4171 - val_accuracy: 0.8141\n",
            "Epoch 137/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4372 - accuracy: 0.8012 - val_loss: 0.4179 - val_accuracy: 0.8142\n",
            "Epoch 138/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4342 - accuracy: 0.8037 - val_loss: 0.4177 - val_accuracy: 0.8139\n",
            "Epoch 139/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4386 - accuracy: 0.7991 - val_loss: 0.4175 - val_accuracy: 0.8156\n",
            "Epoch 140/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4385 - accuracy: 0.8005 - val_loss: 0.4156 - val_accuracy: 0.8159\n",
            "Epoch 141/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4373 - accuracy: 0.8003 - val_loss: 0.4164 - val_accuracy: 0.8150\n",
            "Epoch 142/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4404 - accuracy: 0.7999 - val_loss: 0.4164 - val_accuracy: 0.8142\n",
            "Epoch 143/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4364 - accuracy: 0.8020 - val_loss: 0.4160 - val_accuracy: 0.8158\n",
            "Epoch 144/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4369 - accuracy: 0.8017 - val_loss: 0.4152 - val_accuracy: 0.8163\n",
            "Epoch 145/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4369 - accuracy: 0.8016 - val_loss: 0.4165 - val_accuracy: 0.8161\n",
            "Epoch 146/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4376 - accuracy: 0.8012 - val_loss: 0.4161 - val_accuracy: 0.8150\n",
            "Epoch 147/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4402 - accuracy: 0.7996 - val_loss: 0.4143 - val_accuracy: 0.8167\n",
            "Epoch 148/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4352 - accuracy: 0.8030 - val_loss: 0.4155 - val_accuracy: 0.8167\n",
            "Epoch 149/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4328 - accuracy: 0.8047 - val_loss: 0.4159 - val_accuracy: 0.8157\n",
            "Epoch 150/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4357 - accuracy: 0.8029 - val_loss: 0.4167 - val_accuracy: 0.8132\n",
            "Epoch 151/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4336 - accuracy: 0.8043 - val_loss: 0.4144 - val_accuracy: 0.8160\n",
            "Epoch 152/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4400 - accuracy: 0.8002 - val_loss: 0.4137 - val_accuracy: 0.8164\n",
            "Epoch 153/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4376 - accuracy: 0.8003 - val_loss: 0.4136 - val_accuracy: 0.8174\n",
            "Epoch 154/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4367 - accuracy: 0.8013 - val_loss: 0.4136 - val_accuracy: 0.8172\n",
            "Epoch 155/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4321 - accuracy: 0.8057 - val_loss: 0.4141 - val_accuracy: 0.8168\n",
            "Epoch 156/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4354 - accuracy: 0.8029 - val_loss: 0.4137 - val_accuracy: 0.8151\n",
            "Epoch 157/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4324 - accuracy: 0.8059 - val_loss: 0.4124 - val_accuracy: 0.8166\n",
            "Epoch 158/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4339 - accuracy: 0.8051 - val_loss: 0.4134 - val_accuracy: 0.8172\n",
            "Epoch 159/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4337 - accuracy: 0.8044 - val_loss: 0.4135 - val_accuracy: 0.8158\n",
            "Epoch 160/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4345 - accuracy: 0.8040 - val_loss: 0.4134 - val_accuracy: 0.8165\n",
            "Epoch 161/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4379 - accuracy: 0.8007 - val_loss: 0.4117 - val_accuracy: 0.8165\n",
            "Epoch 162/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4356 - accuracy: 0.8030 - val_loss: 0.4116 - val_accuracy: 0.8171\n",
            "Epoch 163/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4340 - accuracy: 0.8043 - val_loss: 0.4123 - val_accuracy: 0.8180\n",
            "Epoch 164/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4341 - accuracy: 0.8028 - val_loss: 0.4114 - val_accuracy: 0.8183\n",
            "Epoch 165/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4334 - accuracy: 0.8047 - val_loss: 0.4112 - val_accuracy: 0.8181\n",
            "Epoch 166/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4280 - accuracy: 0.8073 - val_loss: 0.4126 - val_accuracy: 0.8163\n",
            "Epoch 167/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4306 - accuracy: 0.8053 - val_loss: 0.4121 - val_accuracy: 0.8182\n",
            "Epoch 168/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4289 - accuracy: 0.8057 - val_loss: 0.4108 - val_accuracy: 0.8178\n",
            "Epoch 169/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4279 - accuracy: 0.8046 - val_loss: 0.4113 - val_accuracy: 0.8181\n",
            "Epoch 170/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4326 - accuracy: 0.8046 - val_loss: 0.4141 - val_accuracy: 0.8158\n",
            "Epoch 171/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4306 - accuracy: 0.8053 - val_loss: 0.4114 - val_accuracy: 0.8171\n",
            "Epoch 172/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4345 - accuracy: 0.8034 - val_loss: 0.4096 - val_accuracy: 0.8189\n",
            "Epoch 173/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4318 - accuracy: 0.8064 - val_loss: 0.4096 - val_accuracy: 0.8190\n",
            "Epoch 174/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4337 - accuracy: 0.8037 - val_loss: 0.4100 - val_accuracy: 0.8192\n",
            "Epoch 175/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4283 - accuracy: 0.8071 - val_loss: 0.4117 - val_accuracy: 0.8175\n",
            "Epoch 176/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4296 - accuracy: 0.8069 - val_loss: 0.4089 - val_accuracy: 0.8186\n",
            "Epoch 177/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4290 - accuracy: 0.8061 - val_loss: 0.4088 - val_accuracy: 0.8200\n",
            "Epoch 178/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4274 - accuracy: 0.8083 - val_loss: 0.4084 - val_accuracy: 0.8201\n",
            "Epoch 179/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4312 - accuracy: 0.8053 - val_loss: 0.4092 - val_accuracy: 0.8174\n",
            "Epoch 180/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4306 - accuracy: 0.8031 - val_loss: 0.4089 - val_accuracy: 0.8204\n",
            "Epoch 181/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4262 - accuracy: 0.8077 - val_loss: 0.4095 - val_accuracy: 0.8192\n",
            "Epoch 182/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4289 - accuracy: 0.8071 - val_loss: 0.4084 - val_accuracy: 0.8194\n",
            "Epoch 183/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4322 - accuracy: 0.8031 - val_loss: 0.4093 - val_accuracy: 0.8190\n",
            "Epoch 184/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4279 - accuracy: 0.8071 - val_loss: 0.4090 - val_accuracy: 0.8182\n",
            "Epoch 185/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4251 - accuracy: 0.8092 - val_loss: 0.4071 - val_accuracy: 0.8204\n",
            "Epoch 186/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4306 - accuracy: 0.8049 - val_loss: 0.4066 - val_accuracy: 0.8200\n",
            "Epoch 187/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4268 - accuracy: 0.8076 - val_loss: 0.4069 - val_accuracy: 0.8207\n",
            "Epoch 188/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4273 - accuracy: 0.8076 - val_loss: 0.4065 - val_accuracy: 0.8209\n",
            "Epoch 189/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4236 - accuracy: 0.8103 - val_loss: 0.4069 - val_accuracy: 0.8212\n",
            "Epoch 190/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4225 - accuracy: 0.8123 - val_loss: 0.4067 - val_accuracy: 0.8201\n",
            "Epoch 191/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4288 - accuracy: 0.8075 - val_loss: 0.4064 - val_accuracy: 0.8208\n",
            "Epoch 192/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4309 - accuracy: 0.8070 - val_loss: 0.4057 - val_accuracy: 0.8192\n",
            "Epoch 193/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4234 - accuracy: 0.8115 - val_loss: 0.4053 - val_accuracy: 0.8216\n",
            "Epoch 194/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4276 - accuracy: 0.8075 - val_loss: 0.4060 - val_accuracy: 0.8205\n",
            "Epoch 195/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4247 - accuracy: 0.8098 - val_loss: 0.4055 - val_accuracy: 0.8206\n",
            "Epoch 196/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4231 - accuracy: 0.8109 - val_loss: 0.4052 - val_accuracy: 0.8209\n",
            "Epoch 197/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4265 - accuracy: 0.8101 - val_loss: 0.4051 - val_accuracy: 0.8204\n",
            "Epoch 198/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4250 - accuracy: 0.8090 - val_loss: 0.4042 - val_accuracy: 0.8214\n",
            "Epoch 199/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4261 - accuracy: 0.8098 - val_loss: 0.4068 - val_accuracy: 0.8207\n",
            "Epoch 200/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4218 - accuracy: 0.8119 - val_loss: 0.4058 - val_accuracy: 0.8226\n",
            "Epoch 201/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4227 - accuracy: 0.8100 - val_loss: 0.4056 - val_accuracy: 0.8209\n",
            "Epoch 202/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4221 - accuracy: 0.8109 - val_loss: 0.4047 - val_accuracy: 0.8215\n",
            "Epoch 203/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4213 - accuracy: 0.8123 - val_loss: 0.4032 - val_accuracy: 0.8234\n",
            "Epoch 204/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4224 - accuracy: 0.8113 - val_loss: 0.4045 - val_accuracy: 0.8214\n",
            "Epoch 205/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4248 - accuracy: 0.8104 - val_loss: 0.4048 - val_accuracy: 0.8208\n",
            "Epoch 206/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4207 - accuracy: 0.8108 - val_loss: 0.4038 - val_accuracy: 0.8219\n",
            "Epoch 207/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4242 - accuracy: 0.8085 - val_loss: 0.4046 - val_accuracy: 0.8222\n",
            "Epoch 208/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4199 - accuracy: 0.8122 - val_loss: 0.4026 - val_accuracy: 0.8227\n",
            "Epoch 209/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4240 - accuracy: 0.8110 - val_loss: 0.4020 - val_accuracy: 0.8227\n",
            "Epoch 210/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4232 - accuracy: 0.8122 - val_loss: 0.4043 - val_accuracy: 0.8231\n",
            "Epoch 211/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4202 - accuracy: 0.8121 - val_loss: 0.4033 - val_accuracy: 0.8214\n",
            "Epoch 212/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4223 - accuracy: 0.8125 - val_loss: 0.4039 - val_accuracy: 0.8202\n",
            "Epoch 213/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4230 - accuracy: 0.8100 - val_loss: 0.4016 - val_accuracy: 0.8229\n",
            "Epoch 214/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4228 - accuracy: 0.8124 - val_loss: 0.4028 - val_accuracy: 0.8244\n",
            "Epoch 215/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4198 - accuracy: 0.8128 - val_loss: 0.4020 - val_accuracy: 0.8231\n",
            "Epoch 216/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4202 - accuracy: 0.8137 - val_loss: 0.4014 - val_accuracy: 0.8245\n",
            "Epoch 217/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4173 - accuracy: 0.8140 - val_loss: 0.4018 - val_accuracy: 0.8241\n",
            "Epoch 218/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4187 - accuracy: 0.8138 - val_loss: 0.4013 - val_accuracy: 0.8252\n",
            "Epoch 219/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4223 - accuracy: 0.8115 - val_loss: 0.4003 - val_accuracy: 0.8240\n",
            "Epoch 220/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4184 - accuracy: 0.8140 - val_loss: 0.4008 - val_accuracy: 0.8244\n",
            "Epoch 221/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4208 - accuracy: 0.8116 - val_loss: 0.4005 - val_accuracy: 0.8255\n",
            "Epoch 222/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4167 - accuracy: 0.8142 - val_loss: 0.4020 - val_accuracy: 0.8231\n",
            "Epoch 223/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4166 - accuracy: 0.8165 - val_loss: 0.4006 - val_accuracy: 0.8239\n",
            "Epoch 224/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4184 - accuracy: 0.8140 - val_loss: 0.3999 - val_accuracy: 0.8243\n",
            "Epoch 225/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4220 - accuracy: 0.8119 - val_loss: 0.4009 - val_accuracy: 0.8235\n",
            "Epoch 226/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4123 - accuracy: 0.8173 - val_loss: 0.4012 - val_accuracy: 0.8247\n",
            "Epoch 227/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4215 - accuracy: 0.8122 - val_loss: 0.3997 - val_accuracy: 0.8239\n",
            "Epoch 228/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4215 - accuracy: 0.8127 - val_loss: 0.4002 - val_accuracy: 0.8228\n",
            "Epoch 229/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4187 - accuracy: 0.8151 - val_loss: 0.3994 - val_accuracy: 0.8246\n",
            "Epoch 230/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4209 - accuracy: 0.8108 - val_loss: 0.4002 - val_accuracy: 0.8244\n",
            "Epoch 231/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4174 - accuracy: 0.8150 - val_loss: 0.4014 - val_accuracy: 0.8242\n",
            "Epoch 232/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4171 - accuracy: 0.8142 - val_loss: 0.4007 - val_accuracy: 0.8230\n",
            "Epoch 233/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4221 - accuracy: 0.8128 - val_loss: 0.3999 - val_accuracy: 0.8231\n",
            "Epoch 234/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4173 - accuracy: 0.8144 - val_loss: 0.4034 - val_accuracy: 0.8225\n",
            "Epoch 235/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4168 - accuracy: 0.8154 - val_loss: 0.4011 - val_accuracy: 0.8238\n",
            "Epoch 236/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4189 - accuracy: 0.8137 - val_loss: 0.3987 - val_accuracy: 0.8238\n",
            "Epoch 237/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4126 - accuracy: 0.8173 - val_loss: 0.3989 - val_accuracy: 0.8238\n",
            "Epoch 238/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4161 - accuracy: 0.8155 - val_loss: 0.3981 - val_accuracy: 0.8250\n",
            "Epoch 239/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4199 - accuracy: 0.8126 - val_loss: 0.3991 - val_accuracy: 0.8244\n",
            "Epoch 240/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4165 - accuracy: 0.8153 - val_loss: 0.3983 - val_accuracy: 0.8251\n",
            "Epoch 241/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4186 - accuracy: 0.8156 - val_loss: 0.3983 - val_accuracy: 0.8241\n",
            "Epoch 242/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4153 - accuracy: 0.8159 - val_loss: 0.3994 - val_accuracy: 0.8241\n",
            "Epoch 243/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4144 - accuracy: 0.8162 - val_loss: 0.3977 - val_accuracy: 0.8258\n",
            "Epoch 244/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4150 - accuracy: 0.8163 - val_loss: 0.4002 - val_accuracy: 0.8232\n",
            "Epoch 245/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4166 - accuracy: 0.8149 - val_loss: 0.3985 - val_accuracy: 0.8262\n",
            "Epoch 246/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4155 - accuracy: 0.8161 - val_loss: 0.3977 - val_accuracy: 0.8247\n",
            "Epoch 247/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4166 - accuracy: 0.8150 - val_loss: 0.3982 - val_accuracy: 0.8253\n",
            "Epoch 248/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4143 - accuracy: 0.8169 - val_loss: 0.3981 - val_accuracy: 0.8238\n",
            "Epoch 249/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4155 - accuracy: 0.8151 - val_loss: 0.3996 - val_accuracy: 0.8220\n",
            "Epoch 250/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4175 - accuracy: 0.8137 - val_loss: 0.4001 - val_accuracy: 0.8229\n",
            "Epoch 251/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4141 - accuracy: 0.8153 - val_loss: 0.3970 - val_accuracy: 0.8261\n",
            "Epoch 252/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4142 - accuracy: 0.8158 - val_loss: 0.3982 - val_accuracy: 0.8247\n",
            "Epoch 253/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4115 - accuracy: 0.8195 - val_loss: 0.3972 - val_accuracy: 0.8280\n",
            "Epoch 254/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4139 - accuracy: 0.8157 - val_loss: 0.3995 - val_accuracy: 0.8236\n",
            "Epoch 255/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4149 - accuracy: 0.8188 - val_loss: 0.3967 - val_accuracy: 0.8255\n",
            "Epoch 256/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4103 - accuracy: 0.8180 - val_loss: 0.3976 - val_accuracy: 0.8252\n",
            "Epoch 257/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4110 - accuracy: 0.8186 - val_loss: 0.3962 - val_accuracy: 0.8273\n",
            "Epoch 258/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4133 - accuracy: 0.8162 - val_loss: 0.3976 - val_accuracy: 0.8236\n",
            "Epoch 259/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4145 - accuracy: 0.8164 - val_loss: 0.3971 - val_accuracy: 0.8249\n",
            "Epoch 260/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4108 - accuracy: 0.8191 - val_loss: 0.3967 - val_accuracy: 0.8259\n",
            "Epoch 261/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4141 - accuracy: 0.8163 - val_loss: 0.3967 - val_accuracy: 0.8266\n",
            "Epoch 262/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4131 - accuracy: 0.8157 - val_loss: 0.3962 - val_accuracy: 0.8277\n",
            "Epoch 263/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4105 - accuracy: 0.8184 - val_loss: 0.3974 - val_accuracy: 0.8251\n",
            "Epoch 264/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4160 - accuracy: 0.8172 - val_loss: 0.4022 - val_accuracy: 0.8219\n",
            "Epoch 265/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4168 - accuracy: 0.8175 - val_loss: 0.3953 - val_accuracy: 0.8275\n",
            "Epoch 266/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4104 - accuracy: 0.8188 - val_loss: 0.3982 - val_accuracy: 0.8234\n",
            "Epoch 267/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4150 - accuracy: 0.8162 - val_loss: 0.3978 - val_accuracy: 0.8234\n",
            "Epoch 268/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4141 - accuracy: 0.8156 - val_loss: 0.3961 - val_accuracy: 0.8251\n",
            "Epoch 269/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4127 - accuracy: 0.8168 - val_loss: 0.3971 - val_accuracy: 0.8248\n",
            "Epoch 270/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4087 - accuracy: 0.8221 - val_loss: 0.3962 - val_accuracy: 0.8261\n",
            "Epoch 271/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4145 - accuracy: 0.8178 - val_loss: 0.3957 - val_accuracy: 0.8252\n",
            "Epoch 272/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4119 - accuracy: 0.8183 - val_loss: 0.3973 - val_accuracy: 0.8237\n",
            "Epoch 273/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4130 - accuracy: 0.8194 - val_loss: 0.3948 - val_accuracy: 0.8277\n",
            "Epoch 274/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4114 - accuracy: 0.8201 - val_loss: 0.3953 - val_accuracy: 0.8269\n",
            "Epoch 275/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4133 - accuracy: 0.8186 - val_loss: 0.3942 - val_accuracy: 0.8301\n",
            "Epoch 276/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4142 - accuracy: 0.8165 - val_loss: 0.3948 - val_accuracy: 0.8277\n",
            "Epoch 277/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4140 - accuracy: 0.8177 - val_loss: 0.3949 - val_accuracy: 0.8261\n",
            "Epoch 278/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4119 - accuracy: 0.8181 - val_loss: 0.3948 - val_accuracy: 0.8269\n",
            "Epoch 279/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4121 - accuracy: 0.8191 - val_loss: 0.3958 - val_accuracy: 0.8260\n",
            "Epoch 280/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4100 - accuracy: 0.8193 - val_loss: 0.3949 - val_accuracy: 0.8267\n",
            "Epoch 281/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4129 - accuracy: 0.8181 - val_loss: 0.3953 - val_accuracy: 0.8258\n",
            "Epoch 282/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4101 - accuracy: 0.8188 - val_loss: 0.3947 - val_accuracy: 0.8263\n",
            "Epoch 283/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4103 - accuracy: 0.8178 - val_loss: 0.3973 - val_accuracy: 0.8254\n",
            "Epoch 284/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4086 - accuracy: 0.8193 - val_loss: 0.3950 - val_accuracy: 0.8262\n",
            "Epoch 285/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4074 - accuracy: 0.8198 - val_loss: 0.3965 - val_accuracy: 0.8256\n",
            "Epoch 286/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4123 - accuracy: 0.8181 - val_loss: 0.3957 - val_accuracy: 0.8249\n",
            "Epoch 287/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4084 - accuracy: 0.8202 - val_loss: 0.3948 - val_accuracy: 0.8266\n",
            "Epoch 288/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4108 - accuracy: 0.8202 - val_loss: 0.3955 - val_accuracy: 0.8265\n",
            "Epoch 289/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4136 - accuracy: 0.8184 - val_loss: 0.3950 - val_accuracy: 0.8251\n",
            "Epoch 290/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4069 - accuracy: 0.8222 - val_loss: 0.3962 - val_accuracy: 0.8263\n",
            "Epoch 291/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4130 - accuracy: 0.8180 - val_loss: 0.3930 - val_accuracy: 0.8286\n",
            "Epoch 292/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4071 - accuracy: 0.8210 - val_loss: 0.3934 - val_accuracy: 0.8275\n",
            "Epoch 293/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4075 - accuracy: 0.8212 - val_loss: 0.3976 - val_accuracy: 0.8239\n",
            "Epoch 294/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4112 - accuracy: 0.8195 - val_loss: 0.3946 - val_accuracy: 0.8258\n",
            "Epoch 295/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4072 - accuracy: 0.8218 - val_loss: 0.3958 - val_accuracy: 0.8264\n",
            "Epoch 296/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4101 - accuracy: 0.8183 - val_loss: 0.3947 - val_accuracy: 0.8268\n",
            "Epoch 297/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4068 - accuracy: 0.8219 - val_loss: 0.3935 - val_accuracy: 0.8306\n",
            "Epoch 298/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4106 - accuracy: 0.8194 - val_loss: 0.3920 - val_accuracy: 0.8299\n",
            "Epoch 299/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4077 - accuracy: 0.8213 - val_loss: 0.3928 - val_accuracy: 0.8296\n",
            "Epoch 300/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4104 - accuracy: 0.8184 - val_loss: 0.3931 - val_accuracy: 0.8285\n",
            "Epoch 301/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4088 - accuracy: 0.8198 - val_loss: 0.3927 - val_accuracy: 0.8286\n",
            "Epoch 302/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4068 - accuracy: 0.8216 - val_loss: 0.3946 - val_accuracy: 0.8259\n",
            "Epoch 303/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4075 - accuracy: 0.8220 - val_loss: 0.3923 - val_accuracy: 0.8301\n",
            "Epoch 304/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4096 - accuracy: 0.8201 - val_loss: 0.3987 - val_accuracy: 0.8234\n",
            "Epoch 305/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4084 - accuracy: 0.8181 - val_loss: 0.3934 - val_accuracy: 0.8272\n",
            "Epoch 306/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4046 - accuracy: 0.8219 - val_loss: 0.3933 - val_accuracy: 0.8276\n",
            "Epoch 307/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4063 - accuracy: 0.8216 - val_loss: 0.3929 - val_accuracy: 0.8277\n",
            "Epoch 308/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4100 - accuracy: 0.8208 - val_loss: 0.3934 - val_accuracy: 0.8280\n",
            "Epoch 309/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4094 - accuracy: 0.8217 - val_loss: 0.3916 - val_accuracy: 0.8303\n",
            "Epoch 310/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4035 - accuracy: 0.8232 - val_loss: 0.3927 - val_accuracy: 0.8278\n",
            "Epoch 311/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4033 - accuracy: 0.8226 - val_loss: 0.3942 - val_accuracy: 0.8267\n",
            "Epoch 312/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4056 - accuracy: 0.8216 - val_loss: 0.3924 - val_accuracy: 0.8288\n",
            "Epoch 313/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4040 - accuracy: 0.8231 - val_loss: 0.3929 - val_accuracy: 0.8282\n",
            "Epoch 314/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4055 - accuracy: 0.8226 - val_loss: 0.3922 - val_accuracy: 0.8289\n",
            "Epoch 315/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4063 - accuracy: 0.8219 - val_loss: 0.3961 - val_accuracy: 0.8254\n",
            "Epoch 316/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4023 - accuracy: 0.8247 - val_loss: 0.3919 - val_accuracy: 0.8287\n",
            "Epoch 317/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4045 - accuracy: 0.8240 - val_loss: 0.3913 - val_accuracy: 0.8297\n",
            "Epoch 318/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4058 - accuracy: 0.8228 - val_loss: 0.3930 - val_accuracy: 0.8267\n",
            "Epoch 319/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4020 - accuracy: 0.8239 - val_loss: 0.3913 - val_accuracy: 0.8304\n",
            "Epoch 320/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4068 - accuracy: 0.8213 - val_loss: 0.3926 - val_accuracy: 0.8279\n",
            "Epoch 321/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4066 - accuracy: 0.8205 - val_loss: 0.3911 - val_accuracy: 0.8299\n",
            "Epoch 322/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4043 - accuracy: 0.8234 - val_loss: 0.3931 - val_accuracy: 0.8273\n",
            "Epoch 323/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4049 - accuracy: 0.8229 - val_loss: 0.3906 - val_accuracy: 0.8320\n",
            "Epoch 324/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4054 - accuracy: 0.8225 - val_loss: 0.3935 - val_accuracy: 0.8282\n",
            "Epoch 325/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4065 - accuracy: 0.8201 - val_loss: 0.3904 - val_accuracy: 0.8298\n",
            "Epoch 326/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4049 - accuracy: 0.8239 - val_loss: 0.3930 - val_accuracy: 0.8273\n",
            "Epoch 327/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4037 - accuracy: 0.8222 - val_loss: 0.3952 - val_accuracy: 0.8256\n",
            "Epoch 328/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4071 - accuracy: 0.8213 - val_loss: 0.3908 - val_accuracy: 0.8287\n",
            "Epoch 329/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4012 - accuracy: 0.8237 - val_loss: 0.3908 - val_accuracy: 0.8286\n",
            "Epoch 330/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4040 - accuracy: 0.8225 - val_loss: 0.3916 - val_accuracy: 0.8274\n",
            "Epoch 331/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4075 - accuracy: 0.8215 - val_loss: 0.3904 - val_accuracy: 0.8299\n",
            "Epoch 332/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4029 - accuracy: 0.8228 - val_loss: 0.3899 - val_accuracy: 0.8300\n",
            "Epoch 333/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4031 - accuracy: 0.8231 - val_loss: 0.3905 - val_accuracy: 0.8313\n",
            "Epoch 334/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4038 - accuracy: 0.8244 - val_loss: 0.3896 - val_accuracy: 0.8322\n",
            "Epoch 335/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4021 - accuracy: 0.8238 - val_loss: 0.3931 - val_accuracy: 0.8271\n",
            "Epoch 336/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4042 - accuracy: 0.8243 - val_loss: 0.3889 - val_accuracy: 0.8317\n",
            "Epoch 337/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4026 - accuracy: 0.8247 - val_loss: 0.3936 - val_accuracy: 0.8263\n",
            "Epoch 338/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4048 - accuracy: 0.8231 - val_loss: 0.3908 - val_accuracy: 0.8280\n",
            "Epoch 339/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4023 - accuracy: 0.8242 - val_loss: 0.3916 - val_accuracy: 0.8297\n",
            "Epoch 340/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4040 - accuracy: 0.8242 - val_loss: 0.3902 - val_accuracy: 0.8298\n",
            "Epoch 341/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3977 - accuracy: 0.8255 - val_loss: 0.3905 - val_accuracy: 0.8297\n",
            "Epoch 342/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4038 - accuracy: 0.8231 - val_loss: 0.3897 - val_accuracy: 0.8292\n",
            "Epoch 343/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4087 - accuracy: 0.8214 - val_loss: 0.3882 - val_accuracy: 0.8312\n",
            "Epoch 344/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4043 - accuracy: 0.8237 - val_loss: 0.3900 - val_accuracy: 0.8289\n",
            "Epoch 345/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4005 - accuracy: 0.8253 - val_loss: 0.3889 - val_accuracy: 0.8310\n",
            "Epoch 346/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4031 - accuracy: 0.8250 - val_loss: 0.3890 - val_accuracy: 0.8301\n",
            "Epoch 347/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4043 - accuracy: 0.8235 - val_loss: 0.3905 - val_accuracy: 0.8292\n",
            "Epoch 348/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4048 - accuracy: 0.8223 - val_loss: 0.3889 - val_accuracy: 0.8299\n",
            "Epoch 349/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4002 - accuracy: 0.8278 - val_loss: 0.3890 - val_accuracy: 0.8292\n",
            "Epoch 350/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4028 - accuracy: 0.8234 - val_loss: 0.3894 - val_accuracy: 0.8303\n",
            "Epoch 351/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4026 - accuracy: 0.8231 - val_loss: 0.3895 - val_accuracy: 0.8296\n",
            "Epoch 352/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4022 - accuracy: 0.8255 - val_loss: 0.3879 - val_accuracy: 0.8322\n",
            "Epoch 353/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4031 - accuracy: 0.8226 - val_loss: 0.3896 - val_accuracy: 0.8291\n",
            "Epoch 354/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4033 - accuracy: 0.8223 - val_loss: 0.3914 - val_accuracy: 0.8277\n",
            "Epoch 355/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4038 - accuracy: 0.8233 - val_loss: 0.3896 - val_accuracy: 0.8299\n",
            "Epoch 356/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4041 - accuracy: 0.8220 - val_loss: 0.3888 - val_accuracy: 0.8287\n",
            "Epoch 357/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4024 - accuracy: 0.8240 - val_loss: 0.3886 - val_accuracy: 0.8311\n",
            "Epoch 358/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4027 - accuracy: 0.8259 - val_loss: 0.3876 - val_accuracy: 0.8325\n",
            "Epoch 359/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3999 - accuracy: 0.8237 - val_loss: 0.3876 - val_accuracy: 0.8312\n",
            "Epoch 360/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4017 - accuracy: 0.8250 - val_loss: 0.3874 - val_accuracy: 0.8320\n",
            "Epoch 361/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4001 - accuracy: 0.8258 - val_loss: 0.3877 - val_accuracy: 0.8316\n",
            "Epoch 362/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3981 - accuracy: 0.8267 - val_loss: 0.3910 - val_accuracy: 0.8280\n",
            "Epoch 363/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4053 - accuracy: 0.8227 - val_loss: 0.3886 - val_accuracy: 0.8291\n",
            "Epoch 364/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4010 - accuracy: 0.8245 - val_loss: 0.3878 - val_accuracy: 0.8309\n",
            "Epoch 365/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4006 - accuracy: 0.8243 - val_loss: 0.3874 - val_accuracy: 0.8318\n",
            "Epoch 366/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4035 - accuracy: 0.8226 - val_loss: 0.3864 - val_accuracy: 0.8330\n",
            "Epoch 367/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3993 - accuracy: 0.8257 - val_loss: 0.3914 - val_accuracy: 0.8283\n",
            "Epoch 368/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4019 - accuracy: 0.8252 - val_loss: 0.3877 - val_accuracy: 0.8320\n",
            "Epoch 369/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4026 - accuracy: 0.8240 - val_loss: 0.3883 - val_accuracy: 0.8314\n",
            "Epoch 370/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4028 - accuracy: 0.8249 - val_loss: 0.3860 - val_accuracy: 0.8329\n",
            "Epoch 371/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3990 - accuracy: 0.8267 - val_loss: 0.3860 - val_accuracy: 0.8330\n",
            "Epoch 372/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4032 - accuracy: 0.8238 - val_loss: 0.3880 - val_accuracy: 0.8306\n",
            "Epoch 373/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3963 - accuracy: 0.8281 - val_loss: 0.3899 - val_accuracy: 0.8283\n",
            "Epoch 374/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3954 - accuracy: 0.8282 - val_loss: 0.3877 - val_accuracy: 0.8324\n",
            "Epoch 375/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4009 - accuracy: 0.8260 - val_loss: 0.3883 - val_accuracy: 0.8307\n",
            "Epoch 376/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4050 - accuracy: 0.8234 - val_loss: 0.3871 - val_accuracy: 0.8316\n",
            "Epoch 377/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3980 - accuracy: 0.8272 - val_loss: 0.3886 - val_accuracy: 0.8301\n",
            "Epoch 378/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4009 - accuracy: 0.8251 - val_loss: 0.3868 - val_accuracy: 0.8318\n",
            "Epoch 379/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3971 - accuracy: 0.8271 - val_loss: 0.3872 - val_accuracy: 0.8325\n",
            "Epoch 380/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3984 - accuracy: 0.8264 - val_loss: 0.3852 - val_accuracy: 0.8329\n",
            "Epoch 381/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4020 - accuracy: 0.8247 - val_loss: 0.3891 - val_accuracy: 0.8286\n",
            "Epoch 382/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3999 - accuracy: 0.8265 - val_loss: 0.3866 - val_accuracy: 0.8327\n",
            "Epoch 383/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4028 - accuracy: 0.8243 - val_loss: 0.3888 - val_accuracy: 0.8289\n",
            "Epoch 384/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4010 - accuracy: 0.8253 - val_loss: 0.3869 - val_accuracy: 0.8317\n",
            "Epoch 385/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3983 - accuracy: 0.8258 - val_loss: 0.3882 - val_accuracy: 0.8307\n",
            "Epoch 386/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4013 - accuracy: 0.8247 - val_loss: 0.3859 - val_accuracy: 0.8326\n",
            "Epoch 387/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3996 - accuracy: 0.8252 - val_loss: 0.3883 - val_accuracy: 0.8298\n",
            "Epoch 388/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4002 - accuracy: 0.8247 - val_loss: 0.3850 - val_accuracy: 0.8329\n",
            "Epoch 389/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3969 - accuracy: 0.8283 - val_loss: 0.3857 - val_accuracy: 0.8314\n",
            "Epoch 390/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3988 - accuracy: 0.8266 - val_loss: 0.3861 - val_accuracy: 0.8320\n",
            "Epoch 391/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3992 - accuracy: 0.8248 - val_loss: 0.3869 - val_accuracy: 0.8313\n",
            "Epoch 392/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3982 - accuracy: 0.8248 - val_loss: 0.3901 - val_accuracy: 0.8280\n",
            "Epoch 393/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3987 - accuracy: 0.8254 - val_loss: 0.3857 - val_accuracy: 0.8322\n",
            "Epoch 394/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3985 - accuracy: 0.8273 - val_loss: 0.3869 - val_accuracy: 0.8322\n",
            "Epoch 395/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3963 - accuracy: 0.8275 - val_loss: 0.3889 - val_accuracy: 0.8291\n",
            "Epoch 396/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3972 - accuracy: 0.8276 - val_loss: 0.3852 - val_accuracy: 0.8325\n",
            "Epoch 397/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3992 - accuracy: 0.8265 - val_loss: 0.3865 - val_accuracy: 0.8302\n",
            "Epoch 398/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.4011 - accuracy: 0.8242 - val_loss: 0.3860 - val_accuracy: 0.8311\n",
            "Epoch 399/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3939 - accuracy: 0.8293 - val_loss: 0.3866 - val_accuracy: 0.8313\n",
            "Epoch 400/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3983 - accuracy: 0.8276 - val_loss: 0.3848 - val_accuracy: 0.8309\n",
            "Epoch 401/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3951 - accuracy: 0.8282 - val_loss: 0.3866 - val_accuracy: 0.8307\n",
            "Epoch 402/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4013 - accuracy: 0.8221 - val_loss: 0.3853 - val_accuracy: 0.8323\n",
            "Epoch 403/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4005 - accuracy: 0.8259 - val_loss: 0.3865 - val_accuracy: 0.8301\n",
            "Epoch 404/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3968 - accuracy: 0.8280 - val_loss: 0.3862 - val_accuracy: 0.8315\n",
            "Epoch 405/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4017 - accuracy: 0.8225 - val_loss: 0.3842 - val_accuracy: 0.8330\n",
            "Epoch 406/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3979 - accuracy: 0.8256 - val_loss: 0.3863 - val_accuracy: 0.8314\n",
            "Epoch 407/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3949 - accuracy: 0.8292 - val_loss: 0.3850 - val_accuracy: 0.8320\n",
            "Epoch 408/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4001 - accuracy: 0.8250 - val_loss: 0.3855 - val_accuracy: 0.8312\n",
            "Epoch 409/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3992 - accuracy: 0.8270 - val_loss: 0.3877 - val_accuracy: 0.8305\n",
            "Epoch 410/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.4000 - accuracy: 0.8257 - val_loss: 0.3841 - val_accuracy: 0.8321\n",
            "Epoch 411/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3984 - accuracy: 0.8278 - val_loss: 0.3870 - val_accuracy: 0.8311\n",
            "Epoch 412/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3959 - accuracy: 0.8269 - val_loss: 0.3851 - val_accuracy: 0.8321\n",
            "Epoch 413/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3940 - accuracy: 0.8275 - val_loss: 0.3891 - val_accuracy: 0.8292\n",
            "Epoch 414/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3985 - accuracy: 0.8270 - val_loss: 0.3867 - val_accuracy: 0.8296\n",
            "Epoch 415/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3957 - accuracy: 0.8287 - val_loss: 0.3853 - val_accuracy: 0.8312\n",
            "Epoch 416/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3954 - accuracy: 0.8281 - val_loss: 0.3864 - val_accuracy: 0.8304\n",
            "Epoch 417/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3942 - accuracy: 0.8283 - val_loss: 0.3859 - val_accuracy: 0.8305\n",
            "Epoch 418/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3920 - accuracy: 0.8292 - val_loss: 0.3872 - val_accuracy: 0.8295\n",
            "Epoch 419/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3946 - accuracy: 0.8288 - val_loss: 0.3854 - val_accuracy: 0.8314\n",
            "Epoch 420/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3952 - accuracy: 0.8287 - val_loss: 0.3861 - val_accuracy: 0.8306\n",
            "Epoch 421/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3970 - accuracy: 0.8266 - val_loss: 0.3841 - val_accuracy: 0.8332\n",
            "Epoch 422/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3967 - accuracy: 0.8276 - val_loss: 0.3845 - val_accuracy: 0.8321\n",
            "Epoch 423/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3969 - accuracy: 0.8265 - val_loss: 0.3873 - val_accuracy: 0.8297\n",
            "Epoch 424/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3958 - accuracy: 0.8274 - val_loss: 0.3877 - val_accuracy: 0.8300\n",
            "Epoch 425/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3958 - accuracy: 0.8292 - val_loss: 0.3836 - val_accuracy: 0.8329\n",
            "Epoch 426/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3968 - accuracy: 0.8293 - val_loss: 0.3852 - val_accuracy: 0.8314\n",
            "Epoch 427/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3962 - accuracy: 0.8289 - val_loss: 0.3837 - val_accuracy: 0.8332\n",
            "Epoch 428/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3965 - accuracy: 0.8274 - val_loss: 0.3832 - val_accuracy: 0.8327\n",
            "Epoch 429/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3967 - accuracy: 0.8271 - val_loss: 0.3841 - val_accuracy: 0.8315\n",
            "Epoch 430/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3944 - accuracy: 0.8283 - val_loss: 0.3834 - val_accuracy: 0.8318\n",
            "Epoch 431/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3950 - accuracy: 0.8297 - val_loss: 0.3866 - val_accuracy: 0.8294\n",
            "Epoch 432/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3913 - accuracy: 0.8317 - val_loss: 0.3844 - val_accuracy: 0.8316\n",
            "Epoch 433/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3949 - accuracy: 0.8282 - val_loss: 0.3844 - val_accuracy: 0.8317\n",
            "Epoch 434/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3954 - accuracy: 0.8303 - val_loss: 0.3829 - val_accuracy: 0.8337\n",
            "Epoch 435/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3929 - accuracy: 0.8296 - val_loss: 0.3847 - val_accuracy: 0.8319\n",
            "Epoch 436/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3924 - accuracy: 0.8294 - val_loss: 0.3841 - val_accuracy: 0.8317\n",
            "Epoch 437/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3956 - accuracy: 0.8266 - val_loss: 0.3856 - val_accuracy: 0.8311\n",
            "Epoch 438/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3985 - accuracy: 0.8272 - val_loss: 0.3829 - val_accuracy: 0.8339\n",
            "Epoch 439/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3949 - accuracy: 0.8305 - val_loss: 0.3859 - val_accuracy: 0.8310\n",
            "Epoch 440/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3965 - accuracy: 0.8287 - val_loss: 0.3829 - val_accuracy: 0.8341\n",
            "Epoch 441/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3990 - accuracy: 0.8275 - val_loss: 0.3846 - val_accuracy: 0.8320\n",
            "Epoch 442/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3956 - accuracy: 0.8282 - val_loss: 0.3830 - val_accuracy: 0.8341\n",
            "Epoch 443/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3940 - accuracy: 0.8282 - val_loss: 0.3857 - val_accuracy: 0.8315\n",
            "Epoch 444/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3949 - accuracy: 0.8278 - val_loss: 0.3835 - val_accuracy: 0.8316\n",
            "Epoch 445/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3943 - accuracy: 0.8275 - val_loss: 0.3816 - val_accuracy: 0.8361\n",
            "Epoch 446/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3983 - accuracy: 0.8253 - val_loss: 0.3842 - val_accuracy: 0.8308\n",
            "Epoch 447/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3922 - accuracy: 0.8302 - val_loss: 0.3821 - val_accuracy: 0.8342\n",
            "Epoch 448/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3930 - accuracy: 0.8287 - val_loss: 0.3835 - val_accuracy: 0.8328\n",
            "Epoch 449/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3923 - accuracy: 0.8299 - val_loss: 0.3834 - val_accuracy: 0.8325\n",
            "Epoch 450/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3956 - accuracy: 0.8295 - val_loss: 0.3828 - val_accuracy: 0.8325\n",
            "Epoch 451/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3995 - accuracy: 0.8258 - val_loss: 0.3832 - val_accuracy: 0.8322\n",
            "Epoch 452/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3917 - accuracy: 0.8291 - val_loss: 0.3822 - val_accuracy: 0.8336\n",
            "Epoch 453/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3942 - accuracy: 0.8294 - val_loss: 0.3842 - val_accuracy: 0.8326\n",
            "Epoch 454/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3976 - accuracy: 0.8294 - val_loss: 0.3822 - val_accuracy: 0.8329\n",
            "Epoch 455/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3971 - accuracy: 0.8282 - val_loss: 0.3858 - val_accuracy: 0.8313\n",
            "Epoch 456/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3911 - accuracy: 0.8308 - val_loss: 0.3836 - val_accuracy: 0.8318\n",
            "Epoch 457/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3941 - accuracy: 0.8302 - val_loss: 0.3832 - val_accuracy: 0.8328\n",
            "Epoch 458/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3923 - accuracy: 0.8292 - val_loss: 0.3851 - val_accuracy: 0.8313\n",
            "Epoch 459/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3979 - accuracy: 0.8254 - val_loss: 0.3830 - val_accuracy: 0.8322\n",
            "Epoch 460/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3915 - accuracy: 0.8306 - val_loss: 0.3854 - val_accuracy: 0.8307\n",
            "Epoch 461/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3944 - accuracy: 0.8300 - val_loss: 0.3857 - val_accuracy: 0.8299\n",
            "Epoch 462/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3952 - accuracy: 0.8287 - val_loss: 0.3830 - val_accuracy: 0.8330\n",
            "Epoch 463/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3921 - accuracy: 0.8306 - val_loss: 0.3817 - val_accuracy: 0.8341\n",
            "Epoch 464/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3945 - accuracy: 0.8274 - val_loss: 0.3808 - val_accuracy: 0.8352\n",
            "Epoch 465/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3941 - accuracy: 0.8287 - val_loss: 0.3814 - val_accuracy: 0.8338\n",
            "Epoch 466/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3918 - accuracy: 0.8290 - val_loss: 0.3806 - val_accuracy: 0.8356\n",
            "Epoch 467/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3975 - accuracy: 0.8271 - val_loss: 0.3832 - val_accuracy: 0.8326\n",
            "Epoch 468/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3929 - accuracy: 0.8313 - val_loss: 0.3812 - val_accuracy: 0.8338\n",
            "Epoch 469/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3933 - accuracy: 0.8286 - val_loss: 0.3806 - val_accuracy: 0.8354\n",
            "Epoch 470/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3937 - accuracy: 0.8283 - val_loss: 0.3809 - val_accuracy: 0.8336\n",
            "Epoch 471/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3958 - accuracy: 0.8267 - val_loss: 0.3811 - val_accuracy: 0.8338\n",
            "Epoch 472/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3927 - accuracy: 0.8304 - val_loss: 0.3838 - val_accuracy: 0.8326\n",
            "Epoch 473/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3934 - accuracy: 0.8290 - val_loss: 0.3827 - val_accuracy: 0.8318\n",
            "Epoch 474/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3940 - accuracy: 0.8296 - val_loss: 0.3805 - val_accuracy: 0.8354\n",
            "Epoch 475/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3935 - accuracy: 0.8291 - val_loss: 0.3825 - val_accuracy: 0.8328\n",
            "Epoch 476/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3924 - accuracy: 0.8288 - val_loss: 0.3808 - val_accuracy: 0.8342\n",
            "Epoch 477/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3930 - accuracy: 0.8308 - val_loss: 0.3797 - val_accuracy: 0.8347\n",
            "Epoch 478/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3932 - accuracy: 0.8302 - val_loss: 0.3806 - val_accuracy: 0.8338\n",
            "Epoch 479/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3930 - accuracy: 0.8312 - val_loss: 0.3837 - val_accuracy: 0.8328\n",
            "Epoch 480/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3954 - accuracy: 0.8278 - val_loss: 0.3856 - val_accuracy: 0.8307\n",
            "Epoch 481/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3918 - accuracy: 0.8302 - val_loss: 0.3822 - val_accuracy: 0.8331\n",
            "Epoch 482/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3947 - accuracy: 0.8292 - val_loss: 0.3800 - val_accuracy: 0.8338\n",
            "Epoch 483/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3908 - accuracy: 0.8307 - val_loss: 0.3827 - val_accuracy: 0.8332\n",
            "Epoch 484/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3955 - accuracy: 0.8285 - val_loss: 0.3797 - val_accuracy: 0.8347\n",
            "Epoch 485/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3901 - accuracy: 0.8319 - val_loss: 0.3814 - val_accuracy: 0.8338\n",
            "Epoch 486/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3950 - accuracy: 0.8288 - val_loss: 0.3801 - val_accuracy: 0.8347\n",
            "Epoch 487/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3908 - accuracy: 0.8323 - val_loss: 0.3868 - val_accuracy: 0.8309\n",
            "Epoch 488/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3885 - accuracy: 0.8317 - val_loss: 0.3805 - val_accuracy: 0.8346\n",
            "Epoch 489/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3906 - accuracy: 0.8306 - val_loss: 0.3825 - val_accuracy: 0.8328\n",
            "Epoch 490/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3909 - accuracy: 0.8308 - val_loss: 0.3833 - val_accuracy: 0.8326\n",
            "Epoch 491/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3937 - accuracy: 0.8299 - val_loss: 0.3820 - val_accuracy: 0.8335\n",
            "Epoch 492/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3909 - accuracy: 0.8323 - val_loss: 0.3809 - val_accuracy: 0.8340\n",
            "Epoch 493/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3911 - accuracy: 0.8327 - val_loss: 0.3810 - val_accuracy: 0.8337\n",
            "Epoch 494/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3933 - accuracy: 0.8299 - val_loss: 0.3814 - val_accuracy: 0.8334\n",
            "Epoch 495/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3952 - accuracy: 0.8301 - val_loss: 0.3846 - val_accuracy: 0.8319\n",
            "Epoch 496/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3916 - accuracy: 0.8304 - val_loss: 0.3811 - val_accuracy: 0.8333\n",
            "Epoch 497/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3889 - accuracy: 0.8321 - val_loss: 0.3806 - val_accuracy: 0.8337\n",
            "Epoch 498/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3946 - accuracy: 0.8286 - val_loss: 0.3813 - val_accuracy: 0.8332\n",
            "Epoch 499/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3943 - accuracy: 0.8296 - val_loss: 0.3819 - val_accuracy: 0.8335\n",
            "Epoch 500/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3919 - accuracy: 0.8314 - val_loss: 0.3828 - val_accuracy: 0.8332\n",
            "Epoch 501/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3914 - accuracy: 0.8306 - val_loss: 0.3795 - val_accuracy: 0.8344\n",
            "Epoch 502/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3888 - accuracy: 0.8314 - val_loss: 0.3845 - val_accuracy: 0.8315\n",
            "Epoch 503/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3883 - accuracy: 0.8326 - val_loss: 0.3804 - val_accuracy: 0.8353\n",
            "Epoch 504/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3940 - accuracy: 0.8298 - val_loss: 0.3805 - val_accuracy: 0.8334\n",
            "Epoch 505/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3923 - accuracy: 0.8304 - val_loss: 0.3813 - val_accuracy: 0.8335\n",
            "Epoch 506/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3919 - accuracy: 0.8304 - val_loss: 0.3828 - val_accuracy: 0.8326\n",
            "Epoch 507/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3911 - accuracy: 0.8303 - val_loss: 0.3804 - val_accuracy: 0.8339\n",
            "Epoch 508/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3924 - accuracy: 0.8300 - val_loss: 0.3824 - val_accuracy: 0.8328\n",
            "Epoch 509/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3890 - accuracy: 0.8327 - val_loss: 0.3789 - val_accuracy: 0.8347\n",
            "Epoch 510/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3910 - accuracy: 0.8307 - val_loss: 0.3797 - val_accuracy: 0.8349\n",
            "Epoch 511/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3924 - accuracy: 0.8302 - val_loss: 0.3803 - val_accuracy: 0.8332\n",
            "Epoch 512/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3900 - accuracy: 0.8317 - val_loss: 0.3823 - val_accuracy: 0.8318\n",
            "Epoch 513/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3904 - accuracy: 0.8318 - val_loss: 0.3801 - val_accuracy: 0.8337\n",
            "Epoch 514/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3892 - accuracy: 0.8324 - val_loss: 0.3813 - val_accuracy: 0.8330\n",
            "Epoch 515/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3920 - accuracy: 0.8315 - val_loss: 0.3797 - val_accuracy: 0.8345\n",
            "Epoch 516/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3875 - accuracy: 0.8318 - val_loss: 0.3833 - val_accuracy: 0.8320\n",
            "Epoch 517/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3888 - accuracy: 0.8324 - val_loss: 0.3807 - val_accuracy: 0.8335\n",
            "Epoch 518/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3923 - accuracy: 0.8306 - val_loss: 0.3798 - val_accuracy: 0.8345\n",
            "Epoch 519/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3913 - accuracy: 0.8318 - val_loss: 0.3783 - val_accuracy: 0.8352\n",
            "Epoch 520/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3888 - accuracy: 0.8299 - val_loss: 0.3786 - val_accuracy: 0.8341\n",
            "Epoch 521/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3881 - accuracy: 0.8327 - val_loss: 0.3865 - val_accuracy: 0.8307\n",
            "Epoch 522/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3898 - accuracy: 0.8323 - val_loss: 0.3802 - val_accuracy: 0.8331\n",
            "Epoch 523/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3837 - accuracy: 0.8336 - val_loss: 0.3792 - val_accuracy: 0.8338\n",
            "Epoch 524/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3910 - accuracy: 0.8314 - val_loss: 0.3797 - val_accuracy: 0.8344\n",
            "Epoch 525/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3875 - accuracy: 0.8336 - val_loss: 0.3782 - val_accuracy: 0.8350\n",
            "Epoch 526/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3896 - accuracy: 0.8319 - val_loss: 0.3797 - val_accuracy: 0.8359\n",
            "Epoch 527/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3874 - accuracy: 0.8334 - val_loss: 0.3811 - val_accuracy: 0.8334\n",
            "Epoch 528/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3896 - accuracy: 0.8314 - val_loss: 0.3790 - val_accuracy: 0.8353\n",
            "Epoch 529/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3894 - accuracy: 0.8325 - val_loss: 0.3824 - val_accuracy: 0.8319\n",
            "Epoch 530/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3900 - accuracy: 0.8312 - val_loss: 0.3817 - val_accuracy: 0.8335\n",
            "Epoch 531/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3879 - accuracy: 0.8321 - val_loss: 0.3785 - val_accuracy: 0.8365\n",
            "Epoch 532/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3886 - accuracy: 0.8327 - val_loss: 0.3814 - val_accuracy: 0.8328\n",
            "Epoch 533/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3907 - accuracy: 0.8308 - val_loss: 0.3790 - val_accuracy: 0.8352\n",
            "Epoch 534/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3913 - accuracy: 0.8289 - val_loss: 0.3816 - val_accuracy: 0.8341\n",
            "Epoch 535/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3891 - accuracy: 0.8307 - val_loss: 0.3811 - val_accuracy: 0.8335\n",
            "Epoch 536/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3897 - accuracy: 0.8341 - val_loss: 0.3799 - val_accuracy: 0.8339\n",
            "Epoch 537/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3889 - accuracy: 0.8339 - val_loss: 0.3811 - val_accuracy: 0.8334\n",
            "Epoch 538/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3904 - accuracy: 0.8321 - val_loss: 0.3796 - val_accuracy: 0.8345\n",
            "Epoch 539/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3908 - accuracy: 0.8307 - val_loss: 0.3818 - val_accuracy: 0.8330\n",
            "Epoch 540/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3887 - accuracy: 0.8322 - val_loss: 0.3867 - val_accuracy: 0.8292\n",
            "Epoch 541/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3872 - accuracy: 0.8325 - val_loss: 0.3789 - val_accuracy: 0.8348\n",
            "Epoch 542/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3909 - accuracy: 0.8318 - val_loss: 0.3778 - val_accuracy: 0.8355\n",
            "Epoch 543/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3934 - accuracy: 0.8292 - val_loss: 0.3787 - val_accuracy: 0.8347\n",
            "Epoch 544/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3877 - accuracy: 0.8323 - val_loss: 0.3782 - val_accuracy: 0.8339\n",
            "Epoch 545/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3822 - accuracy: 0.8354 - val_loss: 0.3824 - val_accuracy: 0.8329\n",
            "Epoch 546/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3886 - accuracy: 0.8324 - val_loss: 0.3782 - val_accuracy: 0.8356\n",
            "Epoch 547/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3898 - accuracy: 0.8332 - val_loss: 0.3791 - val_accuracy: 0.8354\n",
            "Epoch 548/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3920 - accuracy: 0.8317 - val_loss: 0.3793 - val_accuracy: 0.8345\n",
            "Epoch 549/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3886 - accuracy: 0.8338 - val_loss: 0.3782 - val_accuracy: 0.8358\n",
            "Epoch 550/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3870 - accuracy: 0.8319 - val_loss: 0.3778 - val_accuracy: 0.8355\n",
            "Epoch 551/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3886 - accuracy: 0.8327 - val_loss: 0.3792 - val_accuracy: 0.8341\n",
            "Epoch 552/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3860 - accuracy: 0.8340 - val_loss: 0.3782 - val_accuracy: 0.8357\n",
            "Epoch 553/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3884 - accuracy: 0.8337 - val_loss: 0.3814 - val_accuracy: 0.8345\n",
            "Epoch 554/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3836 - accuracy: 0.8357 - val_loss: 0.3772 - val_accuracy: 0.8364\n",
            "Epoch 555/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3882 - accuracy: 0.8329 - val_loss: 0.3861 - val_accuracy: 0.8307\n",
            "Epoch 556/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3889 - accuracy: 0.8327 - val_loss: 0.3798 - val_accuracy: 0.8344\n",
            "Epoch 557/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3893 - accuracy: 0.8336 - val_loss: 0.3799 - val_accuracy: 0.8341\n",
            "Epoch 558/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3906 - accuracy: 0.8303 - val_loss: 0.3786 - val_accuracy: 0.8354\n",
            "Epoch 559/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3852 - accuracy: 0.8349 - val_loss: 0.3790 - val_accuracy: 0.8345\n",
            "Epoch 560/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3872 - accuracy: 0.8346 - val_loss: 0.3785 - val_accuracy: 0.8355\n",
            "Epoch 561/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3878 - accuracy: 0.8335 - val_loss: 0.3785 - val_accuracy: 0.8333\n",
            "Epoch 562/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3883 - accuracy: 0.8325 - val_loss: 0.3784 - val_accuracy: 0.8343\n",
            "Epoch 563/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3887 - accuracy: 0.8315 - val_loss: 0.3764 - val_accuracy: 0.8363\n",
            "Epoch 564/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3899 - accuracy: 0.8318 - val_loss: 0.3785 - val_accuracy: 0.8345\n",
            "Epoch 565/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3846 - accuracy: 0.8341 - val_loss: 0.3803 - val_accuracy: 0.8338\n",
            "Epoch 566/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3889 - accuracy: 0.8328 - val_loss: 0.3781 - val_accuracy: 0.8352\n",
            "Epoch 567/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3868 - accuracy: 0.8338 - val_loss: 0.3772 - val_accuracy: 0.8364\n",
            "Epoch 568/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3848 - accuracy: 0.8352 - val_loss: 0.3812 - val_accuracy: 0.8347\n",
            "Epoch 569/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3850 - accuracy: 0.8359 - val_loss: 0.3753 - val_accuracy: 0.8375\n",
            "Epoch 570/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3923 - accuracy: 0.8303 - val_loss: 0.3782 - val_accuracy: 0.8354\n",
            "Epoch 571/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3860 - accuracy: 0.8331 - val_loss: 0.3768 - val_accuracy: 0.8355\n",
            "Epoch 572/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3851 - accuracy: 0.8342 - val_loss: 0.3773 - val_accuracy: 0.8362\n",
            "Epoch 573/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3921 - accuracy: 0.8302 - val_loss: 0.3814 - val_accuracy: 0.8336\n",
            "Epoch 574/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3868 - accuracy: 0.8336 - val_loss: 0.3767 - val_accuracy: 0.8366\n",
            "Epoch 575/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3896 - accuracy: 0.8322 - val_loss: 0.3817 - val_accuracy: 0.8333\n",
            "Epoch 576/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3856 - accuracy: 0.8342 - val_loss: 0.3811 - val_accuracy: 0.8327\n",
            "Epoch 577/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3854 - accuracy: 0.8348 - val_loss: 0.3782 - val_accuracy: 0.8353\n",
            "Epoch 578/1000\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.3859 - accuracy: 0.8324 - val_loss: 0.3776 - val_accuracy: 0.8359\n",
            "Epoch 579/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3863 - accuracy: 0.8332 - val_loss: 0.3765 - val_accuracy: 0.8371\n",
            "Epoch 580/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3826 - accuracy: 0.8351 - val_loss: 0.3778 - val_accuracy: 0.8358\n",
            "Epoch 581/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3855 - accuracy: 0.8344 - val_loss: 0.3804 - val_accuracy: 0.8341\n",
            "Epoch 582/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3885 - accuracy: 0.8323 - val_loss: 0.3777 - val_accuracy: 0.8358\n",
            "Epoch 583/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3871 - accuracy: 0.8337 - val_loss: 0.3796 - val_accuracy: 0.8336\n",
            "Epoch 584/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3855 - accuracy: 0.8327 - val_loss: 0.3799 - val_accuracy: 0.8346\n",
            "Epoch 585/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3848 - accuracy: 0.8363 - val_loss: 0.3809 - val_accuracy: 0.8332\n",
            "Epoch 586/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3873 - accuracy: 0.8339 - val_loss: 0.3775 - val_accuracy: 0.8369\n",
            "Epoch 587/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3840 - accuracy: 0.8340 - val_loss: 0.3778 - val_accuracy: 0.8357\n",
            "Epoch 588/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3820 - accuracy: 0.8367 - val_loss: 0.3798 - val_accuracy: 0.8335\n",
            "Epoch 589/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3857 - accuracy: 0.8349 - val_loss: 0.3820 - val_accuracy: 0.8322\n",
            "Epoch 590/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3875 - accuracy: 0.8343 - val_loss: 0.3779 - val_accuracy: 0.8355\n",
            "Epoch 591/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3847 - accuracy: 0.8355 - val_loss: 0.3770 - val_accuracy: 0.8364\n",
            "Epoch 592/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3831 - accuracy: 0.8367 - val_loss: 0.3786 - val_accuracy: 0.8344\n",
            "Epoch 593/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3854 - accuracy: 0.8350 - val_loss: 0.3785 - val_accuracy: 0.8352\n",
            "Epoch 594/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3892 - accuracy: 0.8328 - val_loss: 0.3769 - val_accuracy: 0.8380\n",
            "Epoch 595/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3904 - accuracy: 0.8328 - val_loss: 0.3802 - val_accuracy: 0.8338\n",
            "Epoch 596/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3866 - accuracy: 0.8339 - val_loss: 0.3767 - val_accuracy: 0.8366\n",
            "Epoch 597/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3891 - accuracy: 0.8333 - val_loss: 0.3820 - val_accuracy: 0.8317\n",
            "Epoch 598/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3871 - accuracy: 0.8336 - val_loss: 0.3741 - val_accuracy: 0.8380\n",
            "Epoch 599/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3866 - accuracy: 0.8335 - val_loss: 0.3754 - val_accuracy: 0.8378\n",
            "Epoch 600/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3839 - accuracy: 0.8319 - val_loss: 0.3780 - val_accuracy: 0.8365\n",
            "Epoch 601/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3845 - accuracy: 0.8349 - val_loss: 0.3783 - val_accuracy: 0.8343\n",
            "Epoch 602/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3869 - accuracy: 0.8339 - val_loss: 0.3844 - val_accuracy: 0.8325\n",
            "Epoch 603/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3834 - accuracy: 0.8341 - val_loss: 0.3786 - val_accuracy: 0.8359\n",
            "Epoch 604/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3868 - accuracy: 0.8339 - val_loss: 0.3771 - val_accuracy: 0.8359\n",
            "Epoch 605/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3865 - accuracy: 0.8326 - val_loss: 0.3772 - val_accuracy: 0.8369\n",
            "Epoch 606/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3858 - accuracy: 0.8345 - val_loss: 0.3751 - val_accuracy: 0.8373\n",
            "Epoch 607/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3876 - accuracy: 0.8343 - val_loss: 0.3765 - val_accuracy: 0.8365\n",
            "Epoch 608/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3836 - accuracy: 0.8357 - val_loss: 0.3773 - val_accuracy: 0.8367\n",
            "Epoch 609/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3865 - accuracy: 0.8340 - val_loss: 0.3801 - val_accuracy: 0.8340\n",
            "Epoch 610/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3848 - accuracy: 0.8352 - val_loss: 0.3796 - val_accuracy: 0.8349\n",
            "Epoch 611/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3862 - accuracy: 0.8356 - val_loss: 0.3778 - val_accuracy: 0.8359\n",
            "Epoch 612/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3852 - accuracy: 0.8338 - val_loss: 0.3767 - val_accuracy: 0.8358\n",
            "Epoch 613/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3861 - accuracy: 0.8344 - val_loss: 0.3777 - val_accuracy: 0.8378\n",
            "Epoch 614/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3877 - accuracy: 0.8332 - val_loss: 0.3812 - val_accuracy: 0.8337\n",
            "Epoch 615/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3884 - accuracy: 0.8315 - val_loss: 0.3745 - val_accuracy: 0.8384\n",
            "Epoch 616/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3888 - accuracy: 0.8346 - val_loss: 0.3768 - val_accuracy: 0.8366\n",
            "Epoch 617/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3837 - accuracy: 0.8359 - val_loss: 0.3767 - val_accuracy: 0.8360\n",
            "Epoch 618/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3885 - accuracy: 0.8339 - val_loss: 0.3776 - val_accuracy: 0.8359\n",
            "Epoch 619/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3865 - accuracy: 0.8332 - val_loss: 0.3791 - val_accuracy: 0.8345\n",
            "Epoch 620/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3821 - accuracy: 0.8378 - val_loss: 0.3765 - val_accuracy: 0.8374\n",
            "Epoch 621/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3854 - accuracy: 0.8343 - val_loss: 0.3795 - val_accuracy: 0.8360\n",
            "Epoch 622/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3851 - accuracy: 0.8332 - val_loss: 0.3751 - val_accuracy: 0.8374\n",
            "Epoch 623/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3826 - accuracy: 0.8364 - val_loss: 0.3749 - val_accuracy: 0.8384\n",
            "Epoch 624/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3820 - accuracy: 0.8379 - val_loss: 0.3771 - val_accuracy: 0.8372\n",
            "Epoch 625/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3844 - accuracy: 0.8349 - val_loss: 0.3790 - val_accuracy: 0.8347\n",
            "Epoch 626/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3868 - accuracy: 0.8338 - val_loss: 0.3770 - val_accuracy: 0.8365\n",
            "Epoch 627/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3853 - accuracy: 0.8361 - val_loss: 0.3743 - val_accuracy: 0.8383\n",
            "Epoch 628/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3806 - accuracy: 0.8364 - val_loss: 0.3790 - val_accuracy: 0.8351\n",
            "Epoch 629/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3819 - accuracy: 0.8368 - val_loss: 0.3772 - val_accuracy: 0.8360\n",
            "Epoch 630/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3844 - accuracy: 0.8361 - val_loss: 0.3776 - val_accuracy: 0.8361\n",
            "Epoch 631/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3886 - accuracy: 0.8324 - val_loss: 0.3803 - val_accuracy: 0.8331\n",
            "Epoch 632/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3821 - accuracy: 0.8387 - val_loss: 0.3776 - val_accuracy: 0.8354\n",
            "Epoch 633/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3853 - accuracy: 0.8338 - val_loss: 0.3769 - val_accuracy: 0.8348\n",
            "Epoch 634/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3817 - accuracy: 0.8359 - val_loss: 0.3756 - val_accuracy: 0.8366\n",
            "Epoch 635/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3837 - accuracy: 0.8364 - val_loss: 0.3738 - val_accuracy: 0.8392\n",
            "Epoch 636/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3803 - accuracy: 0.8372 - val_loss: 0.3745 - val_accuracy: 0.8373\n",
            "Epoch 637/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3842 - accuracy: 0.8361 - val_loss: 0.3745 - val_accuracy: 0.8373\n",
            "Epoch 638/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3847 - accuracy: 0.8361 - val_loss: 0.3783 - val_accuracy: 0.8356\n",
            "Epoch 639/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3828 - accuracy: 0.8370 - val_loss: 0.3757 - val_accuracy: 0.8373\n",
            "Epoch 640/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3850 - accuracy: 0.8362 - val_loss: 0.3749 - val_accuracy: 0.8369\n",
            "Epoch 641/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3845 - accuracy: 0.8369 - val_loss: 0.3749 - val_accuracy: 0.8372\n",
            "Epoch 642/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3866 - accuracy: 0.8341 - val_loss: 0.3734 - val_accuracy: 0.8388\n",
            "Epoch 643/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3840 - accuracy: 0.8351 - val_loss: 0.3756 - val_accuracy: 0.8373\n",
            "Epoch 644/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3827 - accuracy: 0.8369 - val_loss: 0.3772 - val_accuracy: 0.8375\n",
            "Epoch 645/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3847 - accuracy: 0.8363 - val_loss: 0.3779 - val_accuracy: 0.8355\n",
            "Epoch 646/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3777 - accuracy: 0.8390 - val_loss: 0.3759 - val_accuracy: 0.8375\n",
            "Epoch 647/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3831 - accuracy: 0.8373 - val_loss: 0.3802 - val_accuracy: 0.8343\n",
            "Epoch 648/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3868 - accuracy: 0.8327 - val_loss: 0.3746 - val_accuracy: 0.8371\n",
            "Epoch 649/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3856 - accuracy: 0.8335 - val_loss: 0.3760 - val_accuracy: 0.8363\n",
            "Epoch 650/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3844 - accuracy: 0.8350 - val_loss: 0.3785 - val_accuracy: 0.8364\n",
            "Epoch 651/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3851 - accuracy: 0.8350 - val_loss: 0.3766 - val_accuracy: 0.8363\n",
            "Epoch 652/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3838 - accuracy: 0.8370 - val_loss: 0.3744 - val_accuracy: 0.8373\n",
            "Epoch 653/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3819 - accuracy: 0.8362 - val_loss: 0.3730 - val_accuracy: 0.8384\n",
            "Epoch 654/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3794 - accuracy: 0.8371 - val_loss: 0.3724 - val_accuracy: 0.8387\n",
            "Epoch 655/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3842 - accuracy: 0.8351 - val_loss: 0.3775 - val_accuracy: 0.8351\n",
            "Epoch 656/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3842 - accuracy: 0.8363 - val_loss: 0.3753 - val_accuracy: 0.8369\n",
            "Epoch 657/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3842 - accuracy: 0.8367 - val_loss: 0.3732 - val_accuracy: 0.8386\n",
            "Epoch 658/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3831 - accuracy: 0.8347 - val_loss: 0.3753 - val_accuracy: 0.8365\n",
            "Epoch 659/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3858 - accuracy: 0.8344 - val_loss: 0.3743 - val_accuracy: 0.8374\n",
            "Epoch 660/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3806 - accuracy: 0.8365 - val_loss: 0.3787 - val_accuracy: 0.8355\n",
            "Epoch 661/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3824 - accuracy: 0.8364 - val_loss: 0.3748 - val_accuracy: 0.8374\n",
            "Epoch 662/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3851 - accuracy: 0.8369 - val_loss: 0.3741 - val_accuracy: 0.8384\n",
            "Epoch 663/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3827 - accuracy: 0.8368 - val_loss: 0.3734 - val_accuracy: 0.8377\n",
            "Epoch 664/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3822 - accuracy: 0.8370 - val_loss: 0.3795 - val_accuracy: 0.8348\n",
            "Epoch 665/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3849 - accuracy: 0.8350 - val_loss: 0.3795 - val_accuracy: 0.8347\n",
            "Epoch 666/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3845 - accuracy: 0.8347 - val_loss: 0.3797 - val_accuracy: 0.8350\n",
            "Epoch 667/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3811 - accuracy: 0.8364 - val_loss: 0.3752 - val_accuracy: 0.8365\n",
            "Epoch 668/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3808 - accuracy: 0.8374 - val_loss: 0.3741 - val_accuracy: 0.8374\n",
            "Epoch 669/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3802 - accuracy: 0.8375 - val_loss: 0.3719 - val_accuracy: 0.8391\n",
            "Epoch 670/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3805 - accuracy: 0.8381 - val_loss: 0.3790 - val_accuracy: 0.8348\n",
            "Epoch 671/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3836 - accuracy: 0.8362 - val_loss: 0.3720 - val_accuracy: 0.8393\n",
            "Epoch 672/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3858 - accuracy: 0.8360 - val_loss: 0.3745 - val_accuracy: 0.8370\n",
            "Epoch 673/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3843 - accuracy: 0.8350 - val_loss: 0.3730 - val_accuracy: 0.8378\n",
            "Epoch 674/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3846 - accuracy: 0.8336 - val_loss: 0.3734 - val_accuracy: 0.8384\n",
            "Epoch 675/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3828 - accuracy: 0.8352 - val_loss: 0.3725 - val_accuracy: 0.8385\n",
            "Epoch 676/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3827 - accuracy: 0.8365 - val_loss: 0.3748 - val_accuracy: 0.8378\n",
            "Epoch 677/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3847 - accuracy: 0.8346 - val_loss: 0.3750 - val_accuracy: 0.8386\n",
            "Epoch 678/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3804 - accuracy: 0.8372 - val_loss: 0.3710 - val_accuracy: 0.8403\n",
            "Epoch 679/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3800 - accuracy: 0.8395 - val_loss: 0.3756 - val_accuracy: 0.8370\n",
            "Epoch 680/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3838 - accuracy: 0.8362 - val_loss: 0.3745 - val_accuracy: 0.8379\n",
            "Epoch 681/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3833 - accuracy: 0.8377 - val_loss: 0.3762 - val_accuracy: 0.8365\n",
            "Epoch 682/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3795 - accuracy: 0.8373 - val_loss: 0.3754 - val_accuracy: 0.8375\n",
            "Epoch 683/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3832 - accuracy: 0.8365 - val_loss: 0.3745 - val_accuracy: 0.8387\n",
            "Epoch 684/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3824 - accuracy: 0.8369 - val_loss: 0.3736 - val_accuracy: 0.8385\n",
            "Epoch 685/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3819 - accuracy: 0.8353 - val_loss: 0.3730 - val_accuracy: 0.8375\n",
            "Epoch 686/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3806 - accuracy: 0.8368 - val_loss: 0.3712 - val_accuracy: 0.8384\n",
            "Epoch 687/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3796 - accuracy: 0.8376 - val_loss: 0.3720 - val_accuracy: 0.8383\n",
            "Epoch 688/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3827 - accuracy: 0.8356 - val_loss: 0.3722 - val_accuracy: 0.8384\n",
            "Epoch 689/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3811 - accuracy: 0.8363 - val_loss: 0.3718 - val_accuracy: 0.8383\n",
            "Epoch 690/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3788 - accuracy: 0.8390 - val_loss: 0.3715 - val_accuracy: 0.8391\n",
            "Epoch 691/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3834 - accuracy: 0.8352 - val_loss: 0.3724 - val_accuracy: 0.8375\n",
            "Epoch 692/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3831 - accuracy: 0.8359 - val_loss: 0.3751 - val_accuracy: 0.8364\n",
            "Epoch 693/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3844 - accuracy: 0.8346 - val_loss: 0.3749 - val_accuracy: 0.8365\n",
            "Epoch 694/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3809 - accuracy: 0.8372 - val_loss: 0.3765 - val_accuracy: 0.8360\n",
            "Epoch 695/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3830 - accuracy: 0.8352 - val_loss: 0.3718 - val_accuracy: 0.8390\n",
            "Epoch 696/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3847 - accuracy: 0.8357 - val_loss: 0.3740 - val_accuracy: 0.8373\n",
            "Epoch 697/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3805 - accuracy: 0.8369 - val_loss: 0.3759 - val_accuracy: 0.8361\n",
            "Epoch 698/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3827 - accuracy: 0.8365 - val_loss: 0.3758 - val_accuracy: 0.8368\n",
            "Epoch 699/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3799 - accuracy: 0.8377 - val_loss: 0.3766 - val_accuracy: 0.8363\n",
            "Epoch 700/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3848 - accuracy: 0.8366 - val_loss: 0.3751 - val_accuracy: 0.8359\n",
            "Epoch 701/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3783 - accuracy: 0.8399 - val_loss: 0.3740 - val_accuracy: 0.8384\n",
            "Epoch 702/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3794 - accuracy: 0.8390 - val_loss: 0.3741 - val_accuracy: 0.8367\n",
            "Epoch 703/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3824 - accuracy: 0.8378 - val_loss: 0.3786 - val_accuracy: 0.8350\n",
            "Epoch 704/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3814 - accuracy: 0.8375 - val_loss: 0.3708 - val_accuracy: 0.8388\n",
            "Epoch 705/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3785 - accuracy: 0.8380 - val_loss: 0.3737 - val_accuracy: 0.8381\n",
            "Epoch 706/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3825 - accuracy: 0.8366 - val_loss: 0.3725 - val_accuracy: 0.8373\n",
            "Epoch 707/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3779 - accuracy: 0.8389 - val_loss: 0.3740 - val_accuracy: 0.8376\n",
            "Epoch 708/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3793 - accuracy: 0.8380 - val_loss: 0.3756 - val_accuracy: 0.8370\n",
            "Epoch 709/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3796 - accuracy: 0.8399 - val_loss: 0.3740 - val_accuracy: 0.8381\n",
            "Epoch 710/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3783 - accuracy: 0.8376 - val_loss: 0.3733 - val_accuracy: 0.8373\n",
            "Epoch 711/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3823 - accuracy: 0.8357 - val_loss: 0.3732 - val_accuracy: 0.8381\n",
            "Epoch 712/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3804 - accuracy: 0.8389 - val_loss: 0.3738 - val_accuracy: 0.8382\n",
            "Epoch 713/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3818 - accuracy: 0.8352 - val_loss: 0.3767 - val_accuracy: 0.8354\n",
            "Epoch 714/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3769 - accuracy: 0.8408 - val_loss: 0.3719 - val_accuracy: 0.8400\n",
            "Epoch 715/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3817 - accuracy: 0.8378 - val_loss: 0.3727 - val_accuracy: 0.8383\n",
            "Epoch 716/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3755 - accuracy: 0.8397 - val_loss: 0.3722 - val_accuracy: 0.8382\n",
            "Epoch 717/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3801 - accuracy: 0.8379 - val_loss: 0.3717 - val_accuracy: 0.8390\n",
            "Epoch 718/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3832 - accuracy: 0.8364 - val_loss: 0.3708 - val_accuracy: 0.8393\n",
            "Epoch 719/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3786 - accuracy: 0.8378 - val_loss: 0.3718 - val_accuracy: 0.8393\n",
            "Epoch 720/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3812 - accuracy: 0.8376 - val_loss: 0.3730 - val_accuracy: 0.8373\n",
            "Epoch 721/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3821 - accuracy: 0.8380 - val_loss: 0.3734 - val_accuracy: 0.8387\n",
            "Epoch 722/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3773 - accuracy: 0.8375 - val_loss: 0.3721 - val_accuracy: 0.8384\n",
            "Epoch 723/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3846 - accuracy: 0.8369 - val_loss: 0.3693 - val_accuracy: 0.8405\n",
            "Epoch 724/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3752 - accuracy: 0.8406 - val_loss: 0.3716 - val_accuracy: 0.8396\n",
            "Epoch 725/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3785 - accuracy: 0.8390 - val_loss: 0.3716 - val_accuracy: 0.8392\n",
            "Epoch 726/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3785 - accuracy: 0.8383 - val_loss: 0.3724 - val_accuracy: 0.8392\n",
            "Epoch 727/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3813 - accuracy: 0.8380 - val_loss: 0.3705 - val_accuracy: 0.8395\n",
            "Epoch 728/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3824 - accuracy: 0.8369 - val_loss: 0.3747 - val_accuracy: 0.8362\n",
            "Epoch 729/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3819 - accuracy: 0.8375 - val_loss: 0.3756 - val_accuracy: 0.8365\n",
            "Epoch 730/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3771 - accuracy: 0.8392 - val_loss: 0.3707 - val_accuracy: 0.8411\n",
            "Epoch 731/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3804 - accuracy: 0.8381 - val_loss: 0.3723 - val_accuracy: 0.8386\n",
            "Epoch 732/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3800 - accuracy: 0.8365 - val_loss: 0.3724 - val_accuracy: 0.8387\n",
            "Epoch 733/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3772 - accuracy: 0.8386 - val_loss: 0.3737 - val_accuracy: 0.8389\n",
            "Epoch 734/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3789 - accuracy: 0.8391 - val_loss: 0.3713 - val_accuracy: 0.8395\n",
            "Epoch 735/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3778 - accuracy: 0.8383 - val_loss: 0.3728 - val_accuracy: 0.8397\n",
            "Epoch 736/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3796 - accuracy: 0.8393 - val_loss: 0.3704 - val_accuracy: 0.8396\n",
            "Epoch 737/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3815 - accuracy: 0.8383 - val_loss: 0.3697 - val_accuracy: 0.8401\n",
            "Epoch 738/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3804 - accuracy: 0.8385 - val_loss: 0.3702 - val_accuracy: 0.8398\n",
            "Epoch 739/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3799 - accuracy: 0.8378 - val_loss: 0.3718 - val_accuracy: 0.8395\n",
            "Epoch 740/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3807 - accuracy: 0.8378 - val_loss: 0.3720 - val_accuracy: 0.8390\n",
            "Epoch 741/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3788 - accuracy: 0.8383 - val_loss: 0.3696 - val_accuracy: 0.8399\n",
            "Epoch 742/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3799 - accuracy: 0.8370 - val_loss: 0.3749 - val_accuracy: 0.8364\n",
            "Epoch 743/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3809 - accuracy: 0.8378 - val_loss: 0.3730 - val_accuracy: 0.8371\n",
            "Epoch 744/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3805 - accuracy: 0.8375 - val_loss: 0.3762 - val_accuracy: 0.8354\n",
            "Epoch 745/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3803 - accuracy: 0.8373 - val_loss: 0.3704 - val_accuracy: 0.8391\n",
            "Epoch 746/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3769 - accuracy: 0.8399 - val_loss: 0.3722 - val_accuracy: 0.8387\n",
            "Epoch 747/1000\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3749 - accuracy: 0.8414 - val_loss: 0.3740 - val_accuracy: 0.8383\n",
            "Epoch 748/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3787 - accuracy: 0.8384 - val_loss: 0.3687 - val_accuracy: 0.8410\n",
            "Epoch 749/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3760 - accuracy: 0.8416 - val_loss: 0.3720 - val_accuracy: 0.8395\n",
            "Epoch 750/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3764 - accuracy: 0.8402 - val_loss: 0.3700 - val_accuracy: 0.8399\n",
            "Epoch 751/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3841 - accuracy: 0.8353 - val_loss: 0.3721 - val_accuracy: 0.8388\n",
            "Epoch 752/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3764 - accuracy: 0.8408 - val_loss: 0.3695 - val_accuracy: 0.8408\n",
            "Epoch 753/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3778 - accuracy: 0.8387 - val_loss: 0.3723 - val_accuracy: 0.8393\n",
            "Epoch 754/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3784 - accuracy: 0.8384 - val_loss: 0.3739 - val_accuracy: 0.8365\n",
            "Epoch 755/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3785 - accuracy: 0.8396 - val_loss: 0.3713 - val_accuracy: 0.8390\n",
            "Epoch 756/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3748 - accuracy: 0.8410 - val_loss: 0.3759 - val_accuracy: 0.8362\n",
            "Epoch 757/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3801 - accuracy: 0.8393 - val_loss: 0.3712 - val_accuracy: 0.8386\n",
            "Epoch 758/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3796 - accuracy: 0.8377 - val_loss: 0.3760 - val_accuracy: 0.8355\n",
            "Epoch 759/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3813 - accuracy: 0.8365 - val_loss: 0.3715 - val_accuracy: 0.8379\n",
            "Epoch 760/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3799 - accuracy: 0.8389 - val_loss: 0.3698 - val_accuracy: 0.8390\n",
            "Epoch 761/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3784 - accuracy: 0.8394 - val_loss: 0.3713 - val_accuracy: 0.8394\n",
            "Epoch 762/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3735 - accuracy: 0.8399 - val_loss: 0.3726 - val_accuracy: 0.8382\n",
            "Epoch 763/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3775 - accuracy: 0.8391 - val_loss: 0.3733 - val_accuracy: 0.8387\n",
            "Epoch 764/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3789 - accuracy: 0.8398 - val_loss: 0.3711 - val_accuracy: 0.8393\n",
            "Epoch 765/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3777 - accuracy: 0.8396 - val_loss: 0.3730 - val_accuracy: 0.8394\n",
            "Epoch 766/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3768 - accuracy: 0.8395 - val_loss: 0.3753 - val_accuracy: 0.8361\n",
            "Epoch 767/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3775 - accuracy: 0.8399 - val_loss: 0.3709 - val_accuracy: 0.8393\n",
            "Epoch 768/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3785 - accuracy: 0.8386 - val_loss: 0.3698 - val_accuracy: 0.8403\n",
            "Epoch 769/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3738 - accuracy: 0.8411 - val_loss: 0.3720 - val_accuracy: 0.8377\n",
            "Epoch 770/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3779 - accuracy: 0.8404 - val_loss: 0.3748 - val_accuracy: 0.8366\n",
            "Epoch 771/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3831 - accuracy: 0.8368 - val_loss: 0.3711 - val_accuracy: 0.8388\n",
            "Epoch 772/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3761 - accuracy: 0.8406 - val_loss: 0.3714 - val_accuracy: 0.8386\n",
            "Epoch 773/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3772 - accuracy: 0.8390 - val_loss: 0.3735 - val_accuracy: 0.8368\n",
            "Epoch 774/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3782 - accuracy: 0.8402 - val_loss: 0.3702 - val_accuracy: 0.8405\n",
            "Epoch 775/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3783 - accuracy: 0.8380 - val_loss: 0.3703 - val_accuracy: 0.8398\n",
            "Epoch 776/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3794 - accuracy: 0.8389 - val_loss: 0.3726 - val_accuracy: 0.8381\n",
            "Epoch 777/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3741 - accuracy: 0.8418 - val_loss: 0.3749 - val_accuracy: 0.8375\n",
            "Epoch 778/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3786 - accuracy: 0.8401 - val_loss: 0.3709 - val_accuracy: 0.8387\n",
            "Epoch 779/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3793 - accuracy: 0.8385 - val_loss: 0.3694 - val_accuracy: 0.8398\n",
            "Epoch 780/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3790 - accuracy: 0.8393 - val_loss: 0.3726 - val_accuracy: 0.8378\n",
            "Epoch 781/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3783 - accuracy: 0.8395 - val_loss: 0.3716 - val_accuracy: 0.8391\n",
            "Epoch 782/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3762 - accuracy: 0.8401 - val_loss: 0.3758 - val_accuracy: 0.8366\n",
            "Epoch 783/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3793 - accuracy: 0.8390 - val_loss: 0.3662 - val_accuracy: 0.8424\n",
            "Epoch 784/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3755 - accuracy: 0.8429 - val_loss: 0.3682 - val_accuracy: 0.8411\n",
            "Epoch 785/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3774 - accuracy: 0.8395 - val_loss: 0.3698 - val_accuracy: 0.8388\n",
            "Epoch 786/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3766 - accuracy: 0.8404 - val_loss: 0.3678 - val_accuracy: 0.8412\n",
            "Epoch 787/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3782 - accuracy: 0.8393 - val_loss: 0.3714 - val_accuracy: 0.8385\n",
            "Epoch 788/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3774 - accuracy: 0.8392 - val_loss: 0.3718 - val_accuracy: 0.8395\n",
            "Epoch 789/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3757 - accuracy: 0.8392 - val_loss: 0.3706 - val_accuracy: 0.8388\n",
            "Epoch 790/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3786 - accuracy: 0.8389 - val_loss: 0.3707 - val_accuracy: 0.8391\n",
            "Epoch 791/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3745 - accuracy: 0.8422 - val_loss: 0.3715 - val_accuracy: 0.8391\n",
            "Epoch 792/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3776 - accuracy: 0.8392 - val_loss: 0.3691 - val_accuracy: 0.8402\n",
            "Epoch 793/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3797 - accuracy: 0.8380 - val_loss: 0.3725 - val_accuracy: 0.8378\n",
            "Epoch 794/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3777 - accuracy: 0.8390 - val_loss: 0.3693 - val_accuracy: 0.8398\n",
            "Epoch 795/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3750 - accuracy: 0.8402 - val_loss: 0.3717 - val_accuracy: 0.8389\n",
            "Epoch 796/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3791 - accuracy: 0.8401 - val_loss: 0.3710 - val_accuracy: 0.8385\n",
            "Epoch 797/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3760 - accuracy: 0.8390 - val_loss: 0.3696 - val_accuracy: 0.8394\n",
            "Epoch 798/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3803 - accuracy: 0.8360 - val_loss: 0.3699 - val_accuracy: 0.8390\n",
            "Epoch 799/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3775 - accuracy: 0.8390 - val_loss: 0.3721 - val_accuracy: 0.8388\n",
            "Epoch 800/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3749 - accuracy: 0.8416 - val_loss: 0.3680 - val_accuracy: 0.8412\n",
            "Epoch 801/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3798 - accuracy: 0.8384 - val_loss: 0.3696 - val_accuracy: 0.8398\n",
            "Epoch 802/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3794 - accuracy: 0.8377 - val_loss: 0.3729 - val_accuracy: 0.8377\n",
            "Epoch 803/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3769 - accuracy: 0.8376 - val_loss: 0.3734 - val_accuracy: 0.8375\n",
            "Epoch 804/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3825 - accuracy: 0.8380 - val_loss: 0.3727 - val_accuracy: 0.8383\n",
            "Epoch 805/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3743 - accuracy: 0.8402 - val_loss: 0.3687 - val_accuracy: 0.8403\n",
            "Epoch 806/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3772 - accuracy: 0.8388 - val_loss: 0.3695 - val_accuracy: 0.8391\n",
            "Epoch 807/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3749 - accuracy: 0.8421 - val_loss: 0.3707 - val_accuracy: 0.8385\n",
            "Epoch 808/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3777 - accuracy: 0.8416 - val_loss: 0.3695 - val_accuracy: 0.8398\n",
            "Epoch 809/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3742 - accuracy: 0.8422 - val_loss: 0.3713 - val_accuracy: 0.8381\n",
            "Epoch 810/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3768 - accuracy: 0.8412 - val_loss: 0.3691 - val_accuracy: 0.8395\n",
            "Epoch 811/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3777 - accuracy: 0.8383 - val_loss: 0.3671 - val_accuracy: 0.8412\n",
            "Epoch 812/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3766 - accuracy: 0.8398 - val_loss: 0.3710 - val_accuracy: 0.8382\n",
            "Epoch 813/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3744 - accuracy: 0.8415 - val_loss: 0.3714 - val_accuracy: 0.8390\n",
            "Epoch 814/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3762 - accuracy: 0.8420 - val_loss: 0.3707 - val_accuracy: 0.8393\n",
            "Epoch 815/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3760 - accuracy: 0.8428 - val_loss: 0.3706 - val_accuracy: 0.8415\n",
            "Epoch 816/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3775 - accuracy: 0.8391 - val_loss: 0.3666 - val_accuracy: 0.8420\n",
            "Epoch 817/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3759 - accuracy: 0.8409 - val_loss: 0.3699 - val_accuracy: 0.8407\n",
            "Epoch 818/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3767 - accuracy: 0.8398 - val_loss: 0.3690 - val_accuracy: 0.8406\n",
            "Epoch 819/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3742 - accuracy: 0.8414 - val_loss: 0.3680 - val_accuracy: 0.8406\n",
            "Epoch 820/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3752 - accuracy: 0.8397 - val_loss: 0.3704 - val_accuracy: 0.8394\n",
            "Epoch 821/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3734 - accuracy: 0.8401 - val_loss: 0.3738 - val_accuracy: 0.8357\n",
            "Epoch 822/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3769 - accuracy: 0.8415 - val_loss: 0.3712 - val_accuracy: 0.8386\n",
            "Epoch 823/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3758 - accuracy: 0.8392 - val_loss: 0.3668 - val_accuracy: 0.8417\n",
            "Epoch 824/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3728 - accuracy: 0.8415 - val_loss: 0.3686 - val_accuracy: 0.8395\n",
            "Epoch 825/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3748 - accuracy: 0.8404 - val_loss: 0.3720 - val_accuracy: 0.8387\n",
            "Epoch 826/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3741 - accuracy: 0.8413 - val_loss: 0.3700 - val_accuracy: 0.8401\n",
            "Epoch 827/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3757 - accuracy: 0.8429 - val_loss: 0.3675 - val_accuracy: 0.8409\n",
            "Epoch 828/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3771 - accuracy: 0.8407 - val_loss: 0.3704 - val_accuracy: 0.8394\n",
            "Epoch 829/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3747 - accuracy: 0.8409 - val_loss: 0.3687 - val_accuracy: 0.8403\n",
            "Epoch 830/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3771 - accuracy: 0.8393 - val_loss: 0.3703 - val_accuracy: 0.8387\n",
            "Epoch 831/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3746 - accuracy: 0.8385 - val_loss: 0.3712 - val_accuracy: 0.8384\n",
            "Epoch 832/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3794 - accuracy: 0.8408 - val_loss: 0.3696 - val_accuracy: 0.8398\n",
            "Epoch 833/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3736 - accuracy: 0.8420 - val_loss: 0.3709 - val_accuracy: 0.8389\n",
            "Epoch 834/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3754 - accuracy: 0.8409 - val_loss: 0.3672 - val_accuracy: 0.8424\n",
            "Epoch 835/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3766 - accuracy: 0.8411 - val_loss: 0.3700 - val_accuracy: 0.8393\n",
            "Epoch 836/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3755 - accuracy: 0.8411 - val_loss: 0.3710 - val_accuracy: 0.8386\n",
            "Epoch 837/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3731 - accuracy: 0.8424 - val_loss: 0.3681 - val_accuracy: 0.8401\n",
            "Epoch 838/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3779 - accuracy: 0.8374 - val_loss: 0.3686 - val_accuracy: 0.8401\n",
            "Epoch 839/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3763 - accuracy: 0.8405 - val_loss: 0.3704 - val_accuracy: 0.8390\n",
            "Epoch 840/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3730 - accuracy: 0.8436 - val_loss: 0.3720 - val_accuracy: 0.8369\n",
            "Epoch 841/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3757 - accuracy: 0.8401 - val_loss: 0.3696 - val_accuracy: 0.8402\n",
            "Epoch 842/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3785 - accuracy: 0.8391 - val_loss: 0.3709 - val_accuracy: 0.8379\n",
            "Epoch 843/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3764 - accuracy: 0.8403 - val_loss: 0.3663 - val_accuracy: 0.8420\n",
            "Epoch 844/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3756 - accuracy: 0.8406 - val_loss: 0.3726 - val_accuracy: 0.8379\n",
            "Epoch 845/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3753 - accuracy: 0.8396 - val_loss: 0.3690 - val_accuracy: 0.8400\n",
            "Epoch 846/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3780 - accuracy: 0.8392 - val_loss: 0.3654 - val_accuracy: 0.8417\n",
            "Epoch 847/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3759 - accuracy: 0.8399 - val_loss: 0.3712 - val_accuracy: 0.8385\n",
            "Epoch 848/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3716 - accuracy: 0.8432 - val_loss: 0.3710 - val_accuracy: 0.8401\n",
            "Epoch 849/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3745 - accuracy: 0.8397 - val_loss: 0.3723 - val_accuracy: 0.8372\n",
            "Epoch 850/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3740 - accuracy: 0.8402 - val_loss: 0.3680 - val_accuracy: 0.8398\n",
            "Epoch 851/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3740 - accuracy: 0.8420 - val_loss: 0.3700 - val_accuracy: 0.8410\n",
            "Epoch 852/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3732 - accuracy: 0.8419 - val_loss: 0.3719 - val_accuracy: 0.8387\n",
            "Epoch 853/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3748 - accuracy: 0.8423 - val_loss: 0.3702 - val_accuracy: 0.8399\n",
            "Epoch 854/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3777 - accuracy: 0.8404 - val_loss: 0.3668 - val_accuracy: 0.8412\n",
            "Epoch 855/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3734 - accuracy: 0.8412 - val_loss: 0.3750 - val_accuracy: 0.8367\n",
            "Epoch 856/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3752 - accuracy: 0.8406 - val_loss: 0.3667 - val_accuracy: 0.8414\n",
            "Epoch 857/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3754 - accuracy: 0.8401 - val_loss: 0.3688 - val_accuracy: 0.8401\n",
            "Epoch 858/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3725 - accuracy: 0.8425 - val_loss: 0.3714 - val_accuracy: 0.8383\n",
            "Epoch 859/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3769 - accuracy: 0.8402 - val_loss: 0.3698 - val_accuracy: 0.8382\n",
            "Epoch 860/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3741 - accuracy: 0.8407 - val_loss: 0.3661 - val_accuracy: 0.8414\n",
            "Epoch 861/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3748 - accuracy: 0.8408 - val_loss: 0.3698 - val_accuracy: 0.8398\n",
            "Epoch 862/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3748 - accuracy: 0.8395 - val_loss: 0.3701 - val_accuracy: 0.8382\n",
            "Epoch 863/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3749 - accuracy: 0.8397 - val_loss: 0.3685 - val_accuracy: 0.8410\n",
            "Epoch 864/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3726 - accuracy: 0.8444 - val_loss: 0.3686 - val_accuracy: 0.8399\n",
            "Epoch 865/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3719 - accuracy: 0.8425 - val_loss: 0.3645 - val_accuracy: 0.8444\n",
            "Epoch 866/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3726 - accuracy: 0.8404 - val_loss: 0.3685 - val_accuracy: 0.8412\n",
            "Epoch 867/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3749 - accuracy: 0.8406 - val_loss: 0.3693 - val_accuracy: 0.8408\n",
            "Epoch 868/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3740 - accuracy: 0.8395 - val_loss: 0.3719 - val_accuracy: 0.8374\n",
            "Epoch 869/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3732 - accuracy: 0.8419 - val_loss: 0.3747 - val_accuracy: 0.8374\n",
            "Epoch 870/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3723 - accuracy: 0.8429 - val_loss: 0.3670 - val_accuracy: 0.8408\n",
            "Epoch 871/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3762 - accuracy: 0.8405 - val_loss: 0.3662 - val_accuracy: 0.8420\n",
            "Epoch 872/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3715 - accuracy: 0.8421 - val_loss: 0.3656 - val_accuracy: 0.8425\n",
            "Epoch 873/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3717 - accuracy: 0.8428 - val_loss: 0.3662 - val_accuracy: 0.8427\n",
            "Epoch 874/1000\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3769 - accuracy: 0.8386 - val_loss: 0.3725 - val_accuracy: 0.8380\n",
            "Epoch 875/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3753 - accuracy: 0.8387 - val_loss: 0.3717 - val_accuracy: 0.8371\n",
            "Epoch 876/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3729 - accuracy: 0.8415 - val_loss: 0.3691 - val_accuracy: 0.8401\n",
            "Epoch 877/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3738 - accuracy: 0.8411 - val_loss: 0.3723 - val_accuracy: 0.8383\n",
            "Epoch 878/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3739 - accuracy: 0.8411 - val_loss: 0.3670 - val_accuracy: 0.8416\n",
            "Epoch 879/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3753 - accuracy: 0.8408 - val_loss: 0.3685 - val_accuracy: 0.8396\n",
            "Epoch 880/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3755 - accuracy: 0.8389 - val_loss: 0.3681 - val_accuracy: 0.8408\n",
            "Epoch 881/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3764 - accuracy: 0.8393 - val_loss: 0.3689 - val_accuracy: 0.8387\n",
            "Epoch 882/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3724 - accuracy: 0.8433 - val_loss: 0.3668 - val_accuracy: 0.8415\n",
            "Epoch 883/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3734 - accuracy: 0.8411 - val_loss: 0.3682 - val_accuracy: 0.8413\n",
            "Epoch 884/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3759 - accuracy: 0.8402 - val_loss: 0.3654 - val_accuracy: 0.8426\n",
            "Epoch 885/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3756 - accuracy: 0.8394 - val_loss: 0.3657 - val_accuracy: 0.8420\n",
            "Epoch 886/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3719 - accuracy: 0.8427 - val_loss: 0.3670 - val_accuracy: 0.8423\n",
            "Epoch 887/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3745 - accuracy: 0.8406 - val_loss: 0.3693 - val_accuracy: 0.8393\n",
            "Epoch 888/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3762 - accuracy: 0.8416 - val_loss: 0.3675 - val_accuracy: 0.8402\n",
            "Epoch 889/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3731 - accuracy: 0.8411 - val_loss: 0.3682 - val_accuracy: 0.8406\n",
            "Epoch 890/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3732 - accuracy: 0.8412 - val_loss: 0.3685 - val_accuracy: 0.8405\n",
            "Epoch 891/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3788 - accuracy: 0.8389 - val_loss: 0.3673 - val_accuracy: 0.8419\n",
            "Epoch 892/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3774 - accuracy: 0.8379 - val_loss: 0.3640 - val_accuracy: 0.8424\n",
            "Epoch 893/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3715 - accuracy: 0.8423 - val_loss: 0.3652 - val_accuracy: 0.8430\n",
            "Epoch 894/1000\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3727 - accuracy: 0.8411 - val_loss: 0.3660 - val_accuracy: 0.8418\n",
            "Epoch 895/1000\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3726 - accuracy: 0.8408 - val_loss: 0.3672 - val_accuracy: 0.8405\n",
            "Epoch 896/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3760 - accuracy: 0.8408 - val_loss: 0.3711 - val_accuracy: 0.8380\n",
            "Epoch 897/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3755 - accuracy: 0.8408 - val_loss: 0.3679 - val_accuracy: 0.8407\n",
            "Epoch 898/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3768 - accuracy: 0.8409 - val_loss: 0.3648 - val_accuracy: 0.8412\n",
            "Epoch 899/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3739 - accuracy: 0.8399 - val_loss: 0.3645 - val_accuracy: 0.8430\n",
            "Epoch 900/1000\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3757 - accuracy: 0.8401 - val_loss: 0.3674 - val_accuracy: 0.8405\n",
            "Epoch 901/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3730 - accuracy: 0.8433 - val_loss: 0.3650 - val_accuracy: 0.8428\n",
            "Epoch 902/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3725 - accuracy: 0.8431 - val_loss: 0.3665 - val_accuracy: 0.8413\n",
            "Epoch 903/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3752 - accuracy: 0.8394 - val_loss: 0.3696 - val_accuracy: 0.8388\n",
            "Epoch 904/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3741 - accuracy: 0.8422 - val_loss: 0.3650 - val_accuracy: 0.8423\n",
            "Epoch 905/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3749 - accuracy: 0.8390 - val_loss: 0.3723 - val_accuracy: 0.8380\n",
            "Epoch 906/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3713 - accuracy: 0.8436 - val_loss: 0.3687 - val_accuracy: 0.8404\n",
            "Epoch 907/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3728 - accuracy: 0.8425 - val_loss: 0.3700 - val_accuracy: 0.8400\n",
            "Epoch 908/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3759 - accuracy: 0.8409 - val_loss: 0.3697 - val_accuracy: 0.8389\n",
            "Epoch 909/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3746 - accuracy: 0.8422 - val_loss: 0.3653 - val_accuracy: 0.8421\n",
            "Epoch 910/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3713 - accuracy: 0.8420 - val_loss: 0.3661 - val_accuracy: 0.8421\n",
            "Epoch 911/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3724 - accuracy: 0.8435 - val_loss: 0.3676 - val_accuracy: 0.8416\n",
            "Epoch 912/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3717 - accuracy: 0.8425 - val_loss: 0.3686 - val_accuracy: 0.8397\n",
            "Epoch 913/1000\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3705 - accuracy: 0.8431 - val_loss: 0.3652 - val_accuracy: 0.8428\n",
            "Epoch 914/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3738 - accuracy: 0.8412 - val_loss: 0.3679 - val_accuracy: 0.8398\n",
            "Epoch 915/1000\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3713 - accuracy: 0.8422 - val_loss: 0.3633 - val_accuracy: 0.8455\n",
            "Epoch 916/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3784 - accuracy: 0.8408 - val_loss: 0.3665 - val_accuracy: 0.8413\n",
            "Epoch 917/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3724 - accuracy: 0.8416 - val_loss: 0.3662 - val_accuracy: 0.8423\n",
            "Epoch 918/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3695 - accuracy: 0.8449 - val_loss: 0.3660 - val_accuracy: 0.8435\n",
            "Epoch 919/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3747 - accuracy: 0.8414 - val_loss: 0.3667 - val_accuracy: 0.8411\n",
            "Epoch 920/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3723 - accuracy: 0.8422 - val_loss: 0.3653 - val_accuracy: 0.8440\n",
            "Epoch 921/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3731 - accuracy: 0.8435 - val_loss: 0.3665 - val_accuracy: 0.8416\n",
            "Epoch 922/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3723 - accuracy: 0.8433 - val_loss: 0.3655 - val_accuracy: 0.8418\n",
            "Epoch 923/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3711 - accuracy: 0.8432 - val_loss: 0.3687 - val_accuracy: 0.8397\n",
            "Epoch 924/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3710 - accuracy: 0.8426 - val_loss: 0.3684 - val_accuracy: 0.8407\n",
            "Epoch 925/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3704 - accuracy: 0.8438 - val_loss: 0.3651 - val_accuracy: 0.8425\n",
            "Epoch 926/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3693 - accuracy: 0.8434 - val_loss: 0.3671 - val_accuracy: 0.8414\n",
            "Epoch 927/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3775 - accuracy: 0.8382 - val_loss: 0.3665 - val_accuracy: 0.8408\n",
            "Epoch 928/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3753 - accuracy: 0.8423 - val_loss: 0.3636 - val_accuracy: 0.8438\n",
            "Epoch 929/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3749 - accuracy: 0.8408 - val_loss: 0.3661 - val_accuracy: 0.8411\n",
            "Epoch 930/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3768 - accuracy: 0.8402 - val_loss: 0.3654 - val_accuracy: 0.8417\n",
            "Epoch 931/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3710 - accuracy: 0.8415 - val_loss: 0.3660 - val_accuracy: 0.8426\n",
            "Epoch 932/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3723 - accuracy: 0.8436 - val_loss: 0.3725 - val_accuracy: 0.8370\n",
            "Epoch 933/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3712 - accuracy: 0.8434 - val_loss: 0.3677 - val_accuracy: 0.8403\n",
            "Epoch 934/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3716 - accuracy: 0.8420 - val_loss: 0.3646 - val_accuracy: 0.8431\n",
            "Epoch 935/1000\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3716 - accuracy: 0.8408 - val_loss: 0.3668 - val_accuracy: 0.8415\n",
            "Epoch 936/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3705 - accuracy: 0.8431 - val_loss: 0.3648 - val_accuracy: 0.8424\n",
            "Epoch 937/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3725 - accuracy: 0.8420 - val_loss: 0.3717 - val_accuracy: 0.8387\n",
            "Epoch 938/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3723 - accuracy: 0.8437 - val_loss: 0.3697 - val_accuracy: 0.8389\n",
            "Epoch 939/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3696 - accuracy: 0.8434 - val_loss: 0.3660 - val_accuracy: 0.8421\n",
            "Epoch 940/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3731 - accuracy: 0.8419 - val_loss: 0.3656 - val_accuracy: 0.8425\n",
            "Epoch 941/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3690 - accuracy: 0.8454 - val_loss: 0.3654 - val_accuracy: 0.8420\n",
            "Epoch 942/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3711 - accuracy: 0.8431 - val_loss: 0.3664 - val_accuracy: 0.8417\n",
            "Epoch 943/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3770 - accuracy: 0.8400 - val_loss: 0.3675 - val_accuracy: 0.8406\n",
            "Epoch 944/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3758 - accuracy: 0.8398 - val_loss: 0.3657 - val_accuracy: 0.8419\n",
            "Epoch 945/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3720 - accuracy: 0.8424 - val_loss: 0.3735 - val_accuracy: 0.8373\n",
            "Epoch 946/1000\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3730 - accuracy: 0.8414 - val_loss: 0.3637 - val_accuracy: 0.8431\n",
            "Epoch 947/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3707 - accuracy: 0.8437 - val_loss: 0.3669 - val_accuracy: 0.8410\n",
            "Epoch 948/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3724 - accuracy: 0.8431 - val_loss: 0.3625 - val_accuracy: 0.8451\n",
            "Epoch 949/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3712 - accuracy: 0.8433 - val_loss: 0.3657 - val_accuracy: 0.8431\n",
            "Epoch 950/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3762 - accuracy: 0.8386 - val_loss: 0.3655 - val_accuracy: 0.8423\n",
            "Epoch 951/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3721 - accuracy: 0.8429 - val_loss: 0.3641 - val_accuracy: 0.8437\n",
            "Epoch 952/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3771 - accuracy: 0.8403 - val_loss: 0.3683 - val_accuracy: 0.8391\n",
            "Epoch 953/1000\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3700 - accuracy: 0.8428 - val_loss: 0.3642 - val_accuracy: 0.8434\n",
            "Epoch 954/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3740 - accuracy: 0.8421 - val_loss: 0.3644 - val_accuracy: 0.8444\n",
            "Epoch 955/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3716 - accuracy: 0.8411 - val_loss: 0.3628 - val_accuracy: 0.8447\n",
            "Epoch 956/1000\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3708 - accuracy: 0.8428 - val_loss: 0.3637 - val_accuracy: 0.8442\n",
            "Epoch 957/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3723 - accuracy: 0.8419 - val_loss: 0.3680 - val_accuracy: 0.8403\n",
            "Epoch 958/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3773 - accuracy: 0.8390 - val_loss: 0.3653 - val_accuracy: 0.8419\n",
            "Epoch 959/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3722 - accuracy: 0.8426 - val_loss: 0.3770 - val_accuracy: 0.8344\n",
            "Epoch 960/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3734 - accuracy: 0.8405 - val_loss: 0.3665 - val_accuracy: 0.8415\n",
            "Epoch 961/1000\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3710 - accuracy: 0.8431 - val_loss: 0.3666 - val_accuracy: 0.8415\n",
            "Epoch 962/1000\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3687 - accuracy: 0.8449 - val_loss: 0.3634 - val_accuracy: 0.8438\n",
            "Epoch 963/1000\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3696 - accuracy: 0.8438 - val_loss: 0.3686 - val_accuracy: 0.8398\n",
            "Epoch 964/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3720 - accuracy: 0.8442 - val_loss: 0.3627 - val_accuracy: 0.8440\n",
            "Epoch 965/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3742 - accuracy: 0.8418 - val_loss: 0.3702 - val_accuracy: 0.8384\n",
            "Epoch 966/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3737 - accuracy: 0.8427 - val_loss: 0.3645 - val_accuracy: 0.8427\n",
            "Epoch 967/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3731 - accuracy: 0.8411 - val_loss: 0.3638 - val_accuracy: 0.8426\n",
            "Epoch 968/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3708 - accuracy: 0.8437 - val_loss: 0.3646 - val_accuracy: 0.8420\n",
            "Epoch 969/1000\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3741 - accuracy: 0.8406 - val_loss: 0.3664 - val_accuracy: 0.8428\n",
            "Epoch 970/1000\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3731 - accuracy: 0.8429 - val_loss: 0.3666 - val_accuracy: 0.8412\n",
            "Epoch 971/1000\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3707 - accuracy: 0.8443 - val_loss: 0.3639 - val_accuracy: 0.8442\n",
            "Epoch 972/1000\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3696 - accuracy: 0.8416 - val_loss: 0.3645 - val_accuracy: 0.8434\n",
            "Epoch 973/1000\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3693 - accuracy: 0.8450 - val_loss: 0.3620 - val_accuracy: 0.8444\n",
            "Epoch 974/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3726 - accuracy: 0.8410 - val_loss: 0.3680 - val_accuracy: 0.8406\n",
            "Epoch 975/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3699 - accuracy: 0.8438 - val_loss: 0.3657 - val_accuracy: 0.8423\n",
            "Epoch 976/1000\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3730 - accuracy: 0.8423 - val_loss: 0.3644 - val_accuracy: 0.8426\n",
            "Epoch 977/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3718 - accuracy: 0.8422 - val_loss: 0.3652 - val_accuracy: 0.8424\n",
            "Epoch 978/1000\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3716 - accuracy: 0.8432 - val_loss: 0.3621 - val_accuracy: 0.8437\n",
            "Epoch 979/1000\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3722 - accuracy: 0.8416 - val_loss: 0.3633 - val_accuracy: 0.8453\n",
            "Epoch 980/1000\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3694 - accuracy: 0.8427 - val_loss: 0.3626 - val_accuracy: 0.8465\n",
            "Epoch 981/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3767 - accuracy: 0.8402 - val_loss: 0.3644 - val_accuracy: 0.8436\n",
            "Epoch 982/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3751 - accuracy: 0.8410 - val_loss: 0.3679 - val_accuracy: 0.8402\n",
            "Epoch 983/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3734 - accuracy: 0.8423 - val_loss: 0.3660 - val_accuracy: 0.8415\n",
            "Epoch 984/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3716 - accuracy: 0.8420 - val_loss: 0.3667 - val_accuracy: 0.8421\n",
            "Epoch 985/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3676 - accuracy: 0.8453 - val_loss: 0.3669 - val_accuracy: 0.8414\n",
            "Epoch 986/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3725 - accuracy: 0.8429 - val_loss: 0.3624 - val_accuracy: 0.8449\n",
            "Epoch 987/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3724 - accuracy: 0.8437 - val_loss: 0.3622 - val_accuracy: 0.8449\n",
            "Epoch 988/1000\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3668 - accuracy: 0.8449 - val_loss: 0.3608 - val_accuracy: 0.8463\n",
            "Epoch 989/1000\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.3687 - accuracy: 0.8445 - val_loss: 0.3642 - val_accuracy: 0.8429\n",
            "Epoch 990/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3671 - accuracy: 0.8462 - val_loss: 0.3676 - val_accuracy: 0.8407\n",
            "Epoch 991/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3711 - accuracy: 0.8443 - val_loss: 0.3680 - val_accuracy: 0.8390\n",
            "Epoch 992/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3705 - accuracy: 0.8421 - val_loss: 0.3642 - val_accuracy: 0.8430\n",
            "Epoch 993/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3742 - accuracy: 0.8405 - val_loss: 0.3673 - val_accuracy: 0.8409\n",
            "Epoch 994/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3697 - accuracy: 0.8431 - val_loss: 0.3638 - val_accuracy: 0.8441\n",
            "Epoch 995/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3710 - accuracy: 0.8430 - val_loss: 0.3628 - val_accuracy: 0.8435\n",
            "Epoch 996/1000\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3691 - accuracy: 0.8428 - val_loss: 0.3698 - val_accuracy: 0.8378\n",
            "Epoch 997/1000\n",
            "2532/2532 [==============================] - 6s 3ms/step - loss: 0.3734 - accuracy: 0.8421 - val_loss: 0.3685 - val_accuracy: 0.8392\n",
            "Epoch 998/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3685 - accuracy: 0.8437 - val_loss: 0.3633 - val_accuracy: 0.8460\n",
            "Epoch 999/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3698 - accuracy: 0.8431 - val_loss: 0.3626 - val_accuracy: 0.8452\n",
            "Epoch 1000/1000\n",
            "2532/2532 [==============================] - 6s 2ms/step - loss: 0.3666 - accuracy: 0.8458 - val_loss: 0.3653 - val_accuracy: 0.8416\n",
            "Fold 1, 1000 epochs, 5558 sec\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Li3-YuuU8-gs"
      },
      "source": [
        "## Show Results of MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3HL6lwW9A8j"
      },
      "source": [
        "def show_test_AUC(model, title, X, y):\n",
        "    \"\"\"\n",
        "    From Miller's MLP_GenCode_1??.\n",
        "    \"\"\"\n",
        "    ns_probs = [0 for _ in range(len(y))]\n",
        "    bm_probs = model.predict(X)\n",
        "    ns_auc = roc_auc_score(y, ns_probs)\n",
        "    bm_auc = roc_auc_score(y, bm_probs)\n",
        "    ns_fpr, ns_tpr, _ = roc_curve(y, ns_probs)\n",
        "    bm_fpr, bm_tpr, _ = roc_curve(y, bm_probs)\n",
        "    plt.plot(ns_fpr, ns_tpr, linestyle='--', label='Guess, auc=%.4f'%ns_auc)\n",
        "    plt.plot(bm_fpr, bm_tpr, marker='.', label='Model, auc=%.4f'%bm_auc)\n",
        "    plt.title(title + ' ROC')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    print(\"%s: %.2f%%\" %('AUC',bm_auc*100.0))\n",
        "    \n",
        "def show_test_accuracy(model,X,y):\n",
        "    \"\"\"\n",
        "    From Miller's MLP_GenCode_1??.\n",
        "    \"\"\"\n",
        "    scores = model.evaluate(X, y, verbose=0)\n",
        "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "EeWFq22L9N6G",
        "outputId": "8a5ddb4f-4f0c-4d0f-b406-642f57aa1248"
      },
      "source": [
        "print(\"Accuracy on training data.\")\n",
        "print(\"Prepare...\")\n",
        "X, y = prepare_x_and_y(pc_train, nc_train)\n",
        "print(\"Extract K-mer features...\")\n",
        "X = seqs_to_kmer_freqs(X, MAX_K)\n",
        "print(\"Plot...\")\n",
        "show_test_AUC(last_model, 'Train', X, y)\n",
        "show_test_accuracy(last_model, X, y)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training data.\n",
            "Prepare...\n",
            "Extract K-mer features...\n",
            "Plot...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3hUZfbA8e8h9F4CCISQYGgBQouEoggEFBERFQXLimvbXXXdn65KLKuIrmLD1bWismLFlSZWlI4IUhQDCSAdEnqAUEJCyvn9cSfZACkTkslkZs7nefJk7p33zj2Xcs+89733vKKqGGOMCVyVvB2AMcYY77JEYIwxAc4SgTHGBDhLBMYYE+AsERhjTICzRGCMMQHOEoExxRCRb0VkjLfjMMZTLBEYvyQix/P95IjIyXzLN5bks1T1MlWdco5xbM+3770i8r6I1D6jTR8RmS8ix0QkVUS+FJHIM9rUFZF/ichO12dtcS0Hn0tcxuRnicD4JVWtnfsD7ASuyLfu49x2IlK5HMK5whVHV6Ab8HC+/fcGvge+AJoD4cBvwFIRae1qUxWYB3QEhgB1gd5ACtCzHOI3fs4SgQkoItJfRJJEZKyI7AX+IyINROQrETkgIoddr0PybbNQRG53vb5FRH4UkRddbbeJyGXu7FtV9wJzcBJCrueBD1T1FVU9pqqHVPUxYDkwztXmZiAUuEpVE1U1R1X3q+pTqvpNqf9QTMCzRGAC0XlAQ6AVcCfO/4P/uJZDgZPAa0VsHwNsBIJxTuTviYgUt1NXcrkM2Oxargn0AT4voPl/gcGu14OA71T1eHH7MOZcWCIwgSgHeEJVM1T1pKqmqOp0VU1T1WPAP4GLi9h+h6q+o6rZwBSgGdC0iPazROQYsAvYDzzhWt8Q5//gngK22YOTaAAaFdLGmDJhicAEogOqmp67ICI1ReRtEdkhIkeBxUB9EQkqZPu9uS9UNc31snYhbQFGqGodoD/Qnv+d4A/jJKVmBWzTDDjoep1SSBtjyoQlAhOIziy5+3egHRCjqnWBfq71xV7uKdFOVRcB7wMvupZPAMuAawtofh3OADHAXOBSEalVlvEYk8sSgTFQB2dc4IiINOR/l2484V/AYBHp4lqOA8aIyL0iUsc1cP00zl1BT7rafIhzWWm6iLQXkUoi0khEHhGRoR6M1QQISwTGOCfnGjiXYpYD33lqR6p6APgAeNy1/CNwKXA1zjjADpxbTC9U1U2uNhk4A8YbgB+Ao8AKnEtMP3sqVhM4xCamMcaYwGY9AmOMCXCWCIwxJsBZIjDGmABnicAYYwJceRTcKlPBwcEaFhbm7TCMMcanrF69+qCqNi7oPZ9LBGFhYaxatcrbYRhjjE8RkR2FvWeXhowxJsBZIjDGmABnicAYYwKcJQJjjAlwlgiMMSbAeSwRiMhkEdkvIusKeV9E5FUR2Swi8SLS3VOxGGOMKZwnbx99H2e6vw8Kef8yoI3rJwZ40/XbGGN807h6nt9H8x5w5/wy/UiPJQJVXSwiYUU0uRJn0m4FlotIfRFppqo2JZ8xgebpZpCVVny7AJVbI1oAdq+GSQPLNBl484GyFjiTbeRKcq07KxGIyJ04k4wTGhpaLsEZYyifb7imWGdNlbf3tzL9fJ94slhVJwGTAKKjo20CBWPcZSdyn6X5X7gyQV5COK/LWe1Lw5uJIBlomW85xLXOGHMmu3QSUHLyv3Dd0pN3Z48vjRG4YTZwj4hMxRkkTrXxARMw7Ju6f6tUBR4/WOLNDp84Rf2aVagkwnfr9tK8fnWiQup7IMDTeSwRiMinQH8gWESScCYErwKgqm8B3wBDgc1AGvBHT8VijMfZib3sjEv1dgTlTlWZtSaZJ79MZOyQ9lzfM5Qhnc4rt/178q6h64t5X4G7PbV/Y8qEneD/JwBP0OVh95GTPDpzLQs2HqBbaH2iWzUo9xh8YrDYmDIXiCd4O5FXOF+sSebRmevIzlEeHxbJmD5hBFU66x4hj7NEYPzTMyFw6pi3o/AMO6H7jXo1qtC1ZX2evbozLRvW9FoclgiM7/KXb/V2Yg8YWdk5vPfjNjKzc7hnYBv6t2vCxW0bI1L+vYD8LBGYis0XT/Z2YjcFSNx9lLHT41mbnMrlUc1QVUTE60kALBGYisAXTvZ9/w8GP+ntKIwPysjK5rX5m3lz4Rbq16zCGzd257JO51WIBJDLEoEpPxX1ur19gzcetP1gGm8t2sLwrs35x+WRNKhV1dshncUSgfGMivQt3070ppydyMjih8R9jOjWgnbn1WHe/f0JbeS9weDiWCIwpVcRTvp2sjcVxJJNB3h4xlqSj5ykU4u6RDSpU6GTAFgiMOfCWyd+O9mbCiw1LZN/fpPIf1cl0Tq4Fp/d2ZuIJnW8HZZbLBGY4pXnid9O9sYHZeco17z1E9sOnuCu/udzb2wbqlcJ8nZYbrNEYM5WHid+O+EbP3DoxCnq16hCUCXhwUvb0aJ+DTq1qACXSkvIEoFxePLkbyd942dUlRm/JDP+K6dI3A0xoVzasfyKxJU1SwSBzBMnfzvpGz+XdDiNR2auY/HvB+jRqgE9wxt6O6RSs0QQaMr65G8nfhNAZv6axGMz16HAk8M78oderajkhSJxZc0SQSAoy5O/nfhNAGtYqxo9whryzFWdCGlQsW8JLQlLBP6qrE7+duI3ASwzO4d3lmwlK1u5N7YNF7dtTL82wRWqPERZsETgT+zkb0yZWZecytjp8STsPsoVXZpXqCJxZc0SgT8oiwRgJ39jAEjPzObVeZt4e/FWGtSsyls3dWdIp2beDsujLBH4Kjv5G+MRO1LSeGfJVq7u1oLHLo+kXs0q3g7J4ywR+JrSJAAJgicOlV0sxviJExlZzEnYy9XdQ2h3Xh3m/72/V2cMK2+WCHxFaRKAffM3plCLfj/AIzPWsjv1JFEh9YhoUiegkgBYIqj4zjUB2MnfmCIdPnGKp75OZMYvyZzfuBaf/8l3isSVNUsEFdWEMEg/XLJtbBYtY9ySWyRuR0oa9wyI4J6BET5VJK6sWSKoiEraC7Bv/8a4JeV4Bg1qViWokhA3pD0tGtSgY3PfKxJX1iwRVCSWAIzxCFXl89VJPP1VImMva8+NMa24xIeLxJU1SwQVRUmSgCUAY9y261Aaj8xcy5JNB+kZ1pDerRt5O6QKxxKBt1kCMMZjZvySxGOz1iHAUyM6cWPPUL8oElfWLBF4k7tJwBKAMeckuHY1eoY35J9XdaZF/RreDqfCskTgLZYEjClzmdk5vL1oC9k58LdBbejXtjH92jb2dlgVniWC8mYJwBiPWJecyoPT4lm/5yhXdv1fkThTPEsE5cmtJCAw7ojHQzHGX6RnZvOvuZt4Z8lWGtaqytt/6OHT00Z6g0cTgYgMAV4BgoB3VXXCGe+HAlOA+q42car6jSdj8hp3koD1AowpsZ2H0njvx62M7B7CI0M7BESRuLLmsUQgIkHA68BgIAlYKSKzVTUxX7PHgP+q6psiEgl8A4R5KiavsSRgTJk6lp7Jd+v2cm10S9o2rcOCB/r71Yxh5c2TPYKewGZV3QogIlOBK4H8iUCBuq7X9YDdHozHO4pLAkHV4B/7yycWY/zAgg37eXTmWvYeTadbaH0imtSxJFBKnkwELYBd+ZaTgJgz2owDvheRvwK1gEEFfZCI3AncCRAaGlrmgXpMcUnAegHGuO3QiVM89VUiM39Npk2T2kz7S5+ALRJX1rw9WHw98L6qviQivYEPRaSTqubkb6Sqk4BJANHR0eqFOEvOkoAxZSY7Rxn55k/sPJTGvbFtuHvA+VSrHLhF4sqaJxNBMtAy33KIa11+twFDAFR1mYhUB4IB375WYknAmDJx4FgGjWo5ReIeGdqBFg1q0KFZ3eI3NCVSyYOfvRJoIyLhIlIVGA3MPqPNTiAWQEQ6ANWBAx6MyfMsCRhTaqrKZyt3MvClhXyyYicAgyKbWhLwEI/1CFQ1S0TuAebg3Bo6WVUTRGQ8sEpVZwN/B94RkftwBo5vUVXfuPRTEEsCxpTazpQ04mbE89OWFGLCG3JhRLC3Q/J7Hh0jcD0T8M0Z6x7P9zoR6OvJGMqNJQFjSm3a6iT+MWsdQZWEf17ViesvsCJx5cHbg8X+wZKAMWWiad1q9Dm/EU9f1Ylm9axIXHmxROBplgSMKdSprBzeXLiFHFXuG9yWi9o05qI2ViSuvFkiKK2iegOWBIwp1G+7jvDQtHg27jvG1d1aWJE4L7JEUBqWBIwpsZOnspn4w0be+3EbTepU592boxkU2dTbYQU0SwTGmHK163AaU37aweieocRd1p661a1InLdZIjhX1hswxm1HXUXirnMViVv4YH+a24xhFYYlgrJmScCY08zfsI9HZqxj/7F0uoc2IKJJbUsCFYwlgnNRkgnnjQlQKcczGP9VIl+s2U27pnV46w89iGhS29thmQJYIihL1hswBnCKxF371jJ2HU7jvkFt+Uv/86la2ZMVbUxpWCIoKesNGFOo/cfSCa5VjaBKwqOXdyCkQU3anWelois6t1O0iNjMD0Wx3oAJYDk5ysc/72Dgi4v42FUkLrZDU0sCPqLYRCAifUQkEdjgWu4iIm94PLKKqNDegD0EYwLX9oMnuOHd5Tw6cx1RIfW42J4M9jnuXBp6GbgUVwlpVf1NRPp5NCpfM+6ItyMwxiv+u2oX/5i1jqpBlZhwdWdGXdDSng72QW6NEajqrjP+crM9E04FZmMDxpylRf0a9GvbmKeu7MR59ap7OxxzjtxJBLtEpA+gIlIF+Buw3rNh+RAbGzABJCMrmzcWbEFVuf+SdvSNCKavzRfg89xJBH8GXsGZjD4Z+B64y5NBVTjWGzCGX3ceZuz0eH7fd5xruodYkTg/4k4iaKeqN+ZfISJ9gaWeCcmHWG/ABIC0U1m89P3vTF66jfPqVmfyLdEMbG9F4vyJO4ng30B3N9b5J+sNmACXfPgkHy7fwY0xoYwd0p46ViTO7xSaCESkN9AHaCwi9+d7qy7OHMSBzXoDxo+lnszk27V7GN0zlDZN67Dowf42Y5gfK6pHUBWo7WqT/6mQo8BITwZljPGe7xP28tisdaScOEV0WEMimtS2JODnCk0EqroIWCQi76vqjnKMqeIo7LKQ9QaMHzp4PINxsxP4Kn4P7c+rw7tjoq1IXIBwZ4wgTUReADoCeTcKq+pAj0VljClX2TnKyDd/YveRdB64pC1/uvh8qgRZkbhA4U4i+Bj4DBiGcyvpGOCAJ4MyxpSPfUfTaVzbKRL3xBUdCWlQgzZNrT5QoHEn5TdS1feATFVdpKq3Av7fG7DLQsaP5eQoHy7fQexLi/j4Z+fK74D2TSwJBCh3egSZrt97RORyYDfQ0HMhGWM8aeuB48TNWMuKbYe4MCKY/u2aeDsk42XuJIKnRaQe8Hec5wfqAv/n0agqquB23o7AmFL5bOVOHv8igWqVK/H8yCiu7RFiTweb4hOBqn7lepkKDIC8J4v9V2GXhe5ZUb5xGFPGQhrUpH87p0hck7pWJM44inqgLAi4DqfG0Hequk5EhgGPADWAbuUTojHmXGVkZfPveZsBeOBSKxJnClZUj+A9oCWwAnhVRHYD0UCcqs4qj+AqFruVzviW1TsO8dC0eLYcOMF10VYkzhSuqEQQDUSpao6IVAf2Auerakr5hOYlhd4tdLh84zDmHJ3IyOKFORuZsmw7zevVYMqtPbm4rc0aZgpX1NfcU6qaA6Cq6cDWkiYBERkiIhtFZLOIxBXS5joRSRSRBBH5pCSfb4w52+4jJ/lkxU5u7tWKOff1syRgilVUj6C9iMS7XgtwvmtZAFXVqKI+2DXG8DowGEgCVorIbFVNzNemDfAw0FdVD4uI3cdmzDlITcvk67V7uCHGKRK35KEBNLXBYOOmohJBh1J+dk9gs6puBRCRqcCVQGK+NncAr6vqYQBV3V/KfXqGPURmKrDv1u3lH1+s49CJU8S0bsj5jWtbEjAlUlTRudIWmmsB7Mq3nATEnNGmLYCILMUpbT1OVb8784NE5E7gToDQ0NBShlUEm3vA+JD9x9IZNzuBb9buJbJZXf5zywWc39iKxJmSc2vyeg/vvw3QHwgBFotIZ1U9kr+Rqk4CJgFER0dreQdpTEWTnaNc99Yydqem8+Cl7bizX2srEmfOmScTQTLO7ae5Qlzr8ksCflbVTGCbiPyOkxhWejAuY3zWntSTNK1T3SkSN7wjLRvUtFLRptTc+gohIjVEpKT1FVYCbUQkXESqAqOB2We0mYXTG0BEgnEuFW0t4X48y8YHTAWQk6O8v3QbsS8t4qPcInHtmlgSMGWi2EQgIlcAa4DvXMtdReTME/pZVDULuAeYA6wH/quqCSIyXkSGu5rNAVJEJBFYADzotecUbHzAVFCb9x/nureXMe7LRKLDGjKwvd1cZ8qWO5eGxuHcAbQQQFXXiEi4Ox+uqt8A35yx7vF8rxW43/VjjDnD1BU7eXx2AjWqBPHStV24unsLezrYlDm3ylCrauoZ//hswNaYchDaqCaDOjThyeGdaFynmrfDMX7KnUSQICI3AEGuB8DuBX7ybFgVhI0PmHKWnpnNq/M2AfDQkPb0OT+YPudbkTjjWe4MFv8VZ77iDOATnHLUgTkfgTEetGr7IYa+uoQ3Fm7h0IlTOFdOjfE8d3oE7VX1UeBRTwfjNTZQbLzoeEYWL3y3gQ+W76BF/Rp8cGtP+ll9IFOO3EkEL4nIecA04DNVXefhmIwJKHtTTzJ15S7G9A7jwUvbUauat5/zNIGm2EtDqjoAZ2ayA8DbIrJWRB7zeGTeJkHejsD4scMnTvHhcud5gIgmTpG4ccM7WhIwXuHWA2WquldVXwX+jPNMwePFbOL7njjk7QiMH1JVvlm7h8EvL+LJ2QlsOXAcwKaNNF5V7NcPEekAjAKuAVKAz3AmsvcPNj5gysn+o+n844t1zEnYR+cW9fjg1hgrEmcqBHf6oZNxTv6XqupuD8djjF/KzlGufXsZe1PTefiy9tx2YTiVrUicqSCKTQSq2rs8AjHGH+0+cpLz6jpF4sZf2YmWDWrQ2noBpoIp9CuJiPzX9XutiMTn+1mbb+Yy/2QPkplSys5R/nNGkbiL2za2JGAqpKJ6BH9z/R5WHoEY4y827z/GQ9Pi+WXnEfq3a0xsh6beDsmYIhU1Q9ke18u7VHVs/vdE5Dlg7NlbGRPYPvl5J+NmJ1CrWhAvj+rCiK5WJM5UfO6MVg0uYN1lZR2IV9gdQ6aMhQXX5JKOTfnh/ou5qluIJQHjEwrtEYjIX4C7gNZnjAnUAZZ6OjBjfEF6ZjYvz/0dQYi7zIrEGd9U1BjBJ8C3wLNAXL71x1TVf5+2uu0Hb0dgfMTPW1OIm7GWbQdPcGNMKKpqPQDjk4pKBKqq20Xk7jPfEJGGfpsMWvb0dgSmgjuWnslz323go+U7CW1Yk09uj6FPhPUCjO8qrkcwDFiNMxFN/q86CrT2YFzGVFj7jmYwbXUSt18Yzv2XtKVmVasPZHxbUXcNDXP9dmtaSmP82aETp/g6fjd/6B1GRJPaLHlooM0YZvyGO7WG+gJrVPWEiNwEdAf+pao7PR6dJ9kdQ8YNqspX8XsYNzuBo+mZ9I0IpnXj2pYEjF9x5/bRN4E0EemCU2xuC/ChR6MypgLYdzSdOz5YzV8//ZUWDWrw5V8vtCeDjV9y5+JmlqqqiFwJvKaq74nIbZ4OzCtaD/R2BKaCyM5RrnMViXt0aAf+2DfMisQZv+VOIjgmIg8DfwAuEpFKQBXPhuUlN8/0dgTGy5IOp9GsXg2CKglPXdmJ0IY1CQuu5e2wjPEod77ijMKZuP5WVd0LhAAveDQqY8pZdo7y7pKtDJq4iI9cM4f1a9vYkoAJCO6Uod4rIh8DF4jIMGCFqn7g+dCMKR8b9x7joenx/LbrCLHtm3BJRysSZwKLO3cNXYfTA1iI8yzBv0XkQVWd5uHYPOeHJ7wdgakgPlq+gye/TKBO9Sq8Mrorw7s0t6eDTcBxZ4zgUeACVd0PICKNgbmA7yaCpf/ydgTGy3LLQUQ0qc3Qzs14fFgkjWrbLaEmMLmTCCrlJgGXFNyc9N6YiubkqWwm/rCRSpWEhy/rQK/WjejVupG3wzLGq9xJBN+JyBzgU9fyKOAbz4XkJTYrmd9btiWFuBnx7EhJ4w+9WlmROGNc3BksflBErgYudK2apKp2n6XxGUfTM3n2mw18umInrRrV5JM7YqxUtDH5FDUfQRvgReB8YC3wgKoml1dgxpSV/UczmPVrMnf2a819g9pSo2qQt0MypkIp6lr/ZOAr4BqcCqT/LumHi8gQEdkoIptFJK6IdteIiIpIdEn3YUxBUo5n8P7SbQBENKnNj2MH8MjQDpYEjClAUZeG6qjqO67XG0Xkl5J8sIgEAa/jTHWZBKwUkdmqmnhGuzrA34CfS/L5xhREVZn9227GzU7geEYW/do2pnXj2nZHkDFFKCoRVBeRbvxvHoIa+ZdVtbjE0BPYrKpbAURkKnAlkHhGu6eA54AHSxj7uRlXv1x2Y8rf7iMneWzWOuZv2E/XlvV5fmSUFYkzxg1FJYI9wMR8y3vzLStQXIW2FsCufMtJQEz+BiLSHWipql+LSKGJQETuBO4ECA0NLWa3xdFSbm8qoqzsHEZPWs6BYxn8Y1gkt/QJI6iS3RFkjDuKmphmgCd37CpeNxG4pbi2qjoJmAQQHR1tZ3KTZ9ehNJrXr0HloEo8c1VnQhvWJLRRTW+HZYxP8eSDYclAy3zLIa51ueoAnYCFIrId6AXM9sqAsT1D4HOysnOYtHgLgyYu4sNl2wG4sE2wJQFjzoEnJ1tdCbQRkXCcBDAauCH3TVVNBfJu5haRhTi3qK7yYEzGD6zfc5Sx0+OJT0plcGRTLuvczNshGePTPJYIVDVLRO4B5gBBwGRVTRCR8cAqVZ3tqX0b//Xhsu08+WUi9WpU4bUbunF552b2dLAxpeRO9VEBbgRaq+p4EQkFzlPVFcVtq6rfcEY5ClV9vJC2/d2K2ASk3HIQbZvW4YouzfnHsEga1qrq7bCM8Qvu9AjeAHJw7hIaDxwDpgMXeDAuYwBIO5XFi3N+p3KQ8MjQDsS0bkSMFYkzpky5M1gco6p3A+kAqnoYsK9ixuOWbj7Ipf9azOSl2ziVlYOq3TBmjCe40yPIdD0lrJA3H0GOR6MyAS31ZCbPfL2ez1btIjy4Fv/9U296hjf0dljG+C13EsGrwEygiYj8ExgJPObRqExAO3g8gy/jd/Pni8/n/wa1oXoVqw9kjCe5U4b6YxFZDcTilJcYoarrPR6ZJ7zW09sRmEIcOJbBl7/t5tYLwzm/cW1+HDvQBoONKSfu3DUUCqQBX+Zfp6o7PRmYRxzc6O0IzBlUlVlrknnyy0TSMrIZ0L4J4cG1LAkYU47cuTT0Nc74gADVgXBgI9DRg3GZAJB85CSPzlzLwo0H6B7qFIkLD67l7bCMCTjuXBrqnH/ZVSjuLo9FVN6svIRXOEXilpFy/BTjrojkD72tSJwx3lLiJ4tV9RcRiSm+pTFn25mSRosGTpG4CVdHEdqwJi0bWn0gY7zJnTGC+/MtVgK6A7s9FpHxS1nZObyzZBsvz/2dhy9rzx/7htM3wuYNNqYicKdHUCff6yycMYPpngnH+KOE3amMnR7PuuSjXNqxKZdbkThjKpQiE4HrQbI6qvpAOcVj/MyUn7bz1FeJ1K9ZlTdv7G6VQo2pgApNBCJS2VVBtG95BmT8Q26RuPbn1eHKri34x7AO1K9pt4QaUxEV1SNYgTMesEZEZgOfAydy31TVGR6OzfigExlZvDBnI1WChEcvj7Qiccb4AHfGCKoDKTjVR3OfJ1DAEoE5zeLfD/DwjLXsTj3JmN5heb0CY0zFVlQiaOK6Y2gd/0sAuawMpMmTmpbJU18nMm11Eq0bO0XiLgizInHG+IqiEkEQUJvTE0AuSwQmz8ETGXy7dg939T+fe2OtSJwxvqaoRLBHVceXWyTGp+w/ls7sNbu5/aLWeUXiGlh9IGN8UlGJwC7umrOoKtN/SeaprxI5mZlNbIemhAfXsiRgjA8rKhHEllsUxifsOpTGIzPXsmTTQaJbNWDCNVYkzhh/UGgiUNVD5RmIqdiysnO4/p3lHD5xiqeu7MiNMa2oZEXijPELJS46ZwLL9oMnaNmwJpWDKvH8SKdIXEgDKxJnjD9xZ/J6E4Ays3N4fcFmLnl5MR8s2w5An/ODLQkY44esR2DOsi45lYemxZO45yiXd27GsKjm3g7JGONBlgjMaf6zdBtPf72ehrWq8tZNPRjS6Txvh2SM8bDASQQvtPV2BBVabjmIjs3rcXW3Fjx2eST1albxdljGmHIQOIngxD5vR1AhHc/I4vnvNlA1qBKPDYukZ3hDeoZbeQhjAkmADxYH9uEv3LifS19ezIfLd6A4vQJjTOAJnB5BQcYd9nYEXnH4xCme+jqRGb8kE9GkNtP+3IcerRp4OyxjjJcEdiIIUIfTTvF9wj7uHRjB3QMjqFbZisQZE8g8em1ERIaIyEYR2SwicQW8f7+IJIpIvIjME5FWnownkO0/ms6kxVtQVVo3rs3SsQO5/5J2lgSMMZ5LBK75jl8HLgMigetFJPKMZr8C0aoaBUwDnvdUPIFKVfnvyl3ETlzES9//zvaUNAC7I8gYk8eTl4Z6AptVdSuAiEwFrgQScxuo6oJ87ZcDN3kwnoCz61AaD89Yy4+bD9IzvCETru5sReKMMWfxZCJoAezKt5wExBTR/jbg24LeEJE7gTsBQkNDyyo+v5ZbJO5IWiZPj+jEDT1DrUicMaZAFWKwWERuAqKBiwt6X1UnAZMAoqOj7R7HImw7eIJQV5G4F0Z2oVWjmjSvX8PbYRljKjBPDhYnAy3zLYe41p1GRAYBjwLDVTXDg/H4tczsHP49bxOXvryYKT9tB6D3+Y0sCRhjiuXJHsFKoI2IhOMkgNHADfkbiEg34G1giKru92Asfi0+6QgPTYtnw95jXNGlOcO7WpE4Y4z7PJYIVDVLRO4B5gBBwGRVTRCR8cAqVZ0NvADUBj4XEYCdqjrcUzH5o8k/buPprxNpXKca7y7VlBwAABmuSURBVNwczeDIpt4OyRjjYzw6RqCq3wDfnLHu8XyvB3ly//4st0hcVEg9Rl3QkrjLOlCvht0SaowpuQoxWGzcdyw9kwnfbqBa5SAevyKS6LCGRIdZkThjzLkL7KprPmbBhv1c8vJiPl2xk8pBYkXijDFlwnoEPuDQiVOM/zKBWWt207Zpbd64sQ/dQq1InDGmbFgi8AGpJzOZt34/f4ttw90DIqha2TpyxpiyY4mggtqbms6sNcn8qV9rwoNr8WPcQBsMNsZ4hCWCCkZVmbpyF898vZ7MnByGdDyPsOBalgSMMR5jiaAC2ZFygrjpa1m2NYVerRsy4eoowqxInClCZmYmSUlJpKenezsUU0FUr16dkJAQqlRx/8ujJYIKIis7hxve+ZnUk5k8c1VnRl/Q0orEmWIlJSVRp04dwsLCcD2UaQKYqpKSkkJSUhLh4eFub2eJwMu2HDhOK1eRuJeuc4rENatn9YGMe9LT0y0JmDwiQqNGjThw4ECJtrPbT7zkVFYO/5r7O0P+tZgPlu0AoFfrRpYETIlZEjD5ncu/B+sReMGaXUcYOy2ejfuOcWXX5ozo1sLbIRljApj1CMrZez9u4+o3lpJ6MpP3xkTzyuhuNKxV1dthGXPO9u3bxw033EDr1q3p0aMHvXv3ZubMmd4Oq1wcOnSIwYMH06ZNGwYPHszhw4cLbBcUFETXrl3p2rUrw4f/r67mtm3biImJISIiglGjRnHq1CkAMjIyGDVqFBEREcTExLB9+/a8bZ599lkiIiJo164dc+bMKZPjsERQTnLLQXRtWY/RPUP5/v5+xHawSqHGt6kqI0aMoF+/fmzdupXVq1czdepUkpKSvB1auZgwYQKxsbFs2rSJ2NhYJkyYUGC7GjVqsGbNGtasWcPs2bPz1o8dO5b77ruPzZs306BBA9577z0A3nvvPRo0aMDmzZu57777GDt2LACJiYlMnTqVhIQEvvvuO+666y6ys7NLfRyWCDzsaHomD89Yy/ivnKmae7RqyDNXdaZudXsuwJS9UW8vO+vnw2XbATh5KrvA9z9f5cwoe+jEqbPeK878+fOpWrUqf/7zn/PWtWrVir/+9a8AvP/++9xzzz157w0bNoyFCxcC8P3339O7d2+6d+/Otddey/HjxwGIi4sjMjKSqKgoHnjgAQA+//xzOnXqRJcuXejXr1+xcY0YMYIePXrQsWNHJk2alLe+du3aea+nTZvGLbfcAji9mquuuoouXbrQpUsXfvrpp2L3AfDFF18wZswYAMaMGcOsWbPc2g6cJDp//nxGjhx51vb5P3fkyJHMmzcPVeWLL75g9OjRVKtWjfDwcCIiIlixYoXb+yyMjRF40NzEfTw6ay0HjmVwR7/WeaWjjfEXCQkJdO/evcTbHTx4kKeffpq5c+dSq1YtnnvuOSZOnMjdd9/NzJkz2bBhAyLCkSNHABg/fjxz5syhRYsWeeuKMnnyZBo2bMjJkye54IILuOaaa2jUqFGh7e+9914uvvhiZs6cSXZ2dl5Suuiiizh27NhZ7V988UUGDRrEvn37aNasGQDnnXce+/btK/Dz09PTiY6OpnLlysTFxTFixAhSUlKoX78+lSs7p+GQkBCSk51JHJOTk2nZ0pngsXLlytSrV4+UlBSSk5Pp1atX3ufm36Y0AiMRPBNSrrtLOZ7Bk18mMvu33bQ/rw6T/hBNl5b1yzUGE5g++1PvQt+rUTWoyPcb1qpa5PvuuPvuu/nxxx+pWrUqK1euLLTd8uXLSUxMpG/fvgCcOnWK3r17U69ePapXr85tt93GsGHDGDZsGAB9+/bllltu4brrruPqq68uNo5XX301b5xi165dbNq0qchEMH/+fD744APAuZ5fr149AJYsWeLegePcrVPYF70dO3bQokULtm7dysCBA+ncuXPePiqCwEgEp87O6J50LD2LBRv3c9+gtvyl//lWJM74rY4dOzJ9+vS85ddff52DBw8SHR0NON9mc3Jy8t7PfQJaVRk8eDCffvrpWZ+5YsUK5s2bx7Rp03jttdeYP38+b731Fj///DNff/01PXr0YPXq1YWe2BcuXMjcuXNZtmwZNWvWpH///nn7zX+idudp7OJ6BE2bNmXPnj00a9aMPXv20KRJkwI/p0UL587A1q1b079/f3799VeuueYajhw5QlZWFpUrVyYpKSmvXYsWLdi1axchISFkZWWRmppKo0aN8tbnyr9NaQTuGeq2H8r043YfOcnrCzajqoQF12Jp3ED+NqiNJQHj1wYOHEh6ejpvvvlm3rq0tLS812FhYaxZs4acnBx27dqVdz27V69eLF26lM2bNwNw4sQJfv/9d44fP05qaipDhw7l5Zdf5rfffgNgy5YtxMTEMH78eBo3bsyuXbtITk4mNjb2rJhSU1Np0KABNWvWZMOGDSxfvjzvvaZNm7J+/XpycnJOu7MpNjY27xiys7NJTU0FnB5B7iBv/p9Bg5zJFYcPH86UKVMAmDJlCldeeeVZ8Rw+fJiMjAzAuSS2dOlSIiMjEREGDBjAtGnTzto+/+dOmzaNgQMHIiIMHz6cqVOnkpGRwbZt29i0aRM9e/Z082+rcIF7lmpZ+j88gJwc5aPlO7jk5cW8Nn8zO1Kc/wQ2GGwCgYgwa9YsFi1aRHh4OD179mTMmDE899xzgHNJJzw8nMjISO6999688YTGjRvz/vvvc/311xMVFUXv3r3ZsGEDx44dY9iwYURFRXHhhRcyceJEAB588EE6d+5Mp06d6NOnD126dGHPnj1519fzGzJkCFlZWXTo0IG4uLjTrqlPmDCBYcOG0adPn7xr+wCvvPIKCxYsoHPnzvTo0YPExES3jj8uLo4ffviBNm3aMHfuXOLi4gBYtWoVt99+OwDr168nOjqaLl26MGDAgLzBcCBvbCQiIoKUlBRuu+02AG677TZSUlKIiIhg4sSJeXcjdezYkeuuu47IyEiGDBnC66+/TlBQkPt/YYUQX5vlKjo6WletWlWyjcYVcC1uXGqpY9l28ARx0+P5edsh+kY04tmroghtVLPUn2uMu9avX0+HDh28HYZXvPbaa4SGhp52X75xFPTvQkRWq2p0Qe0DY4zAA7Kyc7jp3Z85mp7J89dEcW10iN0RZEw5yn9bqikdSwQltHn/McIa1aJyUCVeHtWVVo1q0rRudW+HZYwx5yxwxwhKKCMrm4k//M6Qfy1hiqtIXM/whpYEjDE+z3oEbvhl52HGTotn0/7jXN2tBVdbkThjjB+xRFCMdxZv5Zlv19OsbnX+88cLGNCu4PuEjTHGV1kiKEROjlKpktC9VX1ujAll7JD21LFbQo0xfsjGCM6QejKTh6b9xpNfJgBOkbinR3S2JGBMIUSEm266KW85KyuLxo0b55WHcFdYWBgHDx4sdZvyoqrce++9REREEBUVxS+//FJgu88++4yoqCg6duyYV0UUYOLEiXnF9WJjY9mxwxl73LFjB927d6dr16507NiRt956K2+bRx99lJYtW55WPK8sWCLIZ07CXgZPXMT0X5KpVa0yvvaMhTFu2bUClrzk/C4DtWrVYt26dZw8eRKAH374oUzKHlR03377LZs2bWLTpk1MmjSJv/zlL2e1SUlJ4cEHH2TevHkkJCSwd+9e5s2bB0C3bt1YtWoV8fHxjBw5koceegiAZs2asWzZMtasWcPPP//MhAkT2L17NwBXXHFFmVQbPZNdGgIOHs/giS8S+HrtHiKb1WXyLRfQqUXFKQhljFu+jYO9a4tuk3EU9q0DzQGpBE07QbW6hbc/rzNcVnCN/fyGDh3K119/zciRI/n000+5/vrr8wq2HTp0iFtvvZWtW7dSs2ZNJk2aRFRUFCkpKVx//fUkJyfTu3fv0754ffTRR7z66qucOnWKmJgY3njjDbefoB0/fjxffvklJ0+epE+fPrz99tuICP379+fFF18kOjo6rx7S9u3byc7OZuzYsXz33XdUqlSJO+64I6+MdlG++OILbr75ZkSEXr16ceTIkby6Q7m2bt1KmzZtaNy4MQCDBg1i+vTpxMbGMmDAgLx2vXr14qOPPgKgatX/TVSVkZFxWq2m/E9JlyXrEQDH07NYsukAD17aji/u6WtJwPiv9FQnCYDzO730T9gDjB49mqlTp5Kenk58fDwxMTF57z3xxBN069aN+Ph4nnnmGW6++WYAnnzySS688EISEhK46qqr2LlzJ+A8FfvZZ5+xdOlS1qxZQ1BQEB9//LHbsdxzzz2sXLkyr5fy1VdfFdl+0qRJbN++nTVr1hAfH8+NN94IwH333Zc3q1j+n9xyD/lLRUPBJaEjIiLYuHEj27dvJysri1mzZp1WNC7Xe++9x2WXXZa3vGvXLqKiomjZsiVjx46lefPmbh//uQjYHkHykZPM/CWJuwdEEBZci58ejqV2tYD94zD+wI1v7uxaAVOGQ/YpCKoK17xbJnW3oqKi2L59O59++ilDhw497b0ff/wxr0LpwIEDSUlJ4ejRoyxevJgZM2YAcPnll9OgQQMA5s2bx+rVq7ngggsAOHnyZKFVPQuyYMECnn/+edLS0jh06BAdO3bkiiuuKLT93Llz+fOf/5xXt6hhw4YAvPzyy27vszANGjTgzTffZNSoUVSqVIk+ffqwZcuW09p89NFHrFq1ikWLFuWta9myJfHx8ezevZsRI0YwcuRImjb13IyGHj3zicgQ4BUgCHhXVSec8X414AOgB5ACjFLV7Z6MSV0/l0xcRI7CsKjmhAXXsiRgAkPLnjBmNmxfAmEXlVnxRXAqZj7wwAMsXLiQlJSUc/4cVWXMmDE8++yzJd42PT2du+66i1WrVtGyZUvGjRuXV246f0lsd0pQ33fffSxYsOCs9aNHjyYuLs7tktBXXHFFXiKaNGnSaZe45s6dyz//+U8WLVpEtWrVztq2efPmdOrUiSVLluTNZOYJHrs0JCJBwOvAZUAkcL2IRJ7R7DbgsKpGAC8Dz3kqnvxycqB7qwZ8f18/woJrlccujak4WvaEi/5epkkA4NZbb+WJJ56gc+fOp62/6KKL8i7tLFy4kODgYOrWrUu/fv345JNPAGfgNXfi99jYWKZNm8b+/fsBZ4wh946a/GJjY8+6FJN7gg8ODub48eN5JZ7BueNo9erVAKetHzx4MG+//TZZWVl5+wOnR1BQCercCqPDhw/ngw8+QFVZvnw59erVO218IFfucRw+fJg33ngjryrpr7/+yp/+9Cdmz559Wo8nKSkpb+D98OHD/Pjjj7Rr167AP/Oy4skxgp7AZlXdqqqngKnAmcW6rwSmuF5PA2LFI5XbhNPu/6kEH9zak5YNrVKoMWUlJCSEe++996z148aNY/Xq1URFRREXF5dXZ/+JJ55g8eLFdOzYkRkzZhAaGgpAZGQkTz/9NJdccglRUVEMHjyYPXv2nPaZOTk5bN68Oe8yTq769etzxx130KlTJy699NK8y0sADzzwAG+++SbdunU77RbU22+/ndDQUKKioujSpUtecirO0KFDad26NREREdxxxx288cYbee917do17/Xf/vY3IiMj6du3L3FxcbRt2xZwSmsfP36ca6+9lq5du+ZVUV2/fj0xMTF06dKFiy++mAceeCAvuT700EOEhISQlpZGSEgI48aNcyvW4nisDLWIjASGqOrtruU/ADGqek++NutcbZJcy1tcbQ6e8Vl3AncChIaG9ijo20GRxgdDTibgXBaSSlXg8YpxL7IxpRGoZajXrVvH5MmT8+YrMKcraRlqn7hrSFUnqWq0qkbn3oZVIh2vynspZywbY3xPp06dLAmUIU+OkCYDLfMth7jWFdQmSUQqA/VwBo3L1jXvOL83/wARg/+3bIwxxqOJYCXQRkTCcU74o4EbzmgzGxgDLANGAvPVU9eq7ORv/JSq2qRIJs+5nEI9dmlIVbOAe4A5wHrgv6qaICLjRSR3brn3gEYishm4H4jzVDzG+KPq1auTkpJi5VAM4CSBlJQUqlcv2TwpgTFnsTF+KjMzk6SkJLfuizeBoXr16oSEhFClyumFMm3OYmP8VJUqVQgPD/d2GMbH+cRdQ8YYYzzHEoExxgQ4SwTGGBPgfG6wWEQOACV8tDhPMBBojxTbMQcGO+bAUJpjbqWqBT6R63OJoDREZFVho+b+yo45MNgxBwZPHbNdGjLGmABnicAYYwJcoCWCSd4OwAvsmAODHXNg8MgxB9QYgTHGmLMFWo/AGGPMGSwRGGNMgPPLRCAiQ0Rko4hsFpGzKpqKSDUR+cz1/s8iElb+UZYtN475fhFJFJF4EZknIq28EWdZKu6Y87W7RkRURHz+VkN3jllErnP9XSeIiHvzLlZgbvzbDhWRBSLyq+vf91BvxFlWRGSyiOx3zeBY0PsiIq+6/jziRaR7qXeqqn71AwQBW4DWQFXgNyDyjDZ3AW+5Xo8GPvN23OVwzAOAmq7XfwmEY3a1qwMsBpYD0d6Ouxz+ntsAvwINXMtNvB13ORzzJOAvrteRwHZvx13KY+4HdAfWFfL+UOBbnAkXewE/l3af/tgj6AlsVtWtqnoKmApceUabK4EprtfTgFjx7Zk9ij1mVV2gqmmuxeU4M8b5Mnf+ngGeAp4D/KFOszvHfAfwuqoeBlDV/eUcY1lz55gVqOt6XQ/YXY7xlTlVXQwcKqLJlcAH6lgO1BeRZqXZpz8mghbArnzLSa51BbZRZwKdVKBRuUTnGe4cc3634Xyj8GXFHrOry9xSVb8uz8A8yJ2/57ZAWxFZKiLLRWRIuUXnGe4c8zjgJhFJAr4B/lo+oXlNSf+/F8vmIwgwInITEA1c7O1YPElEKgETgVu8HEp5q4xzeag/Tq9vsYh0VtUjXo3Ks64H3lfVl0SkN/ChiHRS1RxvB+Yr/LFHkAy0zLcc4lpXYBsRqYzTnUwpl+g8w51jRkQGAY8Cw1U1o5xi85TijrkO0AlYKCLbca6lzvbxAWN3/p6TgNmqmqmq24DfcRKDr3LnmG8D/gugqsuA6jjF2fyVW//fS8IfE8FKoI2IhItIVZzB4NlntJkNjHG9HgnMV9cojI8q9phFpBvwNk4S8PXrxlDMMatqqqoGq2qYqobhjIsMV1VfnufUnX/bs3B6A4hIMM6loq3lGWQZc+eYdwKxACLSAScRHCjXKMvXbOBm191DvYBUVd1Tmg/0u0tDqpolIvcAc3DuOJisqgkiMh5Ypaqzgfdwuo+bcQZlRnsv4tJz85hfAGoDn7vGxXeq6nCvBV1Kbh6zX3HzmOcAl4hIIpANPKiqPtvbdfOY/w68IyL34Qwc3+LLX+xE5FOcZB7sGvd4AqgCoKpv4YyDDAU2A2nAH0u9Tx/+8zLGGFMG/PHSkDHGmBKwRGCMMQHOEoExxgQ4SwTGGBPgLBEYY0yAs0RgKiQRyRaRNfl+wopoe7wM9ve+iGxz7esX1xOqJf2Md0Uk0vX6kTPe+6m0Mbo+J/fPZZ2IfCki9Ytp39XXq3Eaz7PbR02FJCLHVbV2Wbct4jPeB75S1WkicgnwoqpGleLzSh1TcZ8rIlOA31X1n0W0vwWn6uo9ZR2L8R/WIzA+QURqu+ZR+EVE1orIWZVGRaSZiCzO9435Itf6S0RkmWvbz0WkuBP0YiDCte39rs9aJyL/51pXS0S+FpHfXOtHudYvFJFoEZkA1HDF8bHrveOu31NF5PJ8Mb8vIiNFJEhEXhCRla4a839y449lGa5iYyLS03WMv4rITyLSzvUk7nhglCuWUa7YJ4vIClfbgiq2mkDj7drb9mM/Bf3gPBW7xvUzE+cp+Lqu94JxnqrM7dEed/3+O/Co63UQTr2hYJwTey3X+rHA4wXs731gpOv1tcDPQA9gLVAL56nsBKAbcA3wTr5t67l+L8Q150FuTPna5MZ4FTDF9boqThXJGsCdwGOu9dWAVUB4AXEez3d8nwNDXMt1gcqu14OA6a7XtwCv5dv+GeAm1+v6OLWIann779t+vPvjdyUmjN84qapdcxdEpArwjIj0A3Jwvgk3Bfbm22YlMNnVdpaqrhGRi3EmK1nqKq1RFeebdEFeEJHHcOrU3IZTv2amqp5wxTADuAj4DnhJRJ7DuZy0pATH9S3wiohUA4YAi1X1pOtyVJSIjHS1q4dTLG7bGdvXEJE1ruNfD/yQr/0UEWmDU2ahSiH7vwQYLiIPuJarA6GuzzIByhKB8RU3Ao2BHqqaKU5F0er5G6jqYleiuBx4X0QmAoeBH1T1ejf28aCqTstdEJHYghqp6u/izHUwFHhaROap6nh3DkJV00VkIXApMApnohVwZpv6q6rOKeYjTqpqVxGpiVN/527gVZwJeBao6lWugfWFhWwvwDWqutGdeE1gsDEC4yvqAftdSWAAcNacy+LMw7xPVd8B3sWZ7m850FdEcq/51xKRtm7ucwkwQkRqikgtnMs6S0SkOZCmqh/hFPMraM7YTFfPpCCf4RQKy+1dgHNS/0vuNiLS1rXPAqkz29y9wN/lf6XUc0sR35Kv6TGcS2S55gB/FVf3SJyqtCbAWSIwvuJjIFpE1gI3AxsKaNMf+E1EfsX5tv2Kqh7AOTF+KiLxOJeF2ruzQ1X9BWfsYAXOmMG7qvor0BlY4bpE8wTwdAGbTwLicweLz/A9zsRAc9WZfhGcxJUI/CLOpOVvU0yP3RVLPM7ELM8Dz7qOPf92C4DI3MFinJ5DFVdsCa5lE+Ds9lFjjAlw1iMwxpgAZ4nAGGMCnCUCY4wJcJYIjDEmwFkiMMaYAGeJwBhjApwlAmOMCXD/D2dJDwbd/THSAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "AUC: 92.31%\n",
            "accuracy: 84.81%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "LQY5Hze-9hl9",
        "outputId": "f784adbb-9a08-42a4-f8b2-febf85807134"
      },
      "source": [
        "print(\"Accuracy on test data.\")\n",
        "print(\"Prepare...\")\n",
        "X, y = prepare_x_and_y(pc_test, nc_test)\n",
        "print(\"Extract K-mer features...\")\n",
        "X = seqs_to_kmer_freqs(X, MAX_K)\n",
        "print(\"Plot...\")\n",
        "show_test_AUC(last_model, 'Test', X, y)\n",
        "show_test_accuracy(last_model, X, y)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on test data.\n",
            "Prepare...\n",
            "Extract K-mer features...\n",
            "Plot...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "AUC: 93.47%\n",
            "accuracy: 86.04%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}