{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ojm_6E9f9Kcf"
   },
   "source": [
    "# Wen CNN \n",
    "\n",
    "Run on Alien with libcudnn8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RmPF4h_YI_sT",
    "outputId": "e3a5189d-adb3-4019-bdb2-7f3dc89c0be0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-12 07:04:04 EDT\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "def show_time():\n",
    "    t = time.time()\n",
    "    print(time.strftime('%Y-%m-%d %H:%M:%S %Z', time.localtime(t)))\n",
    "show_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "VQY7aTj29Kch"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-12 07:04:04.560222: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D\n",
    "from keras.layers import Dense,Embedding,Dropout\n",
    "from keras.layers import Flatten,TimeDistributed\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xUxEB53HI_sk",
    "outputId": "2c74446f-72cc-4429-8ead-d49d1bb45ae7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoLab not working. On my PC, use relative paths.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "IN_COLAB = False\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    pass\n",
    "if IN_COLAB:\n",
    "    print(\"On Google CoLab, mount cloud-local file, get our code from GitHub.\")\n",
    "    PATH='/content/drive/'\n",
    "    #drive.mount(PATH,force_remount=True)  # hardly ever need this\n",
    "    drive.mount(PATH)    # Google will require login credentials\n",
    "    DATAPATH=PATH+'My Drive/data/'  # must end in \"/\"\n",
    "    import requests\n",
    "    r = requests.get('https://raw.githubusercontent.com/ShepherdCode/Soars2021/master/SimTools/RNA_describe.py')\n",
    "    with open('RNA_describe.py', 'w') as f:\n",
    "        f.write(r.text)  \n",
    "    from RNA_describe import ORF_counter\n",
    "    r = requests.get('https://raw.githubusercontent.com/ShepherdCode/Soars2021/master/SimTools/GenCodeTools.py')\n",
    "    with open('GenCodeTools.py', 'w') as f:\n",
    "        f.write(r.text)  \n",
    "    from GenCodeTools import GenCodeLoader\n",
    "    r = requests.get('https://raw.githubusercontent.com/ShepherdCode/Soars2021/master/SimTools/KmerTools.py')\n",
    "    with open('KmerTools.py', 'w') as f:\n",
    "        f.write(r.text)  \n",
    "    from KmerTools import KmerTools\n",
    "else:\n",
    "        print(\"CoLab not working. On my PC, use relative paths.\")\n",
    "        DATAPATH='data/'  # must end in \"/\"\n",
    "        sys.path.append(\"..\") # append parent dir in order to use sibling dirs\n",
    "        from SimTools.RNA_describe import ORF_counter\n",
    "        from SimTools.GenCodeTools import GenCodeLoader\n",
    "        from SimTools.KmerTools import KmerTools\n",
    "BESTMODELPATH=DATAPATH+\"BestModel-Wen\"  # saved on cloud instance and lost after logout\n",
    "LASTMODELPATH=DATAPATH+\"LastModel-Wen\"  # saved on Google Drive but requires login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8buAhZRfI_sp"
   },
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h94xptH1tI82",
    "outputId": "4dee976e-3b4a-4968-9c8b-2e5243bc3a69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-12 07:04:05 EDT\n"
     ]
    }
   ],
   "source": [
    "PC_TRAINS=8000\n",
    "NC_TRAINS=8000\n",
    "PC_TESTS=2000\n",
    "NC_TESTS=2000   \n",
    "PC_LENS=(200,4000)\n",
    "NC_LENS=(200,4000)   # Wen used 3500 for hyperparameter, 3000 for train\n",
    "PC_FILENAME='gencode.v38.pc_transcripts.fa.gz'\n",
    "NC_FILENAME='gencode.v38.lncRNA_transcripts.fa.gz'\n",
    "PC_FULLPATH=DATAPATH+PC_FILENAME\n",
    "NC_FULLPATH=DATAPATH+NC_FILENAME\n",
    "MAX_K = 3 \n",
    "# With K={1,2,3}, num K-mers is 4^3 + 4^2 + 4^1 = 84.\n",
    "# Wen specified 17x20 which is impossible.\n",
    "# The factors of 84 are 1, 2, 3, 4, 6, 7, 12, 14, 21, 28, 42 and 84.\n",
    "FRQ_CNT=84\n",
    "ROWS=7\n",
    "COLS=FRQ_CNT//ROWS\n",
    "SHAPE2D = (ROWS,COLS,1)\n",
    "EPOCHS=100 # 1000 # 200\n",
    "SPLITS=5\n",
    "FOLDS=5   # make this 5 for serious testing\n",
    "show_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VNnPagXjtI85",
    "outputId": "95ae7ea4-0b93-45b9-83c6-8239e639e5a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PC seqs loaded: 70825\n",
      "NC seqs loaded: 48752\n",
      "2021-08-12 07:04:07 EDT\n"
     ]
    }
   ],
   "source": [
    "loader=GenCodeLoader()\n",
    "loader.set_label(1)\n",
    "loader.set_check_utr(True)\n",
    "pcdf=loader.load_file(PC_FULLPATH)\n",
    "print(\"PC seqs loaded:\",len(pcdf))\n",
    "loader.set_label(0)\n",
    "loader.set_check_utr(False)\n",
    "ncdf=loader.load_file(NC_FULLPATH)\n",
    "print(\"NC seqs loaded:\",len(ncdf))\n",
    "show_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ShtPw_fGtI9E",
    "outputId": "d818a99b-cf67-4a47-d0e8-5f305ac3b01f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-12 07:04:07 EDT\n",
      "PC seqs pass filter: 55381\n",
      "NC seqs pass filter: 46919\n"
     ]
    }
   ],
   "source": [
    "def dataframe_length_filter(df,low_high):\n",
    "    (low,high)=low_high\n",
    "    # The pandas query language is strange, \n",
    "    # but this is MUCH faster than loop & drop.\n",
    "    return df[ (df['seqlen']>=low) & (df['seqlen']<=high) ]\n",
    "def dataframe_extract_sequence(df):\n",
    "    return df['sequence'].tolist()\n",
    "\n",
    "pc_all = dataframe_extract_sequence(\n",
    "    dataframe_length_filter(pcdf,PC_LENS))\n",
    "nc_all = dataframe_extract_sequence(\n",
    "    dataframe_length_filter(ncdf,NC_LENS))\n",
    "\n",
    "show_time()\n",
    "print(\"PC seqs pass filter:\",len(pc_all))\n",
    "print(\"NC seqs pass filter:\",len(nc_all))\n",
    "# Garbage collection to reduce RAM footprint\n",
    "pcdf=None\n",
    "ncdf=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CCNh_FZaI_sv"
   },
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V91rP2osI_s1",
    "outputId": "17779fb5-e420-4192-a375-1dde568341df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PC train, NC train: 8000 8000\n",
      "PC test, NC test: 2000 2000\n"
     ]
    }
   ],
   "source": [
    "pc_train=pc_all[:PC_TRAINS] \n",
    "nc_train=nc_all[:NC_TRAINS]\n",
    "print(\"PC train, NC train:\",len(pc_train),len(nc_train))\n",
    "pc_test=pc_all[PC_TRAINS:PC_TRAINS+PC_TESTS] \n",
    "nc_test=nc_all[NC_TRAINS:NC_TRAINS+PC_TESTS]\n",
    "print(\"PC test, NC test:\",len(pc_test),len(nc_test))\n",
    "# Garbage collection\n",
    "pc_all=None\n",
    "nc_all=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FfyPeInGI_s4",
    "outputId": "4004ab4a-f5e7-41e7-f6d6-4010f6a056d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-12 07:04:07 EDT\n"
     ]
    }
   ],
   "source": [
    "def prepare_x_and_y(seqs1,seqs0):\n",
    "    len1=len(seqs1)\n",
    "    len0=len(seqs0)\n",
    "    total=len1+len0\n",
    "    L1=np.ones(len1,dtype=np.int8)\n",
    "    L0=np.zeros(len0,dtype=np.int8)\n",
    "    S1 = np.asarray(seqs1)\n",
    "    S0 = np.asarray(seqs0)\n",
    "    all_labels = np.concatenate((L1,L0))\n",
    "    all_seqs = np.concatenate((S1,S0))  \n",
    "    # interleave (uses less RAM than shuffle)\n",
    "    for i in range(0,len0):\n",
    "        all_labels[i*2] = L0[i]\n",
    "        all_seqs[i*2] = S0[i]\n",
    "        all_labels[i*2+1] = L1[i]\n",
    "        all_seqs[i*2+1] = S1[i]\n",
    "    return all_seqs,all_labels  # use this to test unshuffled\n",
    "    X,y = shuffle(all_seqs,all_labels) # sklearn.utils.shuffle \n",
    "    return X,y\n",
    "Xseq,y=prepare_x_and_y(pc_train,nc_train)\n",
    "#print(Xseq[:3])\n",
    "#print(y[:3])\n",
    "show_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LWLixZOfI_s7",
    "outputId": "cab949b4-8a4d-489e-cd2d-6b3f935a9a16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-12 07:04:12 EDT\n"
     ]
    }
   ],
   "source": [
    "def seqs_to_kmer_freqs(seqs,max_K):\n",
    "    tool = KmerTools()  # from SimTools\n",
    "    collection = []\n",
    "    for seq in seqs:\n",
    "        counts = tool.make_dict_upto_K(max_K)\n",
    "        # Last param should be True when using Harvester.\n",
    "        counts = tool.update_count_one_K(counts,max_K,seq,True)\n",
    "        # Given counts for K=3, Harvester fills in counts for K=1,2.\n",
    "        counts = tool.harvest_counts_from_K(counts,max_K)\n",
    "        fdict = tool.count_to_frequency(counts,max_K)\n",
    "        freqs = list(fdict.values())\n",
    "        collection.append(freqs)\n",
    "    return np.asarray(collection)\n",
    "Xfrq=seqs_to_kmer_freqs(Xseq,MAX_K)\n",
    "# Garbage collection\n",
    "Xseq = None\n",
    "show_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WBBY4rH3cwT2",
    "outputId": "ceb0441b-3d13-4e40-a157-dff6f69d6d27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xfrq\n",
      "Xfrq type <class 'numpy.ndarray'>\n",
      "Xfrq shape (16000, 84)\n",
      "Xfrq2D shape (16000, 7, 12, 1)\n"
     ]
    }
   ],
   "source": [
    "def reshape(frequency_matrix):\n",
    "    seq_cnt,frq_cnt=Xfrq.shape \n",
    "    # CNN inputs require a last dimension = numbers per pixel.\n",
    "    # For RGB images it is 3.\n",
    "    # For our frequency matrix it is 1.\n",
    "    new_matrix = frequency_matrix.reshape(seq_cnt,ROWS,COLS,1)\n",
    "    return new_matrix\n",
    "\n",
    "print(\"Xfrq\")\n",
    "print(\"Xfrq type\",type(Xfrq))\n",
    "print(\"Xfrq shape\",Xfrq.shape)\n",
    "Xfrq2D = reshape(Xfrq)\n",
    "print(\"Xfrq2D shape\",Xfrq2D.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dJ4XhrzGI_s-"
   },
   "source": [
    "## Build and train a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o5NPW7zKI_tC",
    "outputId": "753fe506-397e-4398-dac3-d3815e96ac92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make_DNN\n",
      "input shape: (7, 12, 1)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 7, 12, 32)         320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 7, 12, 64)         18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 3, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               147584    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 166,529\n",
      "Trainable params: 166,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-12 07:04:12.118082: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-08-12 07:04:12.141001: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-12 07:04:12.141313: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:02:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.75GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2021-08-12 07:04:12.141330: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-08-12 07:04:12.143698: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-08-12 07:04:12.143725: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-08-12 07:04:12.144792: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-08-12 07:04:12.144917: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-08-12 07:04:12.145138: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2021-08-12 07:04:12.145495: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-08-12 07:04:12.145561: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-08-12 07:04:12.145612: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-12 07:04:12.145912: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-12 07:04:12.146132: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-08-12 07:04:12.146564: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-08-12 07:04:12.147349: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-12 07:04:12.147626: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:02:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.75GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2021-08-12 07:04:12.147663: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-12 07:04:12.147915: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-12 07:04:12.148133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-08-12 07:04:12.148152: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-08-12 07:04:12.449791: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-08-12 07:04:12.449818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2021-08-12 07:04:12.449821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2021-08-12 07:04:12.450018: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-12 07:04:12.450247: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-12 07:04:12.450433: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-12 07:04:12.450607: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:02:00.0, compute capability: 7.5)\n"
     ]
    }
   ],
   "source": [
    "def make_DNN(shape):\n",
    "    dt=np.float32\n",
    "    print(\"make_DNN\")\n",
    "    print(\"input shape:\",shape)\n",
    "    WIDTH=(3,3)\n",
    "    STRIDE=(1,1)\n",
    "    dnn = Sequential()\n",
    "    dnn.add(Conv2D(filters=32,kernel_size=WIDTH,strides=STRIDE,activation=\"relu\",padding=\"same\",\n",
    "            input_shape=shape))\n",
    "    dnn.add(Conv2D(filters=64,kernel_size=WIDTH,strides=STRIDE,activation=\"relu\",padding=\"same\"))\n",
    "    dnn.add(MaxPooling2D())\n",
    "    dnn.add(Flatten())\n",
    "    dnn.add(Dropout(0.25))\n",
    "    dnn.add(Dense(128,activation=\"sigmoid\",dtype=dt)) \n",
    "    dnn.add(Dropout(0.50))\n",
    "    dnn.add(Dense(1,activation=\"sigmoid\",dtype=dt))   \n",
    "    dnn.compile(optimizer='adam',    # adadelta doesn't work as well\n",
    "                loss=BinaryCrossentropy(from_logits=False),\n",
    "                metrics=['accuracy'])   # add to default metrics=loss\n",
    "    dnn.build(input_shape=shape) \n",
    "    return dnn\n",
    "model = make_DNN(SHAPE2D)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "7xBalIrXrEAS"
   },
   "outputs": [],
   "source": [
    "def do_cross_validation(X,y,shape):\n",
    "    cv_scores = []\n",
    "    fold=0\n",
    "    mycallbacks = [ModelCheckpoint(\n",
    "        filepath=BESTMODELPATH, save_best_only=True, \n",
    "        monitor='val_accuracy', mode='max')]   \n",
    "    # When shuffle=True, the valid indices are a random subset.\n",
    "    splitter = KFold(n_splits=SPLITS,shuffle=True) \n",
    "    model = None\n",
    "    for train_index,valid_index in splitter.split(X):\n",
    "        if fold < FOLDS:\n",
    "            fold += 1\n",
    "            X_train=X[train_index] # inputs for training\n",
    "            y_train=y[train_index] # labels for training\n",
    "            X_valid=X[valid_index] # inputs for validation\n",
    "            y_valid=y[valid_index] # labels for validation\n",
    "            print(\"MODEL\")\n",
    "            # Call constructor on each CV. Else, continually improves the same model.\n",
    "            model = model = make_DNN(shape)\n",
    "            print(\"FIT\")  # model.fit() implements learning\n",
    "            start_time=time.time()\n",
    "            history=model.fit(X_train, y_train, \n",
    "                    epochs=EPOCHS, \n",
    "                    verbose=1,  # ascii art while learning\n",
    "                    callbacks=mycallbacks,   # called at end of each epoch\n",
    "                    validation_data=(X_valid,y_valid))\n",
    "            end_time=time.time()\n",
    "            elapsed_time=(end_time-start_time)                        \n",
    "            print(\"Fold %d, %d epochs, %d sec\"%(fold,EPOCHS,elapsed_time))\n",
    "            # print(history.history.keys())  # all these keys will be shown in figure\n",
    "            pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "            plt.grid(True)\n",
    "            plt.gca().set_ylim(0,1) # any losses > 1 will be off the scale\n",
    "            plt.show()\n",
    "    return model  # parameters at end of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "BM6UjBzrrEAV",
    "outputId": "3b4153f6-f2ad-4618-8ce2-dcccd9322bd5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-12 07:04:12.652010: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-12 07:04:12 EDT\n",
      "MODEL\n",
      "make_DNN\n",
      "input shape: (7, 12, 1)\n",
      "FIT\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-12 07:04:12.672172: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2496000000 Hz\n",
      "2021-08-12 07:04:19.342598: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-08-12 07:04:19.500387: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8202\n",
      "2021-08-12 07:04:19.756028: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 16.33MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-08-12 07:04:19.756061: W tensorflow/core/kernels/gpu_utils.cc:49] Failed to allocate memory for convolution redzone checking; skipping this check. This is benign and only means that we won't check cudnn for out-of-bounds reads and writes. This message will only be printed once.\n",
      "2021-08-12 07:04:19.813953: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 16.09MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-08-12 07:04:19.814005: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 16.09MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-08-12 07:04:19.814048: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 18.25MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-08-12 07:04:19.814068: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 18.25MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-08-12 07:04:19.820746: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 16.02MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-08-12 07:04:19.820802: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 16.02MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-08-12 07:04:19.820842: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 20.52MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-08-12 07:04:19.820863: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 20.52MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-08-12 07:04:19.820886: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 16.87MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-08-12 07:04:19.821066: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-08-12 07:04:19.822827: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\n",
      "2021-08-12 07:04:19.822953: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_ops.cc:1287 : Not found: No algorithm worked!\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": " No algorithm worked!\n\t [[node sequential_1/conv2d_2/Conv2D (defined at home/jrm/venv/lib/python3.8/site-packages/keras/layers/convolutional.py:245) ]] [Op:__inference_train_function_939]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sequential_1/conv2d_2/Conv2D:\n IteratorGetNext (defined at home/jrm/venv/lib/python3.8/site-packages/keras/engine/training.py:819)\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4298/2092290906.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mshow_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlast_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_cross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXfrq2D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSHAPE2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlast_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLASTMODELPATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4298/1530552266.py\u001b[0m in \u001b[0;36mdo_cross_validation\u001b[0;34m(X, y, shape)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"FIT\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# model.fit() implements learning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mstart_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             history=model.fit(X_train, y_train, \n\u001b[0m\u001b[1;32m     23\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# ascii art while learning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 _r=1):\n\u001b[1;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m:  No algorithm worked!\n\t [[node sequential_1/conv2d_2/Conv2D (defined at home/jrm/venv/lib/python3.8/site-packages/keras/layers/convolutional.py:245) ]] [Op:__inference_train_function_939]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sequential_1/conv2d_2/Conv2D:\n IteratorGetNext (defined at home/jrm/venv/lib/python3.8/site-packages/keras/engine/training.py:819)\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "show_time()\n",
    "last_model = do_cross_validation(Xfrq2D,y,SHAPE2D)\n",
    "last_model.save(LASTMODELPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OsytC9VUrEAX"
   },
   "source": [
    "## Test the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8hIqe1r1rEAa"
   },
   "outputs": [],
   "source": [
    "def show_test_AUC(model,X,y):\n",
    "    ns_probs = [0 for _ in range(len(y))]\n",
    "    bm_probs = model.predict(X)\n",
    "    ns_auc = roc_auc_score(y, ns_probs)\n",
    "    bm_auc = roc_auc_score(y, bm_probs)\n",
    "    ns_fpr, ns_tpr, _ = roc_curve(y, ns_probs)\n",
    "    bm_fpr, bm_tpr, _ = roc_curve(y, bm_probs)\n",
    "    plt.plot(ns_fpr, ns_tpr, linestyle='--', label='Guess, auc=%.4f'%ns_auc)\n",
    "    plt.plot(bm_fpr, bm_tpr, marker='.', label='Model, auc=%.4f'%bm_auc)\n",
    "    plt.title('ROC')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print(\"%s: %.2f%%\" %('AUC',bm_auc*100.0))\n",
    "def show_test_accuracy(model,X,y):\n",
    "    scores = model.evaluate(X, y, verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "id": "tGf2PcxRC8jT",
    "outputId": "5c986f5a-a045-4691-e6ef-f9d86d997ff7"
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy on test data.\")\n",
    "print(\"Prepare...\")\n",
    "show_time()\n",
    "Xseq,y=prepare_x_and_y(pc_test,nc_test)\n",
    "print(\"Extract K-mer features...\")\n",
    "show_time()\n",
    "Xfrq=seqs_to_kmer_freqs(Xseq,MAX_K)\n",
    "Xfrq2D = reshape(Xfrq)\n",
    "print(\"Plot...\")\n",
    "show_time()\n",
    "show_test_AUC(last_model,Xfrq2D,y)\n",
    "show_test_accuracy(last_model,Xfrq2D,y)\n",
    "show_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-cSLTNfzrEAo"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Wen_CNN_102.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
