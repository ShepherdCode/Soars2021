{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0asdcdunj2Tx"
   },
   "source": [
    "# ORF recognition by CNN\n",
    "\n",
    "In 105, we used Conv1D layers with filter width=3 with dropout to reduce overfitting. The simulated RNA lengths were 1000.\n",
    "\n",
    "Here, try really short simulated RNA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "QP1VTRNQj2UO",
    "outputId": "9c0b236a-35ff-4112-d270-bc3f7220ff26"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021-06-07 13:09:32 EDT'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time \n",
    "t = time.time()\n",
    "time.strftime('%Y-%m-%d %H:%M:%S %Z', time.localtime(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Nhz4GKonj2T_"
   },
   "outputs": [],
   "source": [
    "PC_SEQUENCES=20000   # how many protein-coding sequences\n",
    "NC_SEQUENCES=20000   # how many non-coding sequences\n",
    "PC_TESTS=1000\n",
    "NC_TESTS=1000\n",
    "BASES=12            # how long is each sequence\n",
    "CDS_LEN=9\n",
    "ALPHABET=4          # how many different letters are possible\n",
    "INPUT_SHAPE_2D = (BASES,ALPHABET,1) # Conv2D needs 3D inputs\n",
    "INPUT_SHAPE = (BASES,ALPHABET) # Conv1D needs 2D inputs\n",
    "FILTERS = 32   # how many different patterns the model looks for\n",
    "NEURONS = 16\n",
    "DROP_RATE = 0.2\n",
    "WIDTH = 3   # how wide each pattern is, in bases\n",
    "STRIDE_2D = (1,1)  # For Conv2D how far in each direction\n",
    "STRIDE = 1 # For Conv1D, how far between pattern matches, in bases\n",
    "EPOCHS=10  # how many times to train on all the data\n",
    "SPLITS=5  # SPLITS=3 means train on 2/3 and validate on 1/3 \n",
    "FOLDS=1  # train the model this many times (range 1 to SPLITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lr7q90rxj2UE",
    "outputId": "19cd66e8-b5c2-4a9d-a9a2-63f674b034f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoLab not working. On my PC, use relative paths.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    IN_COLAB = True\n",
    "    print(\"On Google CoLab, mount cloud-local file, get our code from GitHub.\")\n",
    "    PATH='/content/drive/'\n",
    "    #drive.mount(PATH,force_remount=True)  # hardly ever need this\n",
    "    #drive.mount(PATH)    # Google will require login credentials\n",
    "    DATAPATH=PATH+'My Drive/data/'  # must end in \"/\"\n",
    "    import requests\n",
    "    r = requests.get('https://raw.githubusercontent.com/ShepherdCode/Soars2021/master/SimTools/RNA_gen.py')\n",
    "    with open('RNA_gen.py', 'w') as f:\n",
    "        f.write(r.text)  \n",
    "    from RNA_gen import *\n",
    "    r = requests.get('https://raw.githubusercontent.com/ShepherdCode/Soars2021/master/SimTools/RNA_describe.py')\n",
    "    with open('RNA_describe.py', 'w') as f:\n",
    "        f.write(r.text)  \n",
    "    from RNA_describe import *\n",
    "    r = requests.get('https://raw.githubusercontent.com/ShepherdCode/Soars2021/master/SimTools/RNA_prep.py')\n",
    "    with open('RNA_prep.py', 'w') as f:\n",
    "        f.write(r.text)  \n",
    "    from RNA_prep import *\n",
    "except:\n",
    "    print(\"CoLab not working. On my PC, use relative paths.\")\n",
    "    IN_COLAB = False\n",
    "    DATAPATH='data/'  # must end in \"/\"\n",
    "    sys.path.append(\"..\") # append parent dir in order to use sibling dirs\n",
    "    from SimTools.RNA_gen import *\n",
    "    from SimTools.RNA_describe import *\n",
    "    from SimTools.RNA_prep import *\n",
    "\n",
    "MODELPATH=\"BestModel\"  # saved on cloud instance and lost after logout\n",
    "#MODELPATH=DATAPATH+MODELPATH  # saved on Google Drive but requires login\n",
    "\n",
    "if not assert_imported_RNA_gen():\n",
    "    print(\"ERROR: Cannot use RNA_gen.\")\n",
    "if not assert_imported_RNA_prep():\n",
    "    print(\"ERROR: Cannot use RNA_prep.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "EGDXH8Uwj2UM"
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import csv\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats  # mode\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Embedding,Dropout\n",
    "from keras.layers import Conv1D,Conv2D\n",
    "from keras.layers import Flatten,MaxPooling1D,MaxPooling2D\n",
    "from keras.losses import BinaryCrossentropy\n",
    "# tf.keras.losses.BinaryCrossentropy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "mycmap = colors.ListedColormap(['red','blue'])  # list color for label 0 then 1\n",
    "np.set_printoptions(precision=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q0FetlLPj2UQ",
    "outputId": "c8305122-1080-480f-f66e-1ca69fedf3d3"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'super' has no attribute 'get_sequence'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-aa5985ffd657>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mpc_sim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnc_sim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_generators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mpc_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpc_sim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPC_SEQUENCES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mnc_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnc_sim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNC_SEQUENCES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train on\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpc_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"PC seqs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Source/Soars2021/SimTools/RNA_gen.py\u001b[0m in \u001b[0;36mget_sequences\u001b[0;34m(self, seqs)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mlen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mso\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m             \u001b[0mcollection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcollection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Source/Soars2021/SimTools/RNA_gen.py\u001b[0m in \u001b[0;36mget_sequence\u001b[0;34m(self, length)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mBoth\u001b[0m \u001b[0mUTR\u001b[0m \u001b[0mcontain\u001b[0m \u001b[0mrandom\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         ORF structure is START+CODON(S)+STOP.'''\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0morf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_orf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0mutr5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mutr3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_utr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Source/Soars2021/SimTools/RNA_gen.py\u001b[0m in \u001b[0;36m__get_orf\u001b[0;34m(self, tlen)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0morflen_actual\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_orf_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;31m# Too short. Just return random sequence.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0mnum_codons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morflen_actual\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcodon_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mnum_codons\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;31m# START and STOP are automatic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'super' has no attribute 'get_sequence'"
     ]
    }
   ],
   "source": [
    "# Use code from our SimTools library.\n",
    "def make_generators(seq_len):\n",
    "    pcgen = Collection_Generator()  \n",
    "    pcgen.get_len_oracle().set_mean(seq_len)\n",
    "    tora = Transcript_Oracle()\n",
    "    tora.set_orf_len_mean(CDS_LEN)  # CDS=ORF+STOP. Method is misnamed.\n",
    "    pcgen.set_seq_oracle(tora)\n",
    "    ncgen = Collection_Generator()  \n",
    "    ncgen.get_len_oracle().set_mean(seq_len)\n",
    "    return pcgen,ncgen\n",
    "\n",
    "pc_sim,nc_sim = make_generators(BASES)\n",
    "pc_train = pc_sim.get_sequences(PC_SEQUENCES)\n",
    "nc_train = nc_sim.get_sequences(NC_SEQUENCES)\n",
    "print(\"Train on\",len(pc_train),\"PC seqs\")\n",
    "print(\"Train on\",len(nc_train),\"NC seqs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CIpTrnH6j2US",
    "outputId": "5c847e21-17a3-4a37-b6b2-24ecb9a53d93"
   },
   "outputs": [],
   "source": [
    "# Use code from our SimTools library.\n",
    "X,y = prepare_inputs_len_x_alphabet(pc_train,nc_train,ALPHABET) # shuffles\n",
    "print(\"Data ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7NvrVU8ij2UU",
    "outputId": "dd01d853-6791-4913-b12d-0e82f4041a9b"
   },
   "outputs": [],
   "source": [
    "def make_DNN():\n",
    "    print(\"make_DNN\")\n",
    "    print(\"input shape:\",INPUT_SHAPE)\n",
    "    dnn = Sequential()\n",
    "    #dnn.add(Embedding(input_dim=INPUT_SHAPE,output_dim=INPUT_SHAPE)) \n",
    "    dnn.add(Conv1D(filters=FILTERS,kernel_size=WIDTH,strides=STRIDE,padding=\"same\",\n",
    "            input_shape=INPUT_SHAPE))\n",
    "    dnn.add(Conv1D(filters=FILTERS,kernel_size=WIDTH,strides=STRIDE,padding=\"same\"))\n",
    "    dnn.add(MaxPooling1D())\n",
    "    dnn.add(Conv1D(filters=FILTERS,kernel_size=WIDTH,strides=STRIDE,padding=\"same\"))\n",
    "    dnn.add(Conv1D(filters=FILTERS,kernel_size=WIDTH,strides=STRIDE,padding=\"same\"))\n",
    "    dnn.add(MaxPooling1D())\n",
    "    dnn.add(Flatten())\n",
    "    dnn.add(Dense(NEURONS,activation=\"sigmoid\",dtype=np.float32))   \n",
    "    dnn.add(Dropout(DROP_RATE))\n",
    "    dnn.add(Dense(1,activation=\"sigmoid\",dtype=np.float32))   \n",
    "    dnn.compile(optimizer='adam',\n",
    "                loss=BinaryCrossentropy(from_logits=False),\n",
    "                metrics=['accuracy'])   # add to default metrics=loss\n",
    "    dnn.build(input_shape=INPUT_SHAPE)\n",
    "    #ln_rate = tf.keras.optimizers.Adam(learning_rate = LN_RATE)\n",
    "    #bc=tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "    #model.compile(loss=bc, optimizer=ln_rate, metrics=[\"accuracy\"])\n",
    "    return dnn\n",
    "model = make_DNN()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nlVF0hR3j2UW"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "def do_cross_validation(X,y):\n",
    "    cv_scores = []\n",
    "    fold=0\n",
    "    mycallbacks = [ModelCheckpoint(\n",
    "        filepath=MODELPATH, save_best_only=True, \n",
    "        monitor='val_accuracy', mode='max')]   \n",
    "    splitter = KFold(n_splits=SPLITS)  # this does not shuffle\n",
    "    for train_index,valid_index in splitter.split(X):\n",
    "        if fold < FOLDS:\n",
    "            fold += 1\n",
    "            X_train=X[train_index] # inputs for training\n",
    "            y_train=y[train_index] # labels for training\n",
    "            X_valid=X[valid_index] # inputs for validation\n",
    "            y_valid=y[valid_index] # labels for validation\n",
    "            print(\"MODEL\")\n",
    "            # Call constructor on each CV. Else, continually improves the same model.\n",
    "            model = model = make_DNN()\n",
    "            print(\"FIT\")  # model.fit() implements learning\n",
    "            start_time=time.time()\n",
    "            history=model.fit(X_train, y_train, \n",
    "                    epochs=EPOCHS, \n",
    "                    verbose=1,  # ascii art while learning\n",
    "                    callbacks=mycallbacks,   # called at end of each epoch\n",
    "                    validation_data=(X_valid,y_valid))\n",
    "            end_time=time.time()\n",
    "            elapsed_time=(end_time-start_time)                        \n",
    "            print(\"Fold %d, %d epochs, %d sec\"%(fold,EPOCHS,elapsed_time))\n",
    "            # print(history.history.keys())  # all these keys will be shown in figure\n",
    "            pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "            plt.grid(True)\n",
    "            plt.gca().set_ylim(0,1) # any losses > 1 will be off the scale\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9Ggt4EsSj2UY",
    "outputId": "488a4de9-d043-4542-e75a-130c29c80773"
   },
   "outputs": [],
   "source": [
    "do_cross_validation(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e-jG1h5fj2Ua",
    "outputId": "8a4e57b5-c379-48c8-e0df-9cbfc828d46b"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "pc_sim.set_reproducible(True)\n",
    "nc_sim.set_reproducible(True)\n",
    "pc_test = pc_sim.get_sequences(PC_TESTS)\n",
    "nc_test = nc_sim.get_sequences(NC_TESTS)\n",
    "X,y = prepare_inputs_len_x_alphabet(pc_test,nc_test,ALPHABET)\n",
    "best_model=load_model(MODELPATH)\n",
    "scores = best_model.evaluate(X, y, verbose=0)\n",
    "print(\"The best model parameters were saved during cross-validation.\")\n",
    "print(\"Best was defined as maximum validation accuracy at end of any epoch.\")\n",
    "print(\"Now re-load the best model and test it on previously unseen data.\")\n",
    "print(\"Test on\",len(pc_test),\"PC seqs\")\n",
    "print(\"Test on\",len(nc_test),\"NC seqs\")\n",
    "print(\"%s: %.2f%%\" % (best_model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "VycUnmvUj2Ue",
    "outputId": "b26172ab-07c5-4ce9-9402-12921abf1778"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "ns_probs = [0 for _ in range(len(y))]\n",
    "bm_probs = best_model.predict(X)\n",
    "ns_auc = roc_auc_score(y, ns_probs)\n",
    "bm_auc = roc_auc_score(y, bm_probs)\n",
    "ns_fpr, ns_tpr, _ = roc_curve(y, ns_probs)\n",
    "bm_fpr, bm_tpr, _ = roc_curve(y, bm_probs)\n",
    "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='Guess, auc=%.4f'%ns_auc)\n",
    "plt.plot(bm_fpr, bm_tpr, marker='.', label='Model, auc=%.4f'%bm_auc)\n",
    "plt.title('ROC')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(\"%s: %.2f%%\" %('AUC',bm_auc*100.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "kFMb6rGNj2Ug",
    "outputId": "9a9eaa14-5656-47f8-9457-b936f9bf922c"
   },
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "time.strftime('%Y-%m-%d %H:%M:%S %Z', time.localtime(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "20% dropout may have reduced overfitting by a small amount.\n",
    "We should try more dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ORF_CNN_105.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
