{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ORF_LSTM_101.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0asdcdunj2Tx"
      },
      "source": [
        "# ORF recognition by LSTM\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "QP1VTRNQj2UO",
        "outputId": "cd925005-d013-4c5b-fc84-118ac3e07eb2"
      },
      "source": [
        "import time \n",
        "t = time.time()\n",
        "time.strftime('%Y-%m-%d %H:%M:%S %Z', time.localtime(t))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2021-05-17 16:42:35 UTC'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nhz4GKonj2T_"
      },
      "source": [
        "PC_SEQUENCES=20000   # how many protein-coding sequences\n",
        "NC_SEQUENCES=20000   # how many non-coding sequences\n",
        "PC_TESTS=1000\n",
        "NC_TESTS=1000\n",
        "BASES=1000            # how long is each sequence\n",
        "ALPHABET=4          # how many different letters are possible\n",
        "INPUT_SHAPE_2D = (BASES,ALPHABET,1) # Conv2D needs 3D inputs\n",
        "INPUT_SHAPE = (BASES,ALPHABET) # Conv1D needs 2D inputs\n",
        "NEURONS = 64\n",
        "#DROP_RATE = 0.2\n",
        "EPOCHS=50  # how many times to train on all the data\n",
        "SPLITS=5  # SPLITS=3 means train on 2/3 and validate on 1/3 \n",
        "FOLDS=1  # train the model this many times (range 1 to SPLITS)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lr7q90rxj2UE",
        "outputId": "2d662fa9-1625-4683-e626-0bcc4d05aa3b"
      },
      "source": [
        "import sys\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    IN_COLAB = True\n",
        "    print(\"On Google CoLab, mount cloud-local file, get our code from GitHub.\")\n",
        "    PATH='/content/drive/'\n",
        "    #drive.mount(PATH,force_remount=True)  # hardly ever need this\n",
        "    #drive.mount(PATH)    # Google will require login credentials\n",
        "    DATAPATH=PATH+'My Drive/data/'  # must end in \"/\"\n",
        "    import requests\n",
        "    r = requests.get('https://raw.githubusercontent.com/ShepherdCode/Soars2021/master/SimTools/RNA_gen.py')\n",
        "    with open('RNA_gen.py', 'w') as f:\n",
        "        f.write(r.text)  \n",
        "    from RNA_gen import *\n",
        "    r = requests.get('https://raw.githubusercontent.com/ShepherdCode/Soars2021/master/SimTools/RNA_describe.py')\n",
        "    with open('RNA_describe.py', 'w') as f:\n",
        "        f.write(r.text)  \n",
        "    from RNA_describe import *\n",
        "    r = requests.get('https://raw.githubusercontent.com/ShepherdCode/Soars2021/master/SimTools/RNA_prep.py')\n",
        "    with open('RNA_prep.py', 'w') as f:\n",
        "        f.write(r.text)  \n",
        "    from RNA_prep import *\n",
        "except:\n",
        "    print(\"CoLab not working. On my PC, use relative paths.\")\n",
        "    IN_COLAB = False\n",
        "    DATAPATH='data/'  # must end in \"/\"\n",
        "    sys.path.append(\"..\") # append parent dir in order to use sibling dirs\n",
        "    from SimTools.RNA_gen import *\n",
        "    from SimTools.RNA_describe import *\n",
        "    from SimTools.RNA_prep import *\n",
        "\n",
        "MODELPATH=\"BestModel\"  # saved on cloud instance and lost after logout\n",
        "#MODELPATH=DATAPATH+MODELPATH  # saved on Google Drive but requires login\n",
        "\n",
        "if not assert_imported_RNA_gen():\n",
        "    print(\"ERROR: Cannot use RNA_gen.\")\n",
        "if not assert_imported_RNA_prep():\n",
        "    print(\"ERROR: Cannot use RNA_prep.\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "On Google CoLab, mount cloud-local file, get our code from GitHub.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGDXH8Uwj2UM"
      },
      "source": [
        "from os import listdir\n",
        "import csv\n",
        "from zipfile import ZipFile\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats  # mode\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Embedding,Dropout,TimeDistributed\n",
        "from keras.layers import LSTM\n",
        "from keras.losses import BinaryCrossentropy\n",
        "# tf.keras.losses.BinaryCrossentropy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import colors\n",
        "mycmap = colors.ListedColormap(['red','blue'])  # list color for label 0 then 1\n",
        "np.set_printoptions(precision=2)\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0FetlLPj2UQ",
        "outputId": "ef23f0ca-3083-4c21-ec2f-e8bd992b2754"
      },
      "source": [
        "# Use code from our SimTools library.\n",
        "def make_generators(seq_len):\n",
        "    pcgen = Collection_Generator()  \n",
        "    pcgen.get_len_oracle().set_mean(seq_len)\n",
        "    pcgen.set_seq_oracle(Transcript_Oracle())\n",
        "    ncgen = Collection_Generator()  \n",
        "    ncgen.get_len_oracle().set_mean(seq_len)\n",
        "    return pcgen,ncgen\n",
        "\n",
        "pc_sim,nc_sim = make_generators(BASES)\n",
        "pc_train = pc_sim.get_sequences(PC_SEQUENCES)\n",
        "nc_train = nc_sim.get_sequences(NC_SEQUENCES)\n",
        "print(\"Train on\",len(pc_train),\"PC seqs\")\n",
        "print(\"Train on\",len(nc_train),\"NC seqs\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 20000 PC seqs\n",
            "Train on 20000 NC seqs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIpTrnH6j2US",
        "outputId": "9331cd01-908b-434b-c314-4f5c69c43b01"
      },
      "source": [
        "# Use code from our SimTools library.\n",
        "X,y = prepare_inputs_len_x_alphabet(pc_train,nc_train,ALPHABET) # shuffles\n",
        "print(\"Data ready.\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data ready.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NvrVU8ij2UU",
        "outputId": "8d3d5e86-4bf7-40fb-fd8e-5951e5a43eb0"
      },
      "source": [
        "def make_DNN():\n",
        "    print(\"make_DNN\")\n",
        "    print(\"input shape:\",INPUT_SHAPE)\n",
        "    dnn = Sequential()\n",
        "    #dnn.add(Embedding(input_dim=ALPHABET, output_dim=ALPHABET))\n",
        "        #VOCABULARY_SIZE, EMBED_DIMEN, input_length=1000, input_length=1000, mask_zero=True)\n",
        "        #input_dim=[None,VOCABULARY_SIZE], output_dim=EMBED_DIMEN, mask_zero=True)\n",
        "    dnn.add(LSTM(NEURONS,return_sequences=True,input_shape=INPUT_SHAPE))\n",
        "    dnn.add(LSTM(NEURONS,return_sequences=True))\n",
        "    dnn.add(LSTM(NEURONS,return_sequences=True)) \n",
        "    # The first dense layer should be wrapped in TimeDistributed()\n",
        "    # but keras claims to autodetect and do that anyway.\n",
        "    dnn.add(TimeDistributed(Dense(NEURONS,activation=\"sigmoid\",dtype=np.float32)))  \n",
        "    dnn.add(Dense(1,activation=\"sigmoid\",dtype=np.float32))   \n",
        "    dnn.compile(optimizer='adam',\n",
        "                loss=BinaryCrossentropy(from_logits=False),\n",
        "                metrics=['accuracy'])   # add to default metrics=loss\n",
        "    dnn.build() # input_shape=INPUT_SHAPE)\n",
        "    #ln_rate = tf.keras.optimizers.Adam(learning_rate = LN_RATE)\n",
        "    #bc=tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "    #model.compile(loss=bc, optimizer=ln_rate, metrics=[\"accuracy\"])\n",
        "    return dnn\n",
        "model = make_DNN()\n",
        "print(model.summary())"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "make_DNN\n",
            "input shape: (1000, 4)\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_20 (LSTM)               (None, 1000, 64)          17664     \n",
            "_________________________________________________________________\n",
            "lstm_21 (LSTM)               (None, 1000, 64)          33024     \n",
            "_________________________________________________________________\n",
            "lstm_22 (LSTM)               (None, 1000, 64)          33024     \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 1000, 64)          4160      \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 1000, 1)           65        \n",
            "=================================================================\n",
            "Total params: 87,937\n",
            "Trainable params: 87,937\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlVF0hR3j2UW"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "# This keras class has a known bug in saving LSTM layers.\n",
        "# The recommended work-around is to save to HDF5 format.\n",
        "# Easier said than done.\n",
        "def do_cross_validation(X,y):\n",
        "    cv_scores = []\n",
        "    fold=0\n",
        "    mycallbacks = [ModelCheckpoint(\n",
        "        filepath=MODELPATH, save_best_only=True, \n",
        "        monitor='val_accuracy', mode='max')]   \n",
        "    splitter = KFold(n_splits=SPLITS)  # this does not shuffle\n",
        "    for train_index,valid_index in splitter.split(X):\n",
        "        if fold < FOLDS:\n",
        "            fold += 1\n",
        "            X_train=X[train_index] # inputs for training\n",
        "            y_train=y[train_index] # labels for training\n",
        "            X_valid=X[valid_index] # inputs for validation\n",
        "            y_valid=y[valid_index] # labels for validation\n",
        "            print(\"MODEL\")\n",
        "            # Call constructor on each CV. Else, continually improves the same model.\n",
        "            model = model = make_DNN()\n",
        "            print(\"FIT\")  # model.fit() implements learning\n",
        "            start_time=time.time()\n",
        "            history=model.fit(X_train, y_train, \n",
        "                    epochs=EPOCHS, \n",
        "                    verbose=1,  # ascii art while learning\n",
        "                    callbacks=mycallbacks,   # called at end of each epoch\n",
        "                    validation_data=(X_valid,y_valid))\n",
        "            end_time=time.time()\n",
        "            elapsed_time=(end_time-start_time)                        \n",
        "            print(\"Fold %d, %d epochs, %d sec\"%(fold,EPOCHS,elapsed_time))\n",
        "            # print(history.history.keys())  # all these keys will be shown in figure\n",
        "            pd.DataFrame(history.history).plot(figsize=(8,5))\n",
        "            plt.grid(True)\n",
        "            plt.gca().set_ylim(0,1) # any losses > 1 will be off the scale\n",
        "            plt.show()\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9Ggt4EsSj2UY",
        "outputId": "60cfe602-13bf-4db8-c583-68eafb9194b8"
      },
      "source": [
        "do_cross_validation(X,y)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MODEL\n",
            "make_DNN\n",
            "input shape: (1000, 4)\n",
            "FIT\n",
            "Epoch 1/50\n",
            "1000/1000 [==============================] - 129s 125ms/step - loss: 0.6943 - accuracy: 0.5031 - val_loss: 0.6957 - val_accuracy: 0.4971\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_25_layer_call_fn, lstm_cell_25_layer_call_and_return_conditional_losses, lstm_cell_26_layer_call_fn, lstm_cell_26_layer_call_and_return_conditional_losses, lstm_cell_27_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_25_layer_call_fn, lstm_cell_25_layer_call_and_return_conditional_losses, lstm_cell_26_layer_call_fn, lstm_cell_26_layer_call_and_return_conditional_losses, lstm_cell_27_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/50\n",
            "1000/1000 [==============================] - 130s 130ms/step - loss: 0.6941 - accuracy: 0.4980 - val_loss: 0.6940 - val_accuracy: 0.5001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_25_layer_call_fn, lstm_cell_25_layer_call_and_return_conditional_losses, lstm_cell_26_layer_call_fn, lstm_cell_26_layer_call_and_return_conditional_losses, lstm_cell_27_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_25_layer_call_fn, lstm_cell_25_layer_call_and_return_conditional_losses, lstm_cell_26_layer_call_fn, lstm_cell_26_layer_call_and_return_conditional_losses, lstm_cell_27_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/50\n",
            "1000/1000 [==============================] - 130s 130ms/step - loss: 0.6940 - accuracy: 0.4946 - val_loss: 0.6936 - val_accuracy: 0.4999\n",
            "Epoch 4/50\n",
            "1000/1000 [==============================] - 129s 129ms/step - loss: 0.6940 - accuracy: 0.4979 - val_loss: 0.6944 - val_accuracy: 0.5001\n",
            "Epoch 5/50\n",
            "1000/1000 [==============================] - 130s 130ms/step - loss: 0.6940 - accuracy: 0.4988 - val_loss: 0.6934 - val_accuracy: 0.4999\n",
            "Epoch 6/50\n",
            "1000/1000 [==============================] - 129s 129ms/step - loss: 0.6938 - accuracy: 0.5004 - val_loss: 0.6945 - val_accuracy: 0.5001\n",
            "Epoch 7/50\n",
            "1000/1000 [==============================] - 129s 129ms/step - loss: 0.6942 - accuracy: 0.4955 - val_loss: 0.6933 - val_accuracy: 0.4999\n",
            "Epoch 8/50\n",
            "1000/1000 [==============================] - 129s 129ms/step - loss: 0.6937 - accuracy: 0.4994 - val_loss: 0.6932 - val_accuracy: 0.5001\n",
            "Epoch 9/50\n",
            "1000/1000 [==============================] - 130s 130ms/step - loss: 0.6937 - accuracy: 0.5026 - val_loss: 0.6941 - val_accuracy: 0.4999\n",
            "Epoch 10/50\n",
            "1000/1000 [==============================] - 130s 130ms/step - loss: 0.6943 - accuracy: 0.4986 - val_loss: 0.6934 - val_accuracy: 0.4999\n",
            "Epoch 11/50\n",
            "1000/1000 [==============================] - 129s 129ms/step - loss: 0.6936 - accuracy: 0.5052 - val_loss: 0.6959 - val_accuracy: 0.4999\n",
            "Epoch 12/50\n",
            "1000/1000 [==============================] - 130s 130ms/step - loss: 0.6938 - accuracy: 0.4995 - val_loss: 0.6932 - val_accuracy: 0.4999\n",
            "Epoch 13/50\n",
            "1000/1000 [==============================] - 129s 129ms/step - loss: 0.6940 - accuracy: 0.4969 - val_loss: 0.6931 - val_accuracy: 0.5002\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_25_layer_call_fn, lstm_cell_25_layer_call_and_return_conditional_losses, lstm_cell_26_layer_call_fn, lstm_cell_26_layer_call_and_return_conditional_losses, lstm_cell_27_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_25_layer_call_fn, lstm_cell_25_layer_call_and_return_conditional_losses, lstm_cell_26_layer_call_fn, lstm_cell_26_layer_call_and_return_conditional_losses, lstm_cell_27_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BestModel/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 14/50\n",
            "1000/1000 [==============================] - 128s 127ms/step - loss: 0.6938 - accuracy: 0.4985 - val_loss: 0.6943 - val_accuracy: 0.4999\n",
            "Epoch 15/50\n",
            "1000/1000 [==============================] - 127s 127ms/step - loss: 0.6940 - accuracy: 0.4981 - val_loss: 0.6944 - val_accuracy: 0.5001\n",
            "Epoch 16/50\n",
            "1000/1000 [==============================] - 127s 127ms/step - loss: 0.6939 - accuracy: 0.5014 - val_loss: 0.6947 - val_accuracy: 0.4999\n",
            "Epoch 17/50\n",
            "1000/1000 [==============================] - 127s 127ms/step - loss: 0.6939 - accuracy: 0.5037 - val_loss: 0.6931 - val_accuracy: 0.4999\n",
            "Epoch 18/50\n",
            "1000/1000 [==============================] - 127s 127ms/step - loss: 0.6938 - accuracy: 0.4968 - val_loss: 0.6932 - val_accuracy: 0.5001\n",
            "Epoch 19/50\n",
            "1000/1000 [==============================] - 127s 127ms/step - loss: 0.6938 - accuracy: 0.4951 - val_loss: 0.6945 - val_accuracy: 0.4999\n",
            "Epoch 20/50\n",
            "1000/1000 [==============================] - 127s 127ms/step - loss: 0.6938 - accuracy: 0.4903 - val_loss: 0.6952 - val_accuracy: 0.5001\n",
            "Epoch 21/50\n",
            "1000/1000 [==============================] - 128s 128ms/step - loss: 0.6936 - accuracy: 0.5040 - val_loss: 0.6940 - val_accuracy: 0.5001\n",
            "Epoch 22/50\n",
            "1000/1000 [==============================] - 128s 128ms/step - loss: 0.6940 - accuracy: 0.5005 - val_loss: 0.6946 - val_accuracy: 0.4999\n",
            "Epoch 23/50\n",
            "1000/1000 [==============================] - 128s 128ms/step - loss: 0.6938 - accuracy: 0.5045 - val_loss: 0.6931 - val_accuracy: 0.4999\n",
            "Epoch 24/50\n",
            "1000/1000 [==============================] - 128s 128ms/step - loss: 0.6940 - accuracy: 0.4944 - val_loss: 0.6944 - val_accuracy: 0.4999\n",
            "Epoch 25/50\n",
            "1000/1000 [==============================] - 128s 128ms/step - loss: 0.6941 - accuracy: 0.4925 - val_loss: 0.6940 - val_accuracy: 0.4999\n",
            "Epoch 26/50\n",
            "1000/1000 [==============================] - 128s 128ms/step - loss: 0.6938 - accuracy: 0.5002 - val_loss: 0.6937 - val_accuracy: 0.5001\n",
            "Epoch 27/50\n",
            "1000/1000 [==============================] - 128s 128ms/step - loss: 0.6937 - accuracy: 0.5031 - val_loss: 0.6960 - val_accuracy: 0.4999\n",
            "Epoch 28/50\n",
            "1000/1000 [==============================] - 128s 128ms/step - loss: 0.6936 - accuracy: 0.5046 - val_loss: 0.6932 - val_accuracy: 0.5001\n",
            "Epoch 29/50\n",
            "1000/1000 [==============================] - 128s 128ms/step - loss: 0.6941 - accuracy: 0.5009 - val_loss: 0.6943 - val_accuracy: 0.4999\n",
            "Epoch 30/50\n",
            "1000/1000 [==============================] - 128s 128ms/step - loss: 0.6937 - accuracy: 0.5040 - val_loss: 0.6931 - val_accuracy: 0.4999\n",
            "Epoch 31/50\n",
            "1000/1000 [==============================] - 128s 128ms/step - loss: 0.6935 - accuracy: 0.4969 - val_loss: 0.6934 - val_accuracy: 0.5001\n",
            "Epoch 32/50\n",
            "1000/1000 [==============================] - 128s 128ms/step - loss: 0.6937 - accuracy: 0.4972 - val_loss: 0.6941 - val_accuracy: 0.4999\n",
            "Epoch 33/50\n",
            "1000/1000 [==============================] - 128s 128ms/step - loss: 0.6938 - accuracy: 0.5002 - val_loss: 0.6932 - val_accuracy: 0.4999\n",
            "Epoch 34/50\n",
            "1000/1000 [==============================] - 128s 128ms/step - loss: 0.6940 - accuracy: 0.5023 - val_loss: 0.6937 - val_accuracy: 0.4999\n",
            "Epoch 35/50\n",
            "1000/1000 [==============================] - 128s 128ms/step - loss: 0.6939 - accuracy: 0.4977 - val_loss: 0.6944 - val_accuracy: 0.5001\n",
            "Epoch 36/50\n",
            "1000/1000 [==============================] - 128s 128ms/step - loss: 0.6939 - accuracy: 0.5017 - val_loss: 0.6952 - val_accuracy: 0.4999\n",
            "Epoch 37/50\n",
            "1000/1000 [==============================] - 127s 127ms/step - loss: 0.6936 - accuracy: 0.4991 - val_loss: 0.6932 - val_accuracy: 0.4999\n",
            "Epoch 38/50\n",
            "1000/1000 [==============================] - 128s 128ms/step - loss: 0.6938 - accuracy: 0.5018 - val_loss: 0.6949 - val_accuracy: 0.5001\n",
            "Epoch 39/50\n",
            "1000/1000 [==============================] - 129s 129ms/step - loss: 0.6943 - accuracy: 0.4954 - val_loss: 0.6932 - val_accuracy: 0.4999\n",
            "Epoch 40/50\n",
            "1000/1000 [==============================] - 129s 129ms/step - loss: 0.6936 - accuracy: 0.5074 - val_loss: 0.6942 - val_accuracy: 0.5001\n",
            "Epoch 41/50\n",
            "1000/1000 [==============================] - 128s 128ms/step - loss: 0.6939 - accuracy: 0.4942 - val_loss: 0.6933 - val_accuracy: 0.4999\n",
            "Epoch 42/50\n",
            "1000/1000 [==============================] - 130s 130ms/step - loss: 0.6939 - accuracy: 0.4986 - val_loss: 0.6944 - val_accuracy: 0.4999\n",
            "Epoch 43/50\n",
            "1000/1000 [==============================] - 130s 130ms/step - loss: 0.6940 - accuracy: 0.4988 - val_loss: 0.6933 - val_accuracy: 0.4999\n",
            "Epoch 44/50\n",
            "1000/1000 [==============================] - 129s 129ms/step - loss: 0.6938 - accuracy: 0.4991 - val_loss: 0.6971 - val_accuracy: 0.4999\n",
            "Epoch 45/50\n",
            "1000/1000 [==============================] - 129s 129ms/step - loss: 0.6939 - accuracy: 0.4963 - val_loss: 0.6939 - val_accuracy: 0.4999\n",
            "Epoch 46/50\n",
            "1000/1000 [==============================] - 128s 128ms/step - loss: 0.6940 - accuracy: 0.5014 - val_loss: 0.6932 - val_accuracy: 0.5001\n",
            "Epoch 47/50\n",
            "1000/1000 [==============================] - 127s 127ms/step - loss: 0.6938 - accuracy: 0.4972 - val_loss: 0.6932 - val_accuracy: 0.5001\n",
            "Epoch 48/50\n",
            "1000/1000 [==============================] - 128s 128ms/step - loss: 0.6937 - accuracy: 0.5010 - val_loss: 0.6946 - val_accuracy: 0.4999\n",
            "Epoch 49/50\n",
            "1000/1000 [==============================] - 128s 128ms/step - loss: 0.6937 - accuracy: 0.5008 - val_loss: 0.6944 - val_accuracy: 0.4999\n",
            "Epoch 50/50\n",
            "1000/1000 [==============================] - 128s 128ms/step - loss: 0.6940 - accuracy: 0.4991 - val_loss: 0.6942 - val_accuracy: 0.5001\n",
            "Fold 1, 50 epochs, 6459 sec\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-jG1h5fj2Ua",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49b377a5-786d-4909-ea7e-cb11534e1044"
      },
      "source": [
        "from keras.models import load_model\n",
        "pc_sim.set_reproducible(True)\n",
        "nc_sim.set_reproducible(True)\n",
        "pc_test = pc_sim.get_sequences(PC_TESTS)\n",
        "nc_test = nc_sim.get_sequences(NC_TESTS)\n",
        "X,y = prepare_inputs_len_x_alphabet(pc_test,nc_test,ALPHABET)\n",
        "best_model=load_model(MODELPATH)\n",
        "scores = best_model.evaluate(X, y, verbose=0)\n",
        "print(\"The best model parameters were saved during cross-validation.\")\n",
        "print(\"Best was defined as maximum validation accuracy at end of any epoch.\")\n",
        "print(\"Now re-load the best model and test it on previously unseen data.\")\n",
        "print(\"Test on\",len(pc_test),\"PC seqs\")\n",
        "print(\"Test on\",len(nc_test),\"NC seqs\")\n",
        "print(\"%s: %.2f%%\" % (best_model.metrics_names[1], scores[1]*100))\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The best model parameters were saved during cross-validation.\n",
            "Best was defined as maximum validation accuracy at end of any epoch.\n",
            "Now re-load the best model and test it on previously unseen data.\n",
            "Test on 1000 PC seqs\n",
            "Test on 1000 NC seqs\n",
            "accuracy: 49.98%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VycUnmvUj2Ue",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "907656a6-b64e-427d-e042-8e5bc4af9a4a"
      },
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "ns_probs = [0 for _ in range(len(y))]\n",
        "bm_probs = best_model.predict(X)\n",
        "ns_auc = roc_auc_score(y, ns_probs)\n",
        "bm_auc = roc_auc_score(y, bm_probs)\n",
        "ns_fpr, ns_tpr, _ = roc_curve(y, ns_probs)\n",
        "bm_fpr, bm_tpr, _ = roc_curve(y, bm_probs)\n",
        "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='Guess, auc=%.4f'%ns_auc)\n",
        "plt.plot(bm_fpr, bm_tpr, marker='.', label='Model, auc=%.4f'%bm_auc)\n",
        "plt.title('ROC')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "print(\"%s: %.2f%%\" %('AUC',bm_auc))\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-d1c96b58fcc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbm_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mns_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mns_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mbm_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbm_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mns_fpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mns_tpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mns_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mbm_fpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbm_tpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbm_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     if y_type == \"multiclass\" or (y_type == \"binary\" and\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n\u001b[0;32m--> 574\u001b[0;31m                              % (array.ndim, estimator_name))\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found array with dim 3. Estimator expected <= 2."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFMb6rGNj2Ug"
      },
      "source": [
        "t = time.time()\n",
        "time.strftime('%Y-%m-%d %H:%M:%S %Z', time.localtime(t))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}