{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PC_SEQUENCES=1000\n",
    "NC_SEQUENCES=1000\n",
    "BASES=55\n",
    "ALPHABET=4\n",
    "EPOCHS=5  # use 5 for software testing, 50 for model testing\n",
    "INPUT_SHAPE_2D = (BASES,ALPHABET,1) #2D inputs\n",
    "INPUT_SHAPE = (BASES,ALPHABET) #1D inputs\n",
    "CELLS = 16\n",
    "FILTERS = 16\n",
    "WIDTH = 3\n",
    "STRIDE_2D = (1,1)\n",
    "STRIDE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On my PC, use relative paths.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    IN_COLAB = True\n",
    "    print(\"On Google CoLab, mount cloud-local file, get our code from GitHub.\")\n",
    "    PATH='/content/drive/'\n",
    "    drive.mount(PATH)\n",
    "    DATAPATH=PATH+'My Drive/data/'  # must end in \"/\"\n",
    "    import requests\n",
    "    r = requests.get('https://raw.githubusercontent.com/ShepherdCode/Soars2021/blob/main/SimTools/RNA_gen.py')\n",
    "    with open('RNA_gen.py', 'w') as f:\n",
    "        f.write(r.text)  # delete the file later?\n",
    "except:\n",
    "    print(\"On my PC, use relative paths.\")\n",
    "    IN_COLAB = False\n",
    "    DATAPATH='data/'  # must end in \"/\"\n",
    "    sys.path.append(\"..\") # append parent dir in order to use sibling dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import datetime\n",
    "import csv\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats  # mode\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Embedding\n",
    "from keras.layers import Conv1D,Conv2D\n",
    "from keras.layers import Flatten,MaxPooling1D,MaxPooling2D\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "mycmap = colors.ListedColormap(['red','blue'])  # list color for label 0 then 1\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "from SimTools.RNA_gen import *\n",
    "if not assert_imported_RNA_gen():\n",
    "    print(\"ERROR: Cannot use RNA_gen.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-06 13:07:22.261924\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_sequences():\n",
    "    cgen = Collection_Generator()\n",
    "    sgen = Sequence_Oracle()\n",
    "    lgen = Length_Oracle()\n",
    "    lgen.set_mean(BASES)\n",
    "    cgen.set_seq_oracle(sgen)\n",
    "    cgen.set_len_oracle(lgen)\n",
    "    pc_seqs=cgen.get_sequences(PC_SEQUENCES)\n",
    "    nc_seqs=cgen.get_sequences(NC_SEQUENCES)\n",
    "    return pc_seqs,nc_seqs\n",
    "pc_seqs,nc_seqs = get_all_sequences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (2000, 55, 4)\n",
      "y shape: (2000,)\n"
     ]
    }
   ],
   "source": [
    "def prepare_for_learning(pcs,ncs):\n",
    "    NUM_SAMPLES=PC_SEQUENCES+NC_SEQUENCES\n",
    "    samples = nc_seqs + pc_seqs\n",
    "    X_shape = (NUM_SAMPLES,BASES,ALPHABET)\n",
    "    Y_shape = (NUM_SAMPLES,1)\n",
    "    y=np.concatenate((np.zeros(NC_SEQUENCES,dtype=np.int8),\n",
    "                      np.ones(PC_SEQUENCES,dtype=np.int8)))\n",
    "    X=np.zeros(X_shape,dtype=np.int8)\n",
    "    base_to_dim = {'A':0, 'C':1, 'G':2, 'T':3}\n",
    "    for s in range(0,NUM_SAMPLES):  # TO DO: speed this up by avoiding loops\n",
    "        sample = samples[s]\n",
    "        for b in range(0,BASES): # use len(sample) if length varies\n",
    "            base = sample[b]\n",
    "            d = base_to_dim[base]   # TO DO: error on non-ACGT\n",
    "            X[s,b,d]=1\n",
    "    return X,y\n",
    "X,y = prepare_for_learning(pc_seqs,nc_seqs)\n",
    "print(\"X shape:\",X.shape)\n",
    "print(\"y shape:\",y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make_DNN\n",
      "input shape: (55, 4)\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 55, 3)             12        \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 55, 16)            160       \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 55, 16)            784       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 27, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 432)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 433       \n",
      "=================================================================\n",
      "Total params: 1,389\n",
      "Trainable params: 1,389\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def make_DNN():\n",
    "    print(\"make_DNN\")\n",
    "    print(\"input shape:\",INPUT_SHAPE)\n",
    "    EMBED_DIM = 3 # for 4-letter one-hot inputs, encode each letter as 3D vector\n",
    "    dnn = Sequential()\n",
    "    dnn.add(Embedding(ALPHABET,EMBED_DIM,input_length=BASES)) \n",
    "    dnn.add(Conv1D( \n",
    "            filters=FILTERS,kernel_size=WIDTH,strides=STRIDE,\n",
    "            activation=None, padding=\"same\"))\n",
    "    dnn.add(Conv1D(\n",
    "            filters=FILTERS,kernel_size=WIDTH,strides=STRIDE,\n",
    "            activation=None, padding=\"same\"))\n",
    "    dnn.add(MaxPooling1D())\n",
    "    dnn.add(Flatten())\n",
    "    dnn.add(Dense(1))   \n",
    "    dnn.compile(optimizer='adam')\n",
    "    dnn.build(input_shape=INPUT_SHAPE)\n",
    "    #ln_rate = tf.keras.optimizers.Adam(learning_rate = LN_RATE)\n",
    "    #bc=tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "    #model.compile(loss=bc, optimizer=ln_rate, metrics=[\"accuracy\"])\n",
    "    return dnn\n",
    "model = make_DNN()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cors = []\n",
    "overall = 0\n",
    "cnt = 0\n",
    "one_site_weather = load_weather_for_site(SITE)\n",
    "for BLDG in SITE_BUILDINGS:\n",
    "    print(\"Building\",BLDG)\n",
    "    one_bldg_meter = load_meter_for_building(BLDG,SMOOTHING_WINDOW)\n",
    "    count_bad = one_bldg_meter[PREDICTED_VARIABLE].isna().sum()\n",
    "    MAX_BAD = 500\n",
    "    if count_bad<=MAX_BAD:\n",
    "        # Must get rid of Nan labels, else loss hits NaN during training.\n",
    "        print(\" Count bad values before pseudofill:\",count_bad)\n",
    "        pseudovalue = one_bldg_meter[PREDICTED_VARIABLE].mean()\n",
    "        one_bldg_meter = one_bldg_meter.fillna(pseudovalue)\n",
    "        count_bad = one_bldg_meter[PREDICTED_VARIABLE].isna().sum()\n",
    "        print(\" Count bad values after pseudofill:\",count_bad)\n",
    "        # Smoothing window applies to inputs\n",
    "        X,y = prepare_for_learning(one_site_weather,one_bldg_meter)\n",
    "        split = len(X)//2   # year 1 vs year 2\n",
    "        X_train = np.asarray(X[0:split])\n",
    "        y_train = np.asarray(y[0:split])\n",
    "        X_test = np.asarray(X[split:])\n",
    "        # Smoothing does not apply to truth\n",
    "        one_bldg_meter = load_meter_for_building(BLDG,0)\n",
    "        one_bldg_meter = one_bldg_meter.fillna(pseudovalue)\n",
    "        X_raw,y_raw = prepare_for_learning(one_site_weather,one_bldg_meter)\n",
    "        y_test = np.asarray(y_raw[split:])\n",
    "        # Train and predict\n",
    "        model = make_DNN()\n",
    "        print(model.summary())\n",
    "        example=411\n",
    "        print(\"Example y train:\\n\",y_train[example].astype(int))\n",
    "        model.fit(X_train,y_train,epochs=EPOCHS)\n",
    "        y_pred = model.predict(X_test)\n",
    "        # Reporting\n",
    "        rmse = mean_squared_error(y_test,y_pred,squared=False)\n",
    "        mean = one_bldg_meter[PREDICTED_VARIABLE].mean()\n",
    "        cors.append([mean,rmse,rmse/mean,BLDG])\n",
    "        cnt += 1\n",
    "        print(\"i,mean,rmse,rmse/mean,bldg:\",cnt,mean,rmse,rmse/mean,BLDG)\n",
    "        overall += rmse/mean\n",
    "        for hr in range(0,24,2):\n",
    "            print(\"Example prediction:\\n\",hr,y_pred[example+hr].astype(int))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
